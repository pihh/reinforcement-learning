{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c22e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T18:16:06.378762Z",
     "start_time": "2022-08-08T18:16:05.724763Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()\n",
    "\n",
    "import gym\n",
    "import src.environments.continuous.stock_trading  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0abe17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T15:21:01.332156Z",
     "start_time": "2022-08-08T15:20:59.717151Z"
    }
   },
   "source": [
    "### Train the agent\n",
    "* Run it until he has a running average above the success_threshold\n",
    "* Use a large number of episodes for the running average ( 1000+ ) so if even it falls into a privileged sample, it wont be prone to error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2904b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T15:21:04.196241Z",
     "start_time": "2022-08-08T15:21:01.334159Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab573ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T18:16:06.394763Z",
     "start_time": "2022-08-08T18:16:06.381764Z"
    }
   },
   "outputs": [],
   "source": [
    "def environment():\n",
    "    env = gym.make('StockTradingEnvironment-v0',\n",
    "        use_technical_indicators= [\n",
    "        \"macd\",\n",
    "        \"boll_ub\",\n",
    "        \"boll_lb\",\n",
    "        \"rsi_30\",\n",
    "        \"cci_30\",\n",
    "        \"dx_30\",\n",
    "        \"close_30_sma\",\n",
    "        \"close_60_sma\",\n",
    "    ])\n",
    "    \n",
    "    env.success_threshold =0.25 # 25%\n",
    "    return env\n",
    "\n",
    "# from src.environments.continuous.trading import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d58347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T18:16:10.169273Z",
     "start_time": "2022-08-08T18:16:06.397766Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.agents.ppo import PpoAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f83292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T18:16:11.262426Z",
     "start_time": "2022-08-08T18:16:10.172274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent=PpoAgent(environment,actor_learning_rate=0.000025,critic_learning_rate=0.000025,policy=\"CNN\")\n",
    "#agent.load()\n",
    "environment().success_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85947b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:59:54.209867Z",
     "start_time": "2022-08-08T18:16:11.264428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 50/100000, score: -0.18632, average: 0.00348 \n",
      "episode: 100/100000, score: 0.15014, average: 0.05732 \n",
      "episode: 150/100000, score: 0.22760, average: 0.07745 \n",
      "episode: 200/100000, score: 0.23973, average: 0.08336 \n",
      "episode: 250/100000, score: 0.20265, average: 0.07955 \n",
      "episode: 300/100000, score: 0.24832, average: 0.07660 \n",
      "episode: 350/100000, score: 0.25888, average: 0.07555 \n",
      "episode: 400/100000, score: 0.24242, average: 0.07228 \n",
      "episode: 450/100000, score: 0.26052, average: 0.07342 \n",
      "episode: 500/100000, score: -0.03302, average: 0.07196 \n",
      "episode: 550/100000, score: 0.31949, average: 0.07286 \n",
      "episode: 600/100000, score: -0.08009, average: 0.06882 \n",
      "episode: 650/100000, score: 0.10843, average: 0.06462 \n",
      "episode: 700/100000, score: -0.11377, average: 0.06697 \n",
      "episode: 750/100000, score: -0.07820, average: 0.06345 \n",
      "episode: 800/100000, score: -0.12765, average: 0.06307 \n",
      "episode: 850/100000, score: 0.02245, average: 0.06662 \n",
      "episode: 900/100000, score: 0.15014, average: 0.06475 \n",
      "episode: 950/100000, score: 0.11157, average: 0.06254 \n",
      "episode: 1000/100000, score: -0.14446, average: 0.06135 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.06159362308270756\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.0616235078315069\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06193858543313106\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06218003157617345\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.062342380147551855\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.0624934905047457\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06266182894546495\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06292643564668082\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06318779909980987\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06343185555884874\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06356002261123883\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06379005540807273\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06403395548867744\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06420769708163232\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06431003017735297\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06457921406907952\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06458264651059538\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06480286626018156\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06531873917673849\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.0654927956558178\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 1050/100000, score: -0.15228, average: 0.06474 \n",
      "episode: 1100/100000, score: -0.06845, average: 0.06026 \n",
      "episode: 1150/100000, score: -0.11617, average: 0.05634 \n",
      "episode: 1200/100000, score: 0.29779, average: 0.05438 \n",
      "episode: 1250/100000, score: -0.18454, average: 0.05277 \n",
      "episode: 1300/100000, score: 0.29845, average: 0.05383 \n",
      "episode: 1350/100000, score: 0.16490, average: 0.05467 \n",
      "episode: 1400/100000, score: 0.17130, average: 0.05532 \n",
      "episode: 1450/100000, score: 0.27313, average: 0.05441 \n",
      "episode: 1500/100000, score: -0.13353, average: 0.05278 \n",
      "episode: 1550/100000, score: -0.11186, average: 0.05409 \n",
      "episode: 1600/100000, score: 0.21209, average: 0.05548 \n",
      "episode: 1650/100000, score: -0.15405, average: 0.06119 \n",
      "episode: 1700/100000, score: 0.19922, average: 0.05852 \n",
      "episode: 1750/100000, score: 0.26341, average: 0.05951 \n",
      "episode: 1800/100000, score: 0.08553, average: 0.06103 \n",
      "episode: 1850/100000, score: -0.14723, average: 0.05670 \n",
      "episode: 1900/100000, score: 0.25121, average: 0.05941 \n",
      "episode: 1950/100000, score: 0.16775, average: 0.06251 \n",
      "episode: 2000/100000, score: 0.24554, average: 0.06490 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.06588043548634007\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06594260988697882\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06594905588704343\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06624394625415632\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06639483332835401\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 2050/100000, score: -0.05381, average: 0.06604 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.06644529141517878\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06685192811598877\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06716282018599434\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06761085480414707\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06763146680967948\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 2100/100000, score: -0.18394, average: 0.06509 \n",
      "episode: 2150/100000, score: 0.26213, average: 0.06326 \n",
      "episode: 2200/100000, score: -0.14538, average: 0.06209 \n",
      "episode: 2250/100000, score: -0.06838, average: 0.06505 \n",
      "episode: 2300/100000, score: 0.25121, average: 0.06535 \n",
      "episode: 2350/100000, score: 0.22760, average: 0.06275 \n",
      "episode: 2400/100000, score: 0.19365, average: 0.06272 \n",
      "episode: 2450/100000, score: 0.24349, average: 0.06207 \n",
      "episode: 2500/100000, score: 0.27736, average: 0.06398 \n",
      "episode: 2550/100000, score: -0.15228, average: 0.06185 \n",
      "episode: 2600/100000, score: 0.27443, average: 0.06292 \n",
      "episode: 2650/100000, score: 0.29845, average: 0.05980 \n",
      "episode: 2700/100000, score: 0.18839, average: 0.05977 \n",
      "episode: 2750/100000, score: 0.32394, average: 0.06112 \n",
      "episode: 2800/100000, score: -0.20367, average: 0.05876 \n",
      "episode: 2850/100000, score: 0.31905, average: 0.06362 \n",
      "episode: 2900/100000, score: 0.10332, average: 0.06254 \n",
      "episode: 2950/100000, score: 0.29661, average: 0.06021 \n",
      "episode: 3000/100000, score: -0.15560, average: 0.05878 \n",
      "episode: 3050/100000, score: -0.11673, average: 0.05551 \n",
      "episode: 3100/100000, score: 0.16298, average: 0.05867 \n",
      "episode: 3150/100000, score: -0.12886, average: 0.06288 \n",
      "episode: 3200/100000, score: 0.26433, average: 0.06193 \n",
      "episode: 3250/100000, score: -0.19829, average: 0.06169 \n",
      "episode: 3300/100000, score: -0.07771, average: 0.05988 \n",
      "episode: 3350/100000, score: -0.18138, average: 0.06197 \n",
      "episode: 3400/100000, score: 0.17691, average: 0.06134 \n",
      "episode: 3450/100000, score: 0.16490, average: 0.06252 \n",
      "episode: 3500/100000, score: 0.28848, average: 0.06095 \n",
      "episode: 3550/100000, score: -0.19682, average: 0.06146 \n",
      "episode: 3600/100000, score: 0.23162, average: 0.05776 \n",
      "episode: 3650/100000, score: -0.11186, average: 0.05681 \n",
      "episode: 3700/100000, score: 0.18254, average: 0.05826 \n",
      "episode: 3750/100000, score: -0.23998, average: 0.05501 \n",
      "episode: 3800/100000, score: 0.31343, average: 0.05621 \n",
      "episode: 3850/100000, score: 0.20618, average: 0.05392 \n",
      "episode: 3900/100000, score: -0.20242, average: 0.05409 \n",
      "episode: 3950/100000, score: 0.30263, average: 0.05444 \n",
      "episode: 4000/100000, score: 0.10625, average: 0.05520 \n",
      "episode: 4050/100000, score: -0.08843, average: 0.05380 \n",
      "episode: 4100/100000, score: 0.23665, average: 0.05269 \n",
      "episode: 4150/100000, score: 0.14390, average: 0.05027 \n",
      "episode: 4200/100000, score: 0.23155, average: 0.05221 \n",
      "episode: 4250/100000, score: -0.18462, average: 0.04842 \n",
      "episode: 4300/100000, score: 0.10843, average: 0.04684 \n",
      "episode: 4350/100000, score: 0.02966, average: 0.04499 \n",
      "episode: 4400/100000, score: -0.12886, average: 0.04390 \n",
      "episode: 4450/100000, score: -0.10874, average: 0.04330 \n",
      "episode: 4500/100000, score: -0.06238, average: 0.04252 \n",
      "episode: 4550/100000, score: -0.18493, average: 0.04426 \n",
      "episode: 4600/100000, score: 0.23775, average: 0.04679 \n",
      "episode: 4650/100000, score: -0.10251, average: 0.04618 \n",
      "episode: 4700/100000, score: 0.31343, average: 0.04629 \n",
      "episode: 4750/100000, score: -0.13366, average: 0.04865 \n",
      "episode: 4800/100000, score: 0.17691, average: 0.04975 \n",
      "episode: 4850/100000, score: 0.23973, average: 0.04905 \n",
      "episode: 4900/100000, score: -0.20481, average: 0.04929 \n",
      "episode: 4950/100000, score: -0.20258, average: 0.05204 \n",
      "episode: 5000/100000, score: -0.14173, average: 0.05024 \n",
      "episode: 5050/100000, score: -0.15200, average: 0.05066 \n",
      "episode: 5100/100000, score: -0.19381, average: 0.05230 \n",
      "episode: 5150/100000, score: 0.32394, average: 0.05399 \n",
      "episode: 5200/100000, score: -0.07771, average: 0.05166 \n",
      "episode: 5250/100000, score: -0.19682, average: 0.05479 \n",
      "episode: 5300/100000, score: 0.24832, average: 0.05758 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5350/100000, score: -0.13198, average: 0.05863 \n",
      "episode: 5400/100000, score: -0.15405, average: 0.05864 \n",
      "episode: 5450/100000, score: -0.03613, average: 0.05692 \n",
      "episode: 5500/100000, score: -0.19682, average: 0.05871 \n",
      "episode: 5550/100000, score: 0.26341, average: 0.05440 \n",
      "episode: 5600/100000, score: -0.09824, average: 0.05558 \n",
      "episode: 5650/100000, score: 0.22516, average: 0.05605 \n",
      "episode: 5700/100000, score: -0.17911, average: 0.05666 \n",
      "episode: 5750/100000, score: 0.21209, average: 0.05586 \n",
      "episode: 5800/100000, score: 0.11157, average: 0.05583 \n",
      "episode: 5850/100000, score: 0.16797, average: 0.05543 \n",
      "episode: 5900/100000, score: 0.14384, average: 0.05512 \n",
      "episode: 5950/100000, score: -0.08843, average: 0.05181 \n",
      "episode: 6000/100000, score: -0.13198, average: 0.04802 \n",
      "episode: 6050/100000, score: -0.17911, average: 0.05090 \n",
      "episode: 6100/100000, score: -0.18203, average: 0.05186 \n",
      "episode: 6150/100000, score: -0.18184, average: 0.05126 \n",
      "episode: 6200/100000, score: 0.33654, average: 0.05304 \n",
      "episode: 6250/100000, score: -0.11186, average: 0.05561 \n",
      "episode: 6300/100000, score: 0.18839, average: 0.05640 \n",
      "episode: 6350/100000, score: -0.23998, average: 0.05505 \n",
      "episode: 6400/100000, score: 0.22577, average: 0.05592 \n",
      "episode: 6450/100000, score: -0.19424, average: 0.05731 \n",
      "episode: 6500/100000, score: -0.19682, average: 0.05794 \n",
      "episode: 6550/100000, score: 0.24832, average: 0.06159 \n",
      "episode: 6600/100000, score: 0.25246, average: 0.06360 \n",
      "episode: 6650/100000, score: -0.06845, average: 0.06233 \n",
      "episode: 6700/100000, score: 0.19922, average: 0.05947 \n",
      "episode: 6750/100000, score: 0.28359, average: 0.06080 \n",
      "episode: 6800/100000, score: 0.11137, average: 0.05908 \n",
      "episode: 6850/100000, score: 0.20618, average: 0.06005 \n",
      "episode: 6900/100000, score: 0.33571, average: 0.05968 \n",
      "episode: 6950/100000, score: 0.31663, average: 0.06193 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.0676684212322248\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06798782683717791\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06802060438151393\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06813477320305403\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06828717873899363\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06831544663272639\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06832775723770375\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.0687038246404421\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.0690615728900278\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 7000/100000, score: 0.22577, average: 0.06906 \n",
      "episode: 7050/100000, score: 0.31949, average: 0.06767 \n",
      "episode: 7100/100000, score: -0.04215, average: 0.06546 \n",
      "episode: 7150/100000, score: -0.20258, average: 0.06610 \n",
      "episode: 7200/100000, score: 0.25888, average: 0.06745 \n",
      "episode: 7250/100000, score: -0.05348, average: 0.06307 \n",
      "episode: 7300/100000, score: 0.27169, average: 0.06188 \n",
      "episode: 7350/100000, score: -0.02483, average: 0.06541 \n",
      "episode: 7400/100000, score: -0.04295, average: 0.06825 \n",
      "episode: 7450/100000, score: 0.20618, average: 0.06879 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.06906794491033696\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 7500/100000, score: 0.21304, average: 0.06705 \n",
      "episode: 7550/100000, score: 0.03258, average: 0.06624 \n",
      "episode: 7600/100000, score: -0.17079, average: 0.06453 \n",
      "episode: 7650/100000, score: 0.14390, average: 0.06555 \n",
      "episode: 7700/100000, score: -0.04295, average: 0.06683 \n",
      "episode: 7750/100000, score: -0.19424, average: 0.06800 \n",
      "* Models saved *\n",
      "\n",
      "New record  0.06918066385569989\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06934211219948554\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.06978071865047497\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.07028389524024024\n",
      "Learning rate decreased\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New record  0.07036091729574222\n",
      "Learning rate decreased\n",
      "\n",
      "episode: 7800/100000, score: -0.13545, average: 0.06785 \n",
      "episode: 7850/100000, score: 0.17028, average: 0.06637 \n",
      "episode: 7900/100000, score: -0.04857, average: 0.06579 \n",
      "episode: 7950/100000, score: 0.03258, average: 0.06504 \n",
      "episode: 8000/100000, score: -0.03093, average: 0.06200 \n",
      "episode: 8050/100000, score: -0.05301, average: 0.06492 \n",
      "episode: 8100/100000, score: -0.05718, average: 0.06405 \n",
      "episode: 8150/100000, score: -0.08009, average: 0.06150 \n",
      "episode: 8200/100000, score: 0.31764, average: 0.06064 \n",
      "episode: 8250/100000, score: -0.07350, average: 0.06400 \n",
      "episode: 8300/100000, score: -0.17911, average: 0.06211 \n",
      "episode: 8350/100000, score: 0.27443, average: 0.05768 \n",
      "episode: 8400/100000, score: -0.17141, average: 0.05426 \n",
      "episode: 8450/100000, score: -0.20481, average: 0.05460 \n",
      "episode: 8500/100000, score: -0.17398, average: 0.05711 \n",
      "episode: 8550/100000, score: 0.31663, average: 0.05463 \n",
      "episode: 8600/100000, score: 0.27443, average: 0.05228 \n",
      "episode: 8650/100000, score: 0.27736, average: 0.05535 \n",
      "episode: 8700/100000, score: 0.16490, average: 0.05353 \n",
      "episode: 8750/100000, score: 0.29302, average: 0.05296 \n",
      "episode: 8800/100000, score: -0.18295, average: 0.05341 \n",
      "episode: 8850/100000, score: 0.26341, average: 0.05352 \n",
      "episode: 8900/100000, score: 0.20706, average: 0.05337 \n",
      "episode: 8950/100000, score: 0.25248, average: 0.05427 \n",
      "episode: 9000/100000, score: -0.18138, average: 0.05450 \n",
      "episode: 9050/100000, score: 0.31620, average: 0.05194 \n",
      "episode: 9100/100000, score: -0.20242, average: 0.05026 \n",
      "episode: 9150/100000, score: -0.02483, average: 0.05076 \n",
      "episode: 9200/100000, score: -0.19237, average: 0.05133 \n",
      "episode: 9250/100000, score: -0.05637, average: 0.04702 \n",
      "episode: 9300/100000, score: 0.31949, average: 0.04916 \n",
      "episode: 9350/100000, score: -0.07795, average: 0.05139 \n",
      "episode: 9400/100000, score: -0.18203, average: 0.05245 \n",
      "episode: 9450/100000, score: 0.02966, average: 0.05012 \n",
      "episode: 9500/100000, score: 0.31955, average: 0.05134 \n",
      "episode: 9550/100000, score: -0.17141, average: 0.05221 \n",
      "episode: 9600/100000, score: 0.16298, average: 0.05710 \n",
      "episode: 9650/100000, score: -0.10873, average: 0.05407 \n",
      "episode: 9700/100000, score: 0.30263, average: 0.05476 \n",
      "episode: 9750/100000, score: 0.18254, average: 0.05478 \n",
      "episode: 9800/100000, score: 0.20948, average: 0.05508 \n",
      "episode: 9850/100000, score: -0.15210, average: 0.05512 \n",
      "episode: 9900/100000, score: 0.29302, average: 0.05413 \n",
      "episode: 9950/100000, score: -0.11052, average: 0.05120 \n",
      "episode: 10000/100000, score: -0.19237, average: 0.05027 \n",
      "episode: 10050/100000, score: 0.20265, average: 0.05175 \n",
      "episode: 10100/100000, score: 0.28359, average: 0.05527 \n",
      "episode: 10150/100000, score: 0.20618, average: 0.05660 \n",
      "episode: 10200/100000, score: -0.05706, average: 0.05655 \n",
      "episode: 10250/100000, score: -0.00533, average: 0.05532 \n",
      "episode: 10300/100000, score: -0.11617, average: 0.05526 \n",
      "episode: 10350/100000, score: 0.28841, average: 0.05532 \n",
      "episode: 10400/100000, score: -0.18295, average: 0.05683 \n",
      "episode: 10450/100000, score: 0.06893, average: 0.06006 \n",
      "episode: 10500/100000, score: -0.18741, average: 0.05659 \n",
      "episode: 10550/100000, score: -0.07560, average: 0.05497 \n",
      "episode: 10600/100000, score: 0.21304, average: 0.05345 \n",
      "episode: 10650/100000, score: -0.05301, average: 0.05429 \n",
      "episode: 10700/100000, score: -0.16941, average: 0.05599 \n",
      "episode: 10750/100000, score: 0.29845, average: 0.05396 \n",
      "episode: 10800/100000, score: -0.11052, average: 0.05275 \n",
      "episode: 10850/100000, score: 0.20618, average: 0.05412 \n",
      "episode: 10900/100000, score: 0.19531, average: 0.05600 \n",
      "episode: 10950/100000, score: 0.16797, average: 0.05901 \n",
      "episode: 11000/100000, score: -0.08009, average: 0.05971 \n",
      "episode: 11050/100000, score: -0.08009, average: 0.05659 \n",
      "episode: 11100/100000, score: -0.16503, average: 0.05611 \n",
      "episode: 11150/100000, score: 0.14390, average: 0.05427 \n",
      "episode: 11200/100000, score: -0.18705, average: 0.05434 \n",
      "episode: 11250/100000, score: 0.33654, average: 0.05736 \n",
      "episode: 11300/100000, score: -0.10899, average: 0.05638 \n",
      "episode: 11350/100000, score: -0.08510, average: 0.05863 \n",
      "episode: 11400/100000, score: 0.24349, average: 0.05677 \n",
      "episode: 11450/100000, score: 0.23775, average: 0.05462 \n",
      "episode: 11500/100000, score: 0.29661, average: 0.05555 \n",
      "episode: 11550/100000, score: 0.11157, average: 0.05720 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 11600/100000, score: 0.30333, average: 0.05565 \n",
      "episode: 11650/100000, score: -0.11673, average: 0.05460 \n",
      "episode: 11700/100000, score: 0.03351, average: 0.05439 \n",
      "episode: 11750/100000, score: 0.25121, average: 0.05623 \n",
      "episode: 11800/100000, score: 0.32244, average: 0.05797 \n",
      "episode: 11850/100000, score: -0.13545, average: 0.05677 \n",
      "episode: 11900/100000, score: 0.32115, average: 0.05590 \n",
      "episode: 11950/100000, score: 0.20706, average: 0.05675 \n",
      "episode: 12000/100000, score: 0.19531, average: 0.05999 \n",
      "episode: 12050/100000, score: 0.17028, average: 0.06315 \n",
      "episode: 12100/100000, score: 0.26433, average: 0.06161 \n",
      "episode: 12150/100000, score: -0.19424, average: 0.06131 \n",
      "episode: 12200/100000, score: 0.30473, average: 0.06240 \n",
      "episode: 12250/100000, score: -0.19379, average: 0.06199 \n",
      "episode: 12300/100000, score: 0.17852, average: 0.06411 \n",
      "episode: 12350/100000, score: -0.13366, average: 0.06202 \n",
      "episode: 12400/100000, score: 0.28359, average: 0.06221 \n",
      "episode: 12450/100000, score: 0.17691, average: 0.06211 \n",
      "episode: 12500/100000, score: -0.02483, average: 0.06127 \n",
      "episode: 12550/100000, score: 0.18772, average: 0.06179 \n",
      "episode: 12600/100000, score: -0.10251, average: 0.05981 \n",
      "episode: 12650/100000, score: 0.21347, average: 0.06316 \n",
      "episode: 12700/100000, score: -0.19424, average: 0.06210 \n",
      "episode: 12750/100000, score: 0.18614, average: 0.06230 \n",
      "episode: 12800/100000, score: 0.29302, average: 0.06284 \n",
      "episode: 12850/100000, score: -0.11617, average: 0.06100 \n",
      "episode: 12900/100000, score: -0.04857, average: 0.06059 \n",
      "episode: 12950/100000, score: 0.22535, average: 0.05710 \n",
      "episode: 13000/100000, score: -0.11673, average: 0.05280 \n",
      "episode: 13050/100000, score: 0.28359, average: 0.05344 \n",
      "episode: 13100/100000, score: 0.30392, average: 0.05499 \n",
      "episode: 13150/100000, score: 0.18614, average: 0.05517 \n",
      "episode: 13200/100000, score: -0.13198, average: 0.05354 \n",
      "episode: 13250/100000, score: -0.15353, average: 0.05533 \n",
      "episode: 13300/100000, score: 0.26341, average: 0.05315 \n",
      "episode: 13350/100000, score: -0.18432, average: 0.05309 \n",
      "episode: 13400/100000, score: -0.10874, average: 0.05437 \n",
      "episode: 13450/100000, score: 0.27313, average: 0.05489 \n",
      "episode: 13500/100000, score: 0.29296, average: 0.05582 \n",
      "episode: 13550/100000, score: -0.15228, average: 0.05480 \n",
      "episode: 13600/100000, score: -0.15560, average: 0.05694 \n",
      "episode: 13650/100000, score: 0.10625, average: 0.05325 \n",
      "episode: 13700/100000, score: -0.08009, average: 0.05420 \n",
      "episode: 13750/100000, score: 0.19062, average: 0.05249 \n",
      "episode: 13800/100000, score: -0.20258, average: 0.05048 \n",
      "episode: 13850/100000, score: 0.31343, average: 0.05279 \n",
      "episode: 13900/100000, score: 0.28290, average: 0.05364 \n",
      "episode: 13950/100000, score: 0.25121, average: 0.05480 \n",
      "episode: 14000/100000, score: -0.18295, average: 0.05659 \n",
      "episode: 14050/100000, score: -0.05706, average: 0.05339 \n",
      "episode: 14100/100000, score: -0.17079, average: 0.05385 \n",
      "episode: 14150/100000, score: 0.22884, average: 0.05698 \n",
      "episode: 14200/100000, score: 0.31764, average: 0.05445 \n",
      "episode: 14250/100000, score: 0.29661, average: 0.05214 \n",
      "episode: 14300/100000, score: 0.26213, average: 0.04985 \n",
      "episode: 14350/100000, score: 0.33654, average: 0.05174 \n",
      "episode: 14400/100000, score: 0.23162, average: 0.05109 \n",
      "episode: 14450/100000, score: 0.19546, average: 0.05209 \n",
      "episode: 14500/100000, score: -0.13922, average: 0.05153 \n",
      "episode: 14550/100000, score: 0.31764, average: 0.05476 \n",
      "episode: 14600/100000, score: 0.23045, average: 0.05069 \n",
      "episode: 14650/100000, score: 0.28182, average: 0.05178 \n",
      "episode: 14700/100000, score: -0.15242, average: 0.04989 \n",
      "episode: 14750/100000, score: 0.23347, average: 0.05069 \n",
      "episode: 14800/100000, score: 0.19671, average: 0.05194 \n",
      "episode: 14850/100000, score: -0.17911, average: 0.04987 \n",
      "episode: 14900/100000, score: -0.10251, average: 0.04857 \n",
      "episode: 14950/100000, score: 0.17691, average: 0.05013 \n",
      "episode: 15000/100000, score: -0.11465, average: 0.05052 \n",
      "episode: 15050/100000, score: 0.16797, average: 0.05189 \n",
      "episode: 15100/100000, score: 0.26052, average: 0.05143 \n",
      "episode: 15150/100000, score: 0.19922, average: 0.05045 \n",
      "episode: 15200/100000, score: 0.25888, average: 0.05382 \n",
      "episode: 15250/100000, score: -0.08510, average: 0.05343 \n",
      "episode: 15300/100000, score: -0.09824, average: 0.05601 \n",
      "episode: 15350/100000, score: -0.20242, average: 0.05173 \n",
      "episode: 15400/100000, score: 0.30952, average: 0.05293 \n",
      "episode: 15450/100000, score: 0.17987, average: 0.05273 \n",
      "episode: 15500/100000, score: 0.14507, average: 0.05030 \n",
      "episode: 15550/100000, score: -0.08009, average: 0.04607 \n",
      "episode: 15600/100000, score: -0.12765, average: 0.05089 \n",
      "episode: 15650/100000, score: -0.06845, average: 0.05031 \n",
      "episode: 15700/100000, score: 0.23045, average: 0.05098 \n",
      "episode: 15750/100000, score: -0.06040, average: 0.04950 \n",
      "episode: 15800/100000, score: -0.16503, average: 0.04869 \n",
      "episode: 15850/100000, score: -0.03076, average: 0.04907 \n",
      "episode: 15900/100000, score: -0.13922, average: 0.05235 \n",
      "episode: 15950/100000, score: -0.19682, average: 0.05221 \n",
      "episode: 16000/100000, score: 0.20948, average: 0.04970 \n",
      "episode: 16050/100000, score: -0.05301, average: 0.05006 \n",
      "episode: 16100/100000, score: -0.15228, average: 0.05089 \n",
      "episode: 16150/100000, score: 0.29265, average: 0.05141 \n",
      "episode: 16200/100000, score: -0.06421, average: 0.05166 \n",
      "episode: 16250/100000, score: 0.22264, average: 0.05326 \n",
      "episode: 16300/100000, score: 0.14390, average: 0.05231 \n",
      "episode: 16350/100000, score: -0.07771, average: 0.05289 \n",
      "episode: 16400/100000, score: 0.30952, average: 0.05220 \n",
      "episode: 16450/100000, score: -0.07795, average: 0.05224 \n",
      "episode: 16500/100000, score: -0.04547, average: 0.05517 \n",
      "episode: 16550/100000, score: -0.13353, average: 0.05885 \n",
      "episode: 16600/100000, score: -0.06040, average: 0.05785 \n",
      "episode: 16650/100000, score: -0.18295, average: 0.05880 \n",
      "episode: 16700/100000, score: -0.14446, average: 0.05995 \n",
      "episode: 16750/100000, score: -0.18203, average: 0.06265 \n",
      "episode: 16800/100000, score: 0.29779, average: 0.06258 \n",
      "episode: 16850/100000, score: -0.13353, average: 0.06423 \n",
      "episode: 16900/100000, score: 0.22516, average: 0.06446 \n",
      "episode: 16950/100000, score: 0.22516, average: 0.06384 \n",
      "episode: 17000/100000, score: 0.16298, average: 0.06425 \n",
      "episode: 17050/100000, score: 0.19671, average: 0.06345 \n",
      "episode: 17100/100000, score: 0.23665, average: 0.06126 \n",
      "episode: 17150/100000, score: 0.23775, average: 0.06071 \n",
      "episode: 17200/100000, score: -0.06653, average: 0.06058 \n",
      "episode: 17250/100000, score: 0.10625, average: 0.06165 \n",
      "episode: 17300/100000, score: -0.18705, average: 0.06200 \n",
      "episode: 17350/100000, score: -0.17141, average: 0.06482 \n",
      "episode: 17400/100000, score: 0.10776, average: 0.06235 \n",
      "episode: 17450/100000, score: 0.24832, average: 0.06101 \n",
      "episode: 17500/100000, score: 0.14507, average: 0.06071 \n",
      "episode: 17550/100000, score: 0.29366, average: 0.05712 \n",
      "episode: 17600/100000, score: -0.04857, average: 0.05476 \n",
      "episode: 17650/100000, score: -0.13366, average: 0.05354 \n",
      "episode: 17700/100000, score: -0.17293, average: 0.05470 \n",
      "episode: 17750/100000, score: -0.17181, average: 0.05365 \n",
      "episode: 17800/100000, score: 0.11137, average: 0.05616 \n",
      "episode: 17850/100000, score: 0.25888, average: 0.05714 \n",
      "episode: 17900/100000, score: -0.10899, average: 0.05680 \n",
      "episode: 17950/100000, score: -0.08510, average: 0.05594 \n",
      "episode: 18000/100000, score: -0.15242, average: 0.05699 \n",
      "episode: 18050/100000, score: 0.25888, average: 0.05888 \n",
      "episode: 18100/100000, score: -0.15679, average: 0.05924 \n",
      "episode: 18150/100000, score: -0.17293, average: 0.05884 \n",
      "episode: 18200/100000, score: 0.24832, average: 0.05945 \n",
      "episode: 18250/100000, score: -0.03302, average: 0.05519 \n",
      "episode: 18300/100000, score: -0.14538, average: 0.05486 \n",
      "episode: 18350/100000, score: -0.19381, average: 0.05337 \n",
      "episode: 18400/100000, score: -0.18595, average: 0.05340 \n",
      "episode: 18450/100000, score: 0.16490, average: 0.05237 \n",
      "episode: 18500/100000, score: 0.18839, average: 0.05404 \n",
      "episode: 18550/100000, score: 0.11119, average: 0.05572 \n",
      "episode: 18600/100000, score: 0.25675, average: 0.05720 \n",
      "episode: 18650/100000, score: -0.14330, average: 0.05862 \n",
      "episode: 18700/100000, score: 0.17987, average: 0.05966 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 18750/100000, score: 0.06893, average: 0.05776 \n",
      "episode: 18800/100000, score: -0.03613, average: 0.05320 \n",
      "episode: 18850/100000, score: -0.18462, average: 0.05148 \n",
      "episode: 18900/100000, score: -0.09824, average: 0.04648 \n",
      "episode: 18950/100000, score: 0.28841, average: 0.04742 \n",
      "episode: 19000/100000, score: 0.03258, average: 0.04771 \n",
      "episode: 19050/100000, score: 0.31905, average: 0.04922 \n",
      "episode: 19100/100000, score: 0.28841, average: 0.05094 \n",
      "episode: 19150/100000, score: 0.29366, average: 0.05158 \n",
      "episode: 19200/100000, score: -0.11186, average: 0.05160 \n",
      "episode: 19250/100000, score: -0.14538, average: 0.05412 \n",
      "episode: 19300/100000, score: 0.32115, average: 0.05312 \n",
      "episode: 19350/100000, score: 0.28290, average: 0.05278 \n",
      "episode: 19400/100000, score: 0.08553, average: 0.05371 \n",
      "episode: 19450/100000, score: 0.20403, average: 0.05617 \n",
      "episode: 19500/100000, score: -0.18705, average: 0.05563 \n",
      "episode: 19550/100000, score: 0.27313, average: 0.05671 \n",
      "episode: 19600/100000, score: 0.29366, average: 0.05830 \n",
      "episode: 19650/100000, score: 0.33654, average: 0.06016 \n",
      "episode: 19700/100000, score: -0.17398, average: 0.05835 \n",
      "episode: 19750/100000, score: -0.19237, average: 0.06299 \n",
      "episode: 19800/100000, score: 0.17987, average: 0.06319 \n",
      "episode: 19850/100000, score: -0.17141, average: 0.06249 \n",
      "episode: 19900/100000, score: 0.24374, average: 0.06415 \n",
      "episode: 19950/100000, score: 0.29845, average: 0.06461 \n",
      "episode: 20000/100000, score: 0.29265, average: 0.06303 \n",
      "episode: 20050/100000, score: -0.20258, average: 0.06309 \n",
      "episode: 20100/100000, score: -0.17911, average: 0.06261 \n",
      "episode: 20150/100000, score: 0.27736, average: 0.06176 \n",
      "episode: 20200/100000, score: 0.25246, average: 0.06015 \n",
      "episode: 20250/100000, score: 0.29779, average: 0.06129 \n",
      "episode: 20300/100000, score: 0.28601, average: 0.06251 \n",
      "episode: 20350/100000, score: 0.14384, average: 0.06383 \n",
      "episode: 20400/100000, score: 0.21347, average: 0.06366 \n",
      "episode: 20450/100000, score: 0.20265, average: 0.06298 \n",
      "episode: 20500/100000, score: -0.14446, average: 0.06380 \n",
      "episode: 20550/100000, score: 0.26213, average: 0.06284 \n",
      "episode: 20600/100000, score: -0.09824, average: 0.06134 \n",
      "episode: 20650/100000, score: -0.10677, average: 0.06064 \n",
      "episode: 20700/100000, score: 0.29366, average: 0.06041 \n",
      "episode: 20750/100000, score: -0.05348, average: 0.05893 \n",
      "episode: 20800/100000, score: 0.21631, average: 0.06176 \n",
      "episode: 20850/100000, score: 0.28795, average: 0.06065 \n",
      "episode: 20900/100000, score: -0.19381, average: 0.06334 \n",
      "episode: 20950/100000, score: -0.17181, average: 0.06041 \n",
      "episode: 21000/100000, score: 0.29296, average: 0.06168 \n",
      "episode: 21050/100000, score: 0.22760, average: 0.06020 \n",
      "episode: 21100/100000, score: -0.00533, average: 0.05967 \n",
      "episode: 21150/100000, score: -0.03076, average: 0.05864 \n",
      "episode: 21200/100000, score: -0.17455, average: 0.05845 \n",
      "episode: 21250/100000, score: -0.11377, average: 0.05888 \n",
      "episode: 21300/100000, score: 0.19531, average: 0.05836 \n",
      "episode: 21350/100000, score: 0.21304, average: 0.05467 \n",
      "episode: 21400/100000, score: 0.21982, average: 0.05416 \n",
      "episode: 21450/100000, score: -0.09338, average: 0.05070 \n",
      "episode: 21500/100000, score: 0.17130, average: 0.04952 \n",
      "episode: 21550/100000, score: -0.15422, average: 0.04873 \n",
      "episode: 21600/100000, score: 0.32394, average: 0.05211 \n",
      "episode: 21650/100000, score: 0.30952, average: 0.05163 \n",
      "episode: 21700/100000, score: -0.06440, average: 0.05381 \n",
      "episode: 21750/100000, score: -0.18184, average: 0.05313 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuccess_threshold_lookback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuccess_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Development\\GIT\\tmp\\reinforcement-learning\\src\\agents\\ppo\\__init__.py:387\u001b[0m, in \u001b[0;36mPpoAgent.learn\u001b[1;34m(self, timesteps, plot_results, reset, success_threshold, log_level, log_every, success_threshold_lookback, success_strict, n_workers)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_every \u001b[38;5;241m=\u001b[39m log_every\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_multiprocesses(n_workers\u001b[38;5;241m=\u001b[39mn_workers)\n",
      "File \u001b[1;32m~\\Development\\GIT\\tmp\\reinforcement-learning\\src\\agents\\ppo\\__init__.py:302\u001b[0m, in \u001b[0;36mPpoAgent.run_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Development\\GIT\\tmp\\reinforcement-learning\\src\\agents\\ppo\\__init__.py:189\u001b[0m, in \u001b[0;36mPpoAgent.replay\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m    186\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([advantages, actions, predictions])\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# training Actor and Critic networkers\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m a_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m c_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit([states, values], target, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_action_space:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# calculate loss parameters (should be done in loss, but couldn't find workering way how to do that with disabled eager execution)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_v1.py:777\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    776\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:641\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    638\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    639\u001b[0m   val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:377\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_index, batch_logs)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    379\u001b[0m   batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\backend.py:4275\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4270\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4271\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4272\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[0;32m   4273\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4275\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4276\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[0;32m   4278\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4280\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4281\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1484\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.learn(\n",
    "    timesteps=-1, \n",
    "    log_every=50,\n",
    "    success_threshold_lookback=1000,\n",
    "    success_strict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807c3a7",
   "metadata": {},
   "source": [
    "### Test the results\n",
    "* Runs a set of episodes with unseen data\n",
    "* Stores the results in a csv file for later consulting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cbe8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:59:54.211868Z",
     "start_time": "2022-08-09T02:59:54.211868Z"
    }
   },
   "outputs": [],
   "source": [
    "success = 0\n",
    "n_tests = 10000\n",
    "\n",
    "scores = []\n",
    "targets = []\n",
    "portfolio_target_ratios = []\n",
    "initial_investments = []\n",
    "\n",
    "for i in trange(n_tests):\n",
    "    state = agent.env.reset(visualize=False,mode=\"test\")\n",
    "    step = 0\n",
    "    score = 0\n",
    "    reward = 0\n",
    "    done = False\n",
    "    \n",
    "    targets.append((agent.env.episode_target-agent.env.initial_investment)/agent.env.initial_investment)\n",
    "    initial_investments.append(agent.env.initial_investment)\n",
    "\n",
    "    while not done:\n",
    "        agent.env.render()\n",
    "        #state = np.expand_dims(state, axis=0)\n",
    "        action, action_onehot, prediction = agent.act(state)\n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        next_state, reward, done, info = agent.env.step(action)\n",
    "        #print(action, reward, agent.env.portfolio_value)\n",
    "        # Memorize (state, action, reward) for training\n",
    "        #self.buffer.remember(np.expand_dims(state, axis=0), action_onehot, reward)\n",
    "        # Update current state\n",
    "        if done :\n",
    "            if agent.env.portfolio_value > agent.env.initial_investment:\n",
    "                success +=1\n",
    "\n",
    "        step+=1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    \n",
    "    # Track scores and ratios\n",
    "    scores.append(score)\n",
    "    portfolio_target_ratios.append(info[\"portfolio_value\"]/info[\"episode_target\"] -1)\n",
    "    \n",
    "    \n",
    "test_results_dataframe = pd.DataFrame([[\n",
    "    n_tests,\n",
    "    str(round(np.mean(scores)*100,3))+'%',\n",
    "    str(round(np.mean(targets)*100,3))+'%',\n",
    "    str(round(np.mean(portfolio_target_ratios)*100,3))+'%',\n",
    "    str(round(min(scores)*100,3))+'%',\n",
    "    str(round(max(scores)*100,3))+'%',\n",
    "    str(round((success/n_tests)*100,3)) +'%'\n",
    "]],\n",
    "    columns=[\n",
    "        '# Blind tests',\n",
    "        '% Average portfolio return', \n",
    "        '% Desired portfolio return', \n",
    "        'Portfolio/Target rate',\n",
    "        '% Historical minimum return',\n",
    "        '% Historical maximum return', \n",
    "        '% Episodes concluded with positive outcome'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_results_dataframe.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af1906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:59:54.212867Z",
     "start_time": "2022-08-09T02:59:54.212867Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.results_writer.store_test_results(agent,test_results_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d48752",
   "metadata": {},
   "source": [
    "### Visual test\n",
    "* Runs a set of episodes with unseen data\n",
    "* See the evolution in real time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec44557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T02:59:54.213867Z",
     "start_time": "2022-08-09T02:59:54.213867Z"
    }
   },
   "outputs": [],
   "source": [
    "success = 0\n",
    "n_tests = 2\n",
    "\n",
    "scores = []\n",
    "targets = []\n",
    "\n",
    "\n",
    "for i in trange(n_tests):\n",
    "    state = agent.env.reset(visualize=True,mode=\"test\")\n",
    "    step = 0\n",
    "    score = 0\n",
    "    reward = 0\n",
    "    done = False\n",
    "    targets.append((agent.env.episode_target-agent.env.initial_investment)/agent.env.initial_investment)\n",
    "    initial_portfolio = agent.env.portfolio_value\n",
    "\n",
    "    while not done:\n",
    "        agent.env.render()\n",
    "        #state = np.expand_dims(state, axis=0)\n",
    "        action, action_onehot, prediction = agent.act(state)\n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        next_state, reward, done, _ = agent.env.step(action)\n",
    "        #print(action, reward, agent.env.portfolio_value)\n",
    "        # Memorize (state, action, reward) for training\n",
    "        #self.buffer.remember(np.expand_dims(state, axis=0), action_onehot, reward)\n",
    "        # Update current state\n",
    "        if done :\n",
    "            if agent.env.portfolio_value > agent.env.initial_investment:\n",
    "                success +=1\n",
    "\n",
    "        step+=1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    \n",
    "    #print(score,initial_portfolio, agent.env.portfolio_value)\n",
    "    scores.append(score)\n",
    "\n",
    "agent.env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
