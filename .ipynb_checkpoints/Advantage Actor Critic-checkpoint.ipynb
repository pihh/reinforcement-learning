{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4ca577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:16:20.394234Z",
     "start_time": "2022-08-01T19:16:20.364168Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36625620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:16:24.787963Z",
     "start_time": "2022-08-01T19:16:20.396181Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from src.agents.agent import Agent\n",
    "from src.utils.buffer import Buffer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca7b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "258a1df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T21:05:51.890187Z",
     "start_time": "2022-08-01T21:05:51.871030Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.networks import CommonLayer\n",
    "\n",
    "class ActorNetwork():\n",
    "    def __init__(self,\n",
    "                 observation_shape,\n",
    "                 action_space_mode,\n",
    "                 action_bound,\n",
    "                 policy,\n",
    "                 n_actions, \n",
    "                 optimizer=Adam,\n",
    "                 learning_rate=0.01,\n",
    "                 std_bound = [1e-2, 1.0],\n",
    "    ):\n",
    "        \n",
    "        self.observation_shape = observation_shape\n",
    "        self.policy = policy\n",
    "        self.n_actions = n_actions\n",
    "        self.action_space_mode = action_space_mode\n",
    "        self.std_bound=std_bound\n",
    "        self.action_bound = action_bound\n",
    "        \n",
    "        optimizer = optimizer(learning_rate)\n",
    "        \n",
    "        \n",
    "        X_input = Input(shape=self.observation_shape) \n",
    "        X = CommonLayer(X_input,self.policy)\n",
    "        \n",
    "        if self.action_space_mode == \"discrete\":\n",
    "            action = Dense(self.n_actions, activation=\"softmax\", kernel_initializer='he_uniform')(X)\n",
    "            self.model = Model(inputs = X_input, outputs = action)\n",
    "            self.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        else:\n",
    "            mu = Dense(self.n_actions, activation=\"tanh\", kernel_initializer='he_uniform')(X)\n",
    "            mu = Lambda(lambda x: x * self.action_bound)(mu)\n",
    "            sigma = Dense(self.n_actions, activation=\"softplus\", kernel_initializer='he_uniform')(X)\n",
    "            \n",
    "            self.model = Model(inputs = X_input, outputs = Concatenate()([mu,sigma]))\n",
    "            self.model.compile(loss=self.continuous_actor_loss, optimizer=optimizer)\n",
    "    \n",
    "    def log_pdf(self,mu, sigma, action):\n",
    "        std = tf.clip_by_value(sigma, self.std_bound[0], self.std_bound[1])\n",
    "        var = std ** 2\n",
    "        log_policy_pdf = -0.5 * (action - mu) ** 2 / var - 0.5 * tf.math.log(\n",
    "            var * 2 * np.pi\n",
    "        )\n",
    "        return tf.reduce_sum(log_policy_pdf, 1, keepdims=True)\n",
    "    \n",
    "    def continuous_actor_loss(self, y_true, y_pred):\n",
    "        \n",
    "        print('continuous actor loss',y_true)\n",
    "        actions, advantages = y_true[:, :self.n_actions], y_true[:, self.n_actions:]\n",
    "        print('actions',actions)\n",
    "        mu,sigma = y_pred[:,:1], y_pred[:,1:]\n",
    "        log_policy_pdf = self.log_pdf(mu,sigma,actions)\n",
    "        loss_policy = log_policy_pdf * advantages\n",
    "        \n",
    "        return tf.reduce_sum(-loss_policy)\n",
    "    \n",
    "    def act(self,state):\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        if self.action_space_mode == \"discrete\":\n",
    "            prediction = self.model.predict(state)[0]\n",
    "            action = np.random.choice(self.n_actions, p=prediction)\n",
    "            action_onehot = np.zeros([self.n_actions])\n",
    "            action_onehot[action] = 1\n",
    "        else:\n",
    "            prediction = self.model.predict(state)[0]\n",
    "            mu = prediction[0]\n",
    "            sigma = prediction[1]\n",
    "            sigma = np.clip(sigma, self.std_bound[0],self.std_bound[1])\n",
    "            action = np.random.normal(mu, sigma,self.n_actions)\n",
    "            action = np.clip(action, -self.action_bound, self.action_bound)\n",
    "            action_onehot = action\n",
    "        return action, action_onehot, prediction\n",
    "    \n",
    "\n",
    "class CriticNetwork():\n",
    "    def __init__(self,\n",
    "                 observation_shape,\n",
    "                 action_space_mode,\n",
    "                 policy,\n",
    "                 n_actions, \n",
    "                 optimizer=Adam,\n",
    "                 learning_rate=0.01,\n",
    "                 std_bound = [1e-2, 1.0],\n",
    "    ):\n",
    "\n",
    "        self.observation_shape = observation_shape\n",
    "        self.policy = policy\n",
    "        self.n_actions = n_actions\n",
    "        self.action_space_mode = action_space_mode\n",
    "        self.std_bound=std_bound\n",
    "        \n",
    "        optimizer = optimizer(learning_rate)\n",
    "        \n",
    "        X_input = Input(shape=self.observation_shape) \n",
    "        X = CommonLayer(X_input,self.policy)\n",
    "        \n",
    "        value = Dense(1, kernel_initializer='he_uniform')(X)\n",
    "        \n",
    "        self.model = Model(inputs = X_input, outputs = value)\n",
    "        self.model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3cb2c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:36:11.035438Z",
     "start_time": "2022-08-01T19:36:11.029162Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.size = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.size = 0\n",
    "        self.states.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "\n",
    "    def remember(self, state, action_onehot, reward ):\n",
    "        self.size +=1\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action_onehot)\n",
    "        self.rewards.append(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "456dff8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T21:05:54.198032Z",
     "start_time": "2022-08-01T21:05:54.166054Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.agents.agent import Agent\n",
    "from src.utils.networks import CommonLayer\n",
    "    \n",
    "\n",
    "class A2CAgent(Agent):\n",
    "    def __init__(self,\n",
    "                environment,\n",
    "                gamma = 0.99,\n",
    "                policy=\"mlp\",\n",
    "                actor_optimizer=Adam,\n",
    "                critic_optimizer=Adam,\n",
    "                actor_learning_rate=0.00001,\n",
    "                critic_learning_rate=0.00001,\n",
    "                std_bound = [1e-2, 1.0],\n",
    "                batch_size=64\n",
    "                ):\n",
    "        super(A2CAgent, self).__init__(environment,args=locals())\n",
    "        \n",
    "        # Args\n",
    "        self.gamma = gamma\n",
    "        self.std_bound = std_bound\n",
    "        self.batch_size = batch_size\n",
    "        self.policy = policy \n",
    "        self.actor_optimizer=actor_optimizer\n",
    "        self.critic_optimizer=critic_optimizer\n",
    "        self.actor_learning_rate= actor_learning_rate\n",
    "        self.critic_learning_rate=critic_learning_rate\n",
    "\n",
    "        # Bootstrap\n",
    "        self.__init_networks()\n",
    "        self.__init_buffers()\n",
    "        self._add_models_to_config([self.actor.model,self.critic.model])\n",
    "        self._init_tensorboard()\n",
    "        \n",
    "    def __init_networks(self):\n",
    "        self.actor = ActorNetwork(\n",
    "            observation_shape=self.observation_shape,\n",
    "            action_space_mode=self.action_space_mode,\n",
    "            policy=self.policy,\n",
    "            n_actions=self.n_actions, \n",
    "            optimizer=self.actor_optimizer,\n",
    "            learning_rate=self.actor_learning_rate,\n",
    "            std_bound = self.std_bound,\n",
    "            action_bound = self.action_bound\n",
    "        )\n",
    "        \n",
    "        self.critic = CriticNetwork(\n",
    "            observation_shape=self.observation_shape,\n",
    "            action_space_mode=self.action_space_mode,\n",
    "            policy=self.policy,\n",
    "            n_actions=self.n_actions, \n",
    "            optimizer=self.critic_optimizer,\n",
    "            learning_rate=self.critic_learning_rate,\n",
    "            std_bound = self.std_bound\n",
    "        )\n",
    "    \n",
    "    def __init_buffers(self):\n",
    "        self.buffer = ReplayBuffer()\n",
    "        \n",
    "\n",
    "    def act(self,state):\n",
    "        action, action_onehot, prediction = self.actor.act(state)\n",
    "        return action, action_onehot, prediction\n",
    "    \n",
    "    def discount_rewards(self, reward):\n",
    "        # Compute the gamma-discounted rewards over an episode\n",
    "        running_add = 0\n",
    "        discounted_r = np.zeros_like(reward)\n",
    "        for i in reversed(range(0,len(reward))):\n",
    "            running_add = running_add * self.gamma + reward[i]\n",
    "            discounted_r[i] = running_add\n",
    "\n",
    "        discounted_r -= np.mean(discounted_r) # normalizing the result\n",
    "        discounted_r /= (np.std(discounted_r) + 1e-8) # divide by standard deviation\n",
    "        \n",
    "        return discounted_r\n",
    "    \n",
    "    def replay(self):\n",
    "\n",
    "        if self.buffer.size > 1:\n",
    "            # reshape memory to appropriate shape for training\n",
    "            states = np.vstack(self.buffer.states)\n",
    "            actions = np.vstack(self.buffer.actions)\n",
    "\n",
    "            # Compute discounted rewards\n",
    "            discounted_r = self.discount_rewards(self.buffer.rewards)\n",
    "\n",
    "            # Get Critic network predictions\n",
    "            values = self.critic.model.predict(states)[:, 0]\n",
    "            # Compute advantages\n",
    "            advantages = discounted_r - values\n",
    "            # training Actor and Critic networks\n",
    "\n",
    "\n",
    "            if self.action_space_mode == \"discrete\":\n",
    "                self.actor.model.fit(states, actions, sample_weight=advantages, epochs=1, verbose=0)\n",
    "            else:\n",
    "                \n",
    "                print(np.array(actions).shape)\n",
    "                print(np.array(advantages).shape)\n",
    "                #print(np.reshape(advantages,newshape=(len(advantages),1)))\n",
    "                print(np.concatenate([actions,np.reshape(advantages,newshape=(len(advantages),1))],axis=1).shape)\n",
    "                print()\n",
    "                self.actor.model.fit(states,np.concatenate([actions,np.reshape(advantages,newshape=(len(advantages),1))],axis=1), epochs=1,verbose=0)\n",
    "\n",
    "            self.critic.model.fit(states, discounted_r, epochs=1, verbose=0)\n",
    "            # reset training memory\n",
    "            self.buffer.reset()\n",
    "        \n",
    "    def learn(self, timesteps=-1, plot_results=True, reset=False, success_threshold=False, log_level=1, log_each_n_episodes=50):\n",
    "        self.validate_learn(timesteps,success_threshold,reset)\n",
    "        success_threshold = success_threshold if success_threshold else self.env.success_threshold\n",
    " \n",
    "        timestep = 0\n",
    "        episode = 0\n",
    "        \n",
    "        while self.learning_condition(timesteps,timestep):  # Run until solved\n",
    "            state = self.env.reset()\n",
    "            score = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                \n",
    "                #state = np.expand_dims(state, axis=0)\n",
    "                action, action_onehot, prediction = self.act(state)\n",
    "                # Retrieve new state, reward, and whether the state is terminal\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                # Memorize (state, action, reward) for training\n",
    "                self.buffer.remember(np.expand_dims(state, axis=0), action_onehot, reward)\n",
    "                # Update current state\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                timestep +=1\n",
    "                \n",
    "                if self.buffer.size >= self.batch_size:\n",
    "                    self.replay()\n",
    "            \n",
    "            # Episode ended\n",
    "            episode +=1\n",
    "            \n",
    "            # Step reward, tensorboard log score, print progress\n",
    "            self.on_learn_episode_end(score,log_each_n_episodes,log_level,success_threshold)\n",
    "            \n",
    "            # If done stop\n",
    "            if self.did_finnish_learning(success_threshold,episode):\n",
    "                break\n",
    "                \n",
    "            # Else learn more\n",
    "            self.replay()\n",
    "        \n",
    "        # End of trainig\n",
    "        self.env.close()\n",
    "        \n",
    "        if plot_results:\n",
    "            self.plot_learning_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1076056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:16:24.851994Z",
     "start_time": "2022-08-01T19:16:24.836948Z"
    }
   },
   "outputs": [],
   "source": [
    "# from src.environments.discrete.cartpole import environment\n",
    "# agent = A2CAgent(environment)\n",
    "# agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21a3f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:29:16.686565Z",
     "start_time": "2022-08-01T19:20:17.596526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    | ---------------------------------\n",
      "    | InvertedPendulumBulletEnv-v0\n",
      "    | \n",
      "    | Action space: Continuous with high action-space\n",
      "    | Environment beated threshold: 200\n",
      "    | Dev notes:\n",
      "    |   * Doesn't work with multiprocessing\n",
      "    | ----------------------------------------------------------   \n",
      "\n",
      "    \n",
      "Episode * 100 * Worker * False * Moving Avg Reward is ==> 22.620 * Last Reward was ==> 15.000\n",
      "Episode * 200 * Worker * False * Moving Avg Reward is ==> 25.720 * Last Reward was ==> 20.000\n",
      "Episode * 300 * Worker * False * Moving Avg Reward is ==> 25.220 * Last Reward was ==> 29.000\n",
      "Episode * 400 * Worker * False * Moving Avg Reward is ==> 24.900 * Last Reward was ==> 60.000\n",
      "Episode * 500 * Worker * False * Moving Avg Reward is ==> 24.660 * Last Reward was ==> 16.000\n",
      "Episode * 600 * Worker * False * Moving Avg Reward is ==> 26.620 * Last Reward was ==> 17.000\n",
      "Episode * 700 * Worker * False * Moving Avg Reward is ==> 24.720 * Last Reward was ==> 19.000\n",
      "Episode * 800 * Worker * False * Moving Avg Reward is ==> 25.120 * Last Reward was ==> 32.000\n",
      "Episode * 900 * Worker * False * Moving Avg Reward is ==> 23.440 * Last Reward was ==> 10.000\n",
      "Episode * 1000 * Worker * False * Moving Avg Reward is ==> 27.100 * Last Reward was ==> 43.000\n",
      "Episode * 1100 * Worker * False * Moving Avg Reward is ==> 27.480 * Last Reward was ==> 11.000\n",
      "Episode * 1200 * Worker * False * Moving Avg Reward is ==> 27.740 * Last Reward was ==> 30.000\n",
      "Episode * 1300 * Worker * False * Moving Avg Reward is ==> 26.700 * Last Reward was ==> 30.000\n",
      "Episode * 1400 * Worker * False * Moving Avg Reward is ==> 27.760 * Last Reward was ==> 21.000\n",
      "Episode * 1500 * Worker * False * Moving Avg Reward is ==> 29.800 * Last Reward was ==> 12.000\n",
      "Episode * 1600 * Worker * False * Moving Avg Reward is ==> 29.620 * Last Reward was ==> 20.000\n",
      "Episode * 1700 * Worker * False * Moving Avg Reward is ==> 35.680 * Last Reward was ==> 12.000\n",
      "Episode * 1800 * Worker * False * Moving Avg Reward is ==> 34.500 * Last Reward was ==> 73.000\n",
      "Episode * 1900 * Worker * False * Moving Avg Reward is ==> 30.940 * Last Reward was ==> 16.000\n",
      "Episode * 2000 * Worker * False * Moving Avg Reward is ==> 29.220 * Last Reward was ==> 45.000\n",
      "Episode * 2100 * Worker * False * Moving Avg Reward is ==> 34.520 * Last Reward was ==> 60.000\n",
      "Episode * 2200 * Worker * False * Moving Avg Reward is ==> 40.220 * Last Reward was ==> 26.000\n",
      "Episode * 2300 * Worker * False * Moving Avg Reward is ==> 38.180 * Last Reward was ==> 57.000\n",
      "Episode * 2400 * Worker * False * Moving Avg Reward is ==> 37.340 * Last Reward was ==> 28.000\n",
      "Episode * 2500 * Worker * False * Moving Avg Reward is ==> 36.860 * Last Reward was ==> 41.000\n",
      "Episode * 2600 * Worker * False * Moving Avg Reward is ==> 39.860 * Last Reward was ==> 48.000\n",
      "Episode * 2700 * Worker * False * Moving Avg Reward is ==> 38.120 * Last Reward was ==> 21.000\n",
      "Episode * 2800 * Worker * False * Moving Avg Reward is ==> 38.860 * Last Reward was ==> 26.000\n",
      "Episode * 2900 * Worker * False * Moving Avg Reward is ==> 38.920 * Last Reward was ==> 106.000\n",
      "Episode * 3000 * Worker * False * Moving Avg Reward is ==> 36.600 * Last Reward was ==> 21.000\n",
      "Episode * 3100 * Worker * False * Moving Avg Reward is ==> 45.980 * Last Reward was ==> 17.000\n",
      "Episode * 3200 * Worker * False * Moving Avg Reward is ==> 43.760 * Last Reward was ==> 45.000\n",
      "Episode * 3300 * Worker * False * Moving Avg Reward is ==> 42.960 * Last Reward was ==> 25.000\n",
      "Episode * 3400 * Worker * False * Moving Avg Reward is ==> 42.520 * Last Reward was ==> 55.000\n",
      "Episode * 3500 * Worker * False * Moving Avg Reward is ==> 47.400 * Last Reward was ==> 89.000\n",
      "Episode * 3600 * Worker * False * Moving Avg Reward is ==> 47.260 * Last Reward was ==> 32.000\n",
      "Episode * 3700 * Worker * False * Moving Avg Reward is ==> 43.480 * Last Reward was ==> 23.000\n",
      "Episode * 3800 * Worker * False * Moving Avg Reward is ==> 52.100 * Last Reward was ==> 20.000\n",
      "Episode * 3900 * Worker * False * Moving Avg Reward is ==> 42.180 * Last Reward was ==> 31.000\n",
      "Episode * 4000 * Worker * False * Moving Avg Reward is ==> 54.780 * Last Reward was ==> 65.000\n",
      "Episode * 4100 * Worker * False * Moving Avg Reward is ==> 49.220 * Last Reward was ==> 36.000\n",
      "Episode * 4200 * Worker * False * Moving Avg Reward is ==> 57.560 * Last Reward was ==> 88.000\n",
      "Episode * 4300 * Worker * False * Moving Avg Reward is ==> 54.460 * Last Reward was ==> 50.000\n",
      "Episode * 4400 * Worker * False * Moving Avg Reward is ==> 59.260 * Last Reward was ==> 85.000\n",
      "Episode * 4500 * Worker * False * Moving Avg Reward is ==> 70.420 * Last Reward was ==> 92.000\n",
      "Episode * 4600 * Worker * False * Moving Avg Reward is ==> 74.460 * Last Reward was ==> 70.000\n",
      "Episode * 4700 * Worker * False * Moving Avg Reward is ==> 67.440 * Last Reward was ==> 69.000\n",
      "Episode * 4800 * Worker * False * Moving Avg Reward is ==> 80.900 * Last Reward was ==> 84.000\n",
      "Episode * 4900 * Worker * False * Moving Avg Reward is ==> 80.940 * Last Reward was ==> 70.000\n",
      "Episode * 5000 * Worker * False * Moving Avg Reward is ==> 83.280 * Last Reward was ==> 28.000\n",
      "Episode * 5100 * Worker * False * Moving Avg Reward is ==> 85.440 * Last Reward was ==> 86.000\n",
      "Episode * 5200 * Worker * False * Moving Avg Reward is ==> 79.920 * Last Reward was ==> 131.000\n",
      "Episode * 5300 * Worker * False * Moving Avg Reward is ==> 93.220 * Last Reward was ==> 184.000\n",
      "Episode * 5400 * Worker * False * Moving Avg Reward is ==> 112.880 * Last Reward was ==> 91.000\n",
      "Episode * 5500 * Worker * False * Moving Avg Reward is ==> 99.540 * Last Reward was ==> 75.000\n",
      "Episode * 5600 * Worker * False * Moving Avg Reward is ==> 111.840 * Last Reward was ==> 109.000\n",
      "Episode * 5700 * Worker * False * Moving Avg Reward is ==> 107.360 * Last Reward was ==> 149.000\n",
      "Episode * 5800 * Worker * False * Moving Avg Reward is ==> 116.900 * Last Reward was ==> 241.000\n",
      "Episode * 5900 * Worker * False * Moving Avg Reward is ==> 136.080 * Last Reward was ==> 182.000\n",
      "Episode * 6000 * Worker * False * Moving Avg Reward is ==> 130.360 * Last Reward was ==> 212.000\n",
      "Episode * 6100 * Worker * False * Moving Avg Reward is ==> 137.220 * Last Reward was ==> 196.000\n",
      "Episode * 6200 * Worker * False * Moving Avg Reward is ==> 163.400 * Last Reward was ==> 137.000\n",
      "Episode * 6300 * Worker * False * Moving Avg Reward is ==> 152.480 * Last Reward was ==> 112.000\n",
      "Episode * 6400 * Worker * False * Moving Avg Reward is ==> 152.520 * Last Reward was ==> 111.000\n",
      "Episode * 6500 * Worker * False * Moving Avg Reward is ==> 166.540 * Last Reward was ==> 125.000\n",
      "Agent solved environment at the episode 6593\n",
      "Agent solved environment at the episode 6593\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.environments.continuous.inverted_pendulum import environment\n",
    "agent = A2CAgent(environment,batch_size=1024)\n",
    "agent.learn(log_each_n_episodes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13e54eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T21:05:58.685611Z",
     "start_time": "2022-08-01T21:05:57.326350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    | ---------------------------------\n",
      "    | LunarLanderContinuous-v2\n",
      "    | \n",
      "    | Action space: Continuous with low state-space\n",
      "    | Environment beated threshold: 200\n",
      "    | ----------------------------------------------------------   \n",
      "\n",
      "    \n",
      "continuous actor loss\n",
      "(62, 2)\n",
      "(62,)\n",
      "(62, 3)\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) INVALID_ARGUMENT: required broadcastable shapes\n\t [[{{node loss_32/concatenate_16_loss/truediv}}]]\n\t [[loss_32/mul/_977]]\n  (1) INVALID_ARGUMENT: required broadcastable shapes\n\t [[{{node loss_32/concatenate_16_loss/truediv}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunarlander\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m environment\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m A2CAgent(environment)\n\u001b[1;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36mA2CAgent.learn\u001b[1;34m(self, timesteps, plot_results, reset, success_threshold, log_level, log_each_n_episodes)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# Else learn more\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# End of trainig\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36mA2CAgent.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate([actions,np\u001b[38;5;241m.\u001b[39mreshape(advantages,newshape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(advantages),\u001b[38;5;241m1\u001b[39m))],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43madvantages\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnewshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43madvantages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(states, discounted_r, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# reset training memory\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_v1.py:777\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    776\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:641\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    638\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    639\u001b[0m   val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:377\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_index, batch_logs)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    379\u001b[0m   batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\backend.py:4275\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4270\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4271\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   4272\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[0;32m   4273\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4275\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4276\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[0;32m   4278\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4280\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4281\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1483\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1484\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT: required broadcastable shapes\n\t [[{{node loss_32/concatenate_16_loss/truediv}}]]\n\t [[loss_32/mul/_977]]\n  (1) INVALID_ARGUMENT: required broadcastable shapes\n\t [[{{node loss_32/concatenate_16_loss/truediv}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "from src.environments.continuous.lunarlander import environment\n",
    "agent = A2CAgent(environment)\n",
    "agent.learn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c314715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:42:14.451464Z",
     "start_time": "2022-08-01T19:42:14.436664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2]])\n",
    "b = np.array([2])\n",
    "b = np.reshape(b,newshape=(len(b),1,))\n",
    "#np.concatenate([a,b],axis=1)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef80a84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:30:02.323997Z",
     "start_time": "2022-08-01T19:30:02.317030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.A2CAgent at 0x2e34e9ef820>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d265be5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:30:07.556627Z",
     "start_time": "2022-08-01T19:30:07.548657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00497074,  1.412474  ,  0.50346166,  0.06904994, -0.00575301,\n",
       "       -0.11404153,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57399f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:30:16.884014Z",
     "start_time": "2022-08-01T19:30:16.861048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.07942333, -0.01143934]),\n",
       " array([-0.07942333, -0.01143934]),\n",
       " array([-0.0979802 ,  0.1297103 ,  0.70620465,  0.68679947], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.act(agent.env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04c5d79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T19:30:39.694690Z",
     "start_time": "2022-08-01T19:30:39.685296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85631824, 0.32485986], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94113253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T20:58:14.656478Z",
     "start_time": "2022-08-01T20:58:14.646038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.],\n",
       "       [2., 2.],\n",
       "       [3., 3.],\n",
       "       [4., 4.],\n",
       "       [5., 5.],\n",
       "       [6., 6.],\n",
       "       [7., 7.],\n",
       "       [8., 8.],\n",
       "       [9., 9.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(shape=(10,2))*[[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
