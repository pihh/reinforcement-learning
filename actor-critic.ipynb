{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4ca577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:57:41.698328Z",
     "start_time": "2022-07-22T09:57:41.675103Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36625620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:57:45.402918Z",
     "start_time": "2022-07-22T09:57:41.701328Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.agents.agent import Agent\n",
    "from src.utils.buffer import Buffer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8743d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:57:45.433884Z",
     "start_time": "2022-07-22T09:57:45.404918Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActorCriticAgent(Agent):\n",
    "    def __init__(self, \n",
    "                environment, \n",
    "                alpha = 0.01,\n",
    "                gamma = 0.99,\n",
    "                eps = np.finfo(np.float32).eps.item(),\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                critic_loss= tf.keras.losses.Huber()):\n",
    "        \n",
    "        super(ActorCriticAgent, self).__init__(environment)\n",
    "        \n",
    "        # Args\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma \n",
    "        self.eps = eps \n",
    "        self.optimizer=optimizer\n",
    "        self.critic_loss = critic_loss\n",
    "        #type(tf.keras.optimizers.Adam(learning_rate=0.01)).__name__\n",
    "\n",
    "        self.__init_networks()\n",
    "        self.__init_buffers()\n",
    "        \n",
    "    def __init_buffers(self):\n",
    "        self.buffer = Buffer(['action_log_probs','critic_values','rewards'])\n",
    "            \n",
    "    def __init_networks(self):\n",
    "        num_inputs = self.observation_shape[0]\n",
    "        num_hidden = 128\n",
    "\n",
    "        inputs = Input(shape=(num_inputs,),name=\"actor_critic_inputs\")\n",
    "        common_layer = Dense(num_hidden, activation=\"relu\", name=\"actor_critic_common_layer\")(inputs)\n",
    "        \n",
    "        if self.action_space_mode == \"discrete\":\n",
    "            action = Dense(self.n_actions, activation=\"softmax\")(common_layer)\n",
    "        elif self.action_space_mode == \"continuous\":\n",
    "            mu_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "            mu = Dense(self.n_actions, activation=\"tanh\" , name='mu',kernel_initializer=mu_init)(common_layer)\n",
    "            \n",
    "            sigma_init = tf.random_uniform_initializer(minval=self.eps, maxval=0.2)\n",
    "            sigma = Dense(self.n_actions, activation=\"softplus\", name=\"sigma\", kernel_initializer=sigma_init)(common_layer)\n",
    "            \n",
    "            action = Concatenate(axis=-1, name=\"actor_output\")([mu,sigma]) * self.action_upper_bounds\n",
    "\n",
    "        critic = Dense(1)(common_layer)\n",
    "\n",
    "        self.model = keras.Model(inputs=inputs, outputs=[action, critic])\n",
    "\n",
    "    def choose_action(self, state, deterministic=True):\n",
    "        action_probs, critic_value = self.model(state)\n",
    "        \n",
    "        if self.action_space_mode == \"discrete\":\n",
    "            # DISCRETE SAMPLING\n",
    "            if deterministic:\n",
    "                action = np.argmax(np.squeeze(action_probs))\n",
    "                action_log_prob = action\n",
    "            else:\n",
    "                # Sample action from action probability distribution\n",
    "                action = np.random.choice(self.n_actions, p=np.squeeze(action_probs))\n",
    "                action_log_prob = tf.math.log(action_probs[0, action])\n",
    "\n",
    "\n",
    "        elif self.action_space_mode == \"continuous\":\n",
    "            # CONTINUOUS SAMPLING\n",
    "            mu = action_probs[:,0:self.n_actions]\n",
    "            sigma = action_probs[:,self.n_actions:]\n",
    "            \n",
    "            if deterministic:\n",
    "                action = mu\n",
    "                action_log_prob = action\n",
    "            else:\n",
    "                norm_dist = tfp.distributions.Normal(mu, sigma)\n",
    "                action = tf.squeeze(norm_dist.sample(self.n_actions), axis=0)\n",
    "                action_log_prob = -(norm_dist.log_prob(action)+self.eps)\n",
    "                action = tf.clip_by_value(\n",
    "                    action, self.env.action_space.low[0], \n",
    "                    self.env.action_space.high[0])\n",
    "\n",
    "                action = np.array(action[0],dtype=np.float32)\n",
    "        \n",
    "        return action, action_log_prob , critic_value\n",
    "    \n",
    "    def test(self, episodes=10, render=True):\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            score = 0\n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                \n",
    "                state = tf.convert_to_tensor(state)\n",
    "                state = tf.expand_dims(state, 0)\n",
    "                \n",
    "                # Sample action, probs and critic\n",
    "                action, action_log_prob, critic_value = self.choose_action(state)\n",
    "\n",
    "                # Step\n",
    "                state,reward,done, info = self.env.step(action)\n",
    "\n",
    "                # Get next state\n",
    "                score += reward\n",
    "            \n",
    "            if render:\n",
    "                self.env.close()\n",
    "\n",
    "            print(\"Test episode: {}, score: {:.2f}\".format(episode,score))\n",
    "    \n",
    "    def learn(self, timesteps=-1, plot_results=True, reset=False, log_each_n_episodes=100, success_threshold=False):\n",
    "        \n",
    "        self.validate_learn(timesteps,success_threshold,reset)\n",
    "        success_threshold = success_threshold if success_threshold else self.env.success_threshold\n",
    " \n",
    "        self.buffer.reset()\n",
    "        score = 0\n",
    "        timestep = 0\n",
    "        episode = 0\n",
    "        \n",
    "        while self.learning_condition(timesteps,timestep):  # Run until solved\n",
    "            state = self.env.reset()\n",
    "            score = 0\n",
    "            done = False\n",
    "            with tf.GradientTape() as tape:\n",
    "                while not done:\n",
    "\n",
    "                    state = tf.convert_to_tensor(state)\n",
    "                    state = tf.expand_dims(state, 0)\n",
    "\n",
    "                    # Predict action probabilities and estimated future rewards\n",
    "                    # from environment state\n",
    "                    action, action_log_prob, critic_value = self.choose_action(state, deterministic=False)\n",
    "\n",
    "                    self.buffer.store('critic_values',critic_value[0, 0])\n",
    "\n",
    "                    # Sample action from action probability distribution\n",
    "                    self.buffer.store('action_log_probs',action_log_prob)\n",
    "\n",
    "                    # Apply the sampled action in our environment\n",
    "                    state, reward, done, _ = self.env.step(action)\n",
    "                    self.buffer.store('rewards',reward)\n",
    "\n",
    "                    score += reward\n",
    "                    timestep+=1\n",
    "                # Update running reward to check condition for solving\n",
    "                self.running_reward.step(score)\n",
    "\n",
    "                # Time discounted rewards\n",
    "                returns = []\n",
    "                discounted_sum = 0\n",
    "                \n",
    "                for r in self.buffer.get('rewards')[::-1]:\n",
    "                    discounted_sum = r + self.gamma * discounted_sum\n",
    "                    returns.insert(0, discounted_sum)\n",
    "\n",
    "                # Normalize\n",
    "                returns = np.array(returns)\n",
    "                returns = (returns - np.mean(returns)) / (np.std(returns) + self.eps)\n",
    "                returns = returns.tolist()\n",
    "\n",
    "                # Calculating loss values to update our network\n",
    "                history = zip(self.buffer.get('action_log_probs'), self.buffer.get('critic_values'), returns)\n",
    "                actor_losses = []\n",
    "                critic_losses = []\n",
    "                for log_prob, value, ret in history:\n",
    "                    # At this point in history, the critic estimated that we would get a\n",
    "                    # total reward = `value` in the future. We took an action with log probability\n",
    "                    # of `log_prob` and ended up recieving a total reward = `ret`.\n",
    "                    # The actor must be updated so that it predicts an action that leads to\n",
    "                    # high rewards (compared to critic's estimate) with high probability.\n",
    "                    diff = ret - value\n",
    "                    actor_losses.append(-log_prob * diff)  # actor loss\n",
    "\n",
    "                    # The critic must be updated so that it predicts a better estimate of\n",
    "                    # the future rewards.\n",
    "                    critic_losses.append(\n",
    "                        self.critic_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
    "                    )\n",
    "\n",
    "                # Backpropagation\n",
    "                loss_value = sum(actor_losses) + sum(critic_losses)\n",
    "                #print(loss_value)\n",
    "                grads = tape.gradient(loss_value, self.model.trainable_variables)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "                # Clear the loss and reward history\n",
    "                self.buffer.reset()\n",
    "\n",
    "            # Log details\n",
    "            episode += 1\n",
    "            if episode % log_each_n_episodes == 0 and episode > 0:\n",
    "                print('episode {}, running reward: {:.2f}, last reward: {:.2f}'.format(episode,self.running_reward.reward, score))\n",
    "\n",
    "            if self.did_finnish_learning(success_threshold,episode):\n",
    "                    break\n",
    "\n",
    "        if plot_results:\n",
    "            self.plot_learning_results()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62df8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:13:15.069892Z",
     "start_time": "2022-07-22T09:12:12.772446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| ---------------------------------\n",
      "| CartPole-v1\n",
      "| Action space: Discrete with high state-space\n",
      "| Environment beated threshold: 200\n",
      "| Dev notes:\n",
      "|   * Agents that track State/Action combinations like \n",
      "|     Q learning will fail due to high state space\n",
      "| ----------------------------------------------------------   \n",
      "\n",
      "\n",
      "episode 10, running reward: 9.60\n",
      "episode 20, running reward: 10.78\n",
      "episode 30, running reward: 14.09\n",
      "episode 40, running reward: 13.12\n",
      "episode 50, running reward: 12.54\n",
      "episode 60, running reward: 16.22\n",
      "episode 70, running reward: 22.04\n",
      "episode 80, running reward: 40.72\n",
      "episode 90, running reward: 84.90\n",
      "episode 100, running reward: 114.00\n",
      "Agent solved environment at the episode 109\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.environments.discrete.cartpole import environment\n",
    "agent_discrete = ActorCriticAgent(environment)\n",
    "agent_discrete.learn(log_each_n_episodes=10)\n",
    "\n",
    "#{'action': 0, 'action_log_prob': <tf.Tensor: shape=(), dtype=float32, numpy=-0.6900733>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9127be71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:08:51.925079Z",
     "start_time": "2022-07-22T09:08:45.284415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode: 0, score: 500.00\n",
      "Test episode: 1, score: 500.00\n",
      "Test episode: 2, score: 500.00\n",
      "Test episode: 3, score: 500.00\n",
      "Test episode: 4, score: 500.00\n",
      "Test episode: 5, score: 500.00\n",
      "Test episode: 6, score: 500.00\n",
      "Test episode: 7, score: 500.00\n",
      "Test episode: 8, score: 500.00\n",
      "Test episode: 9, score: 500.00\n"
     ]
    }
   ],
   "source": [
    "agent_discrete.test(render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f75f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9a22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c3c599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:58:13.982014Z",
     "start_time": "2022-07-22T09:57:50.348529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| ---------------------------------\n",
      "| MountainCarContinuous-v0\n",
      "| \n",
      "| Action space: Continuous with low state-space\n",
      "| Environment beated threshold: -150\n",
      "| Dev notes:\n",
      "|   * Switched _max_episode_steps from 200 to 1000 so \n",
      "|     the agent can explore better.\n",
      "| ----------------------------------------------------------   \n",
      "\n",
      "\n",
      "episode 1, running reward: -2.24, last reward: -44.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmountain_car\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m environment\n\u001b[0;32m      3\u001b[0m agent_continuous \u001b[38;5;241m=\u001b[39m ActorCriticAgent(environment,optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43magent_continuous\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_each_n_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mActorCriticAgent.learn\u001b[1;34m(self, timesteps, plot_results, reset, log_each_n_episodes, success_threshold)\u001b[0m\n\u001b[0;32m    127\u001b[0m state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(state, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Predict action probabilities and estimated future rewards\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# from environment state\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m action, action_log_prob, critic_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mstore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritic_values\u001b[39m\u001b[38;5;124m'\u001b[39m,critic_value[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Sample action from action probability distribution\u001b[39;00m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mActorCriticAgent.choose_action\u001b[1;34m(self, state, deterministic)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     norm_dist \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(mu, sigma)\n\u001b[1;32m---> 72\u001b[0m     action \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mnorm_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_actions\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m     action_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(norm_dist\u001b[38;5;241m.\u001b[39mlog_prob(action)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n\u001b[0;32m     74\u001b[0m     action \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mclip_by_value(\n\u001b[0;32m     75\u001b[0m         action, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow[\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1234\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[1;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[1;32m-> 1234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_sample_n(sample_shape, seed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1211\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[1;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[0;32m   1207\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[0;32m   1208\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1209\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[0;32m   1210\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1211\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_n(\n\u001b[0;32m   1212\u001b[0m     n, seed\u001b[38;5;241m=\u001b[39mseed() \u001b[38;5;28;01mif\u001b[39;00m callable(seed) \u001b[38;5;28;01melse\u001b[39;00m seed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m   1215\u001b[0m     samples)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\normal.py:177\u001b[0m, in \u001b[0;36mNormal._sample_n\u001b[1;34m(self, n, seed)\u001b[0m\n\u001b[0;32m    175\u001b[0m loc \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc)\n\u001b[0;32m    176\u001b[0m scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale)\n\u001b[1;32m--> 177\u001b[0m shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconcat([[n], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[0;32m    178\u001b[0m                   axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    179\u001b[0m sampled \u001b[38;5;241m=\u001b[39m samplers\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[0;32m    180\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, stddev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled \u001b[38;5;241m*\u001b[39m scale \u001b[38;5;241m+\u001b[39m loc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1013\u001b[0m, in \u001b[0;36mDistribution._batch_shape_tensor\u001b[1;34m(self, **parameter_kwargs)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03m\"\"\"Infers batch shape from parameters.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03mThe overall batch shape is inferred by broadcasting the batch shapes of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03m  batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1013\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m batch_shape_lib\u001b[38;5;241m.\u001b[39minferred_batch_shape_tensor(\n\u001b[0;32m   1014\u001b[0m       \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_kwargs)\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1016\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot compute batch shape of distribution \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1017\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: you must implement at least one of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1018\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`_batch_shape_tensor` or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1019\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`_parameter_properties`.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:110\u001b[0m, in \u001b[0;36minferred_batch_shape_tensor\u001b[1;34m(batch_object, bijector_x_event_ndims, **parameter_kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minferred_batch_shape_tensor\u001b[39m(batch_object,\n\u001b[0;32m     79\u001b[0m                                 bijector_x_event_ndims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m                                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_kwargs):\n\u001b[0;32m     81\u001b[0m   \u001b[38;5;124;03m\"\"\"Infers an object's batch shape from its  parameters.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m  Each parameter contributes a batch shape of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m   batch_shapes \u001b[38;5;241m=\u001b[39m map_fn_over_parameters_with_event_ndims(\n\u001b[0;32m    111\u001b[0m       batch_object,\n\u001b[0;32m    112\u001b[0m       get_batch_shape_tensor_part,\n\u001b[0;32m    113\u001b[0m       bijector_x_event_ndims\u001b[38;5;241m=\u001b[39mbijector_x_event_ndims,\n\u001b[0;32m    114\u001b[0m       require_static\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    115\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_kwargs)\n\u001b[0;32m    116\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mreduce(ps\u001b[38;5;241m.\u001b[39mbroadcast_shape, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(batch_shapes), [])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:361\u001b[0m, in \u001b[0;36mmap_fn_over_parameters_with_event_ndims\u001b[1;34m(batch_object, fn, bijector_x_event_ndims, require_static, **parameter_kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (properties\u001b[38;5;241m.\u001b[39mis_tensor\n\u001b[0;32m    356\u001b[0m           \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(param)\n\u001b[0;32m    357\u001b[0m           \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(param_event_ndims)):\n\u001b[0;32m    358\u001b[0m       \u001b[38;5;66;03m# As a last resort, try an explicit conversion.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m       param \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(param, name\u001b[38;5;241m=\u001b[39mparam_name)\n\u001b[1;32m--> 361\u001b[0m   results[param_name] \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_event_ndims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:1425\u001b[0m, in \u001b[0;36mmap_structure_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.nest.map_structure_up_to\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1353\u001b[0m   \u001b[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;124;03m    `shallow_tree`.\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1425\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m map_structure_with_tuple_paths_up_to(\n\u001b[0;32m   1426\u001b[0m       shallow_tree,\n\u001b[0;32m   1427\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m _, \u001b[38;5;241m*\u001b[39mvalues: func(\u001b[38;5;241m*\u001b[39mvalues),  \u001b[38;5;66;03m# Discards the path arg.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m       \u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1429\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:1525\u001b[0m, in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[1;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m flat_value_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1517\u001b[0m     flatten_up_to(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m         shallow_tree,\n\u001b[0;32m   1519\u001b[0m         input_tree,\n\u001b[0;32m   1520\u001b[0m         check_types,\n\u001b[0;32m   1521\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites) \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m   1522\u001b[0m flat_path_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1523\u001b[0m     path\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[38;5;241m0\u001b[39m], is_nested_fn))\n\u001b[1;32m-> 1525\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1526\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_path_gen, \u001b[38;5;241m*\u001b[39mflat_value_gen)\n\u001b[0;32m   1527\u001b[0m ]\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(structure\u001b[38;5;241m=\u001b[39mshallow_tree, flat_sequence\u001b[38;5;241m=\u001b[39mresults,\n\u001b[0;32m   1529\u001b[0m                         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:1526\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1516\u001b[0m flat_value_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1517\u001b[0m     flatten_up_to(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m         shallow_tree,\n\u001b[0;32m   1519\u001b[0m         input_tree,\n\u001b[0;32m   1520\u001b[0m         check_types,\n\u001b[0;32m   1521\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites) \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m   1522\u001b[0m flat_path_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1523\u001b[0m     path\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001b[38;5;241m0\u001b[39m], is_nested_fn))\n\u001b[0;32m   1525\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1526\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_path_gen, \u001b[38;5;241m*\u001b[39mflat_value_gen)\n\u001b[0;32m   1527\u001b[0m ]\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(structure\u001b[38;5;241m=\u001b[39mshallow_tree, flat_sequence\u001b[38;5;241m=\u001b[39mresults,\n\u001b[0;32m   1529\u001b[0m                         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:1427\u001b[0m, in \u001b[0;36mmap_structure_up_to.<locals>.<lambda>\u001b[1;34m(_, *values)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.nest.map_structure_up_to\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1353\u001b[0m   \u001b[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;124;03m    `shallow_tree`.\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m map_structure_with_tuple_paths_up_to(\n\u001b[0;32m   1426\u001b[0m       shallow_tree,\n\u001b[1;32m-> 1427\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m _, \u001b[38;5;241m*\u001b[39mvalues: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# Discards the path arg.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m       \u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1429\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:139\u001b[0m, in \u001b[0;36mget_batch_shape_tensor_part\u001b[1;34m(x, event_ndims)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m   base_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_truncate_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_ndims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\tensorflow_probability\\python\\internal\\batch_shape_lib.py:180\u001b[0m, in \u001b[0;36m_truncate_shape_tensor\u001b[1;34m(shape, rightmost_ndims_to_truncate)\u001b[0m\n\u001b[0;32m    177\u001b[0m rightmost_ndims_to_truncate \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[0;32m    178\u001b[0m     rightmost_ndims_to_truncate, dtype_hint\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    179\u001b[0m base_rank \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mrank_from_shape(shape)\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_rank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Don't try to slice away more ndims than the parameter\u001b[39;49;00m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# actually has, if that's fewer than `event_ndims` (i.e.,\u001b[39;49;00m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# if it relies on broadcasting).\u001b[39;49;00m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrightmost_ndims_to_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_rank\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1052\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1050\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m   1051\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[1;32m-> 1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1225\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[1;32m-> 1225\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1237\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10664\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m  10663\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 10664\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10665\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10666\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10667\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  10669\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.environments.continuous.inverted_pendulum import environment\n",
    "\n",
    "agent_continuous = ActorCriticAgent(environment,optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "agent_continuous.learn(log_each_n_episodes=1)\n",
    "\n",
    "#{'action': array([0.6679693], dtype=float32), 'action_log_prob': array([1.0068668], dtype=float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f9259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:05:15.264295Z",
     "start_time": "2022-07-22T09:05:15.264295Z"
    }
   },
   "outputs": [],
   "source": [
    "agent_continuous.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d437e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
