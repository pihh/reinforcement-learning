{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f3e48f",
   "metadata": {},
   "source": [
    "### Soft Actor Critic\n",
    "\n",
    "#### Introduction:\n",
    "* Maximizes long term rewards and entropy\n",
    "* Similar to Q learning ( epsilon greedy - some % of the time selects random action )\n",
    "* Entropy modeled by reward scaling ( inv. relationship )\n",
    "* Networks:\n",
    "    * 1 actor network\n",
    "    * 1 value network\n",
    "    * 2 critic networks (like ddqn/td3)\n",
    "* Uses a target value function (soft update)\n",
    "* Has replay buffer\n",
    "\n",
    "#### Sampling:\n",
    "* actor outputs mu and sigma and we use a normal dist from them\n",
    "\n",
    "#### Network updates:\n",
    "* Actor:\n",
    "    * sample states from buffer, compute new actions\n",
    "    * get the minimum of two critics\n",
    "    * log is computed according to the previous slide\n",
    "* Value:\n",
    "    * use value fn (current params) for states\n",
    "    * samples states and computes new actions\n",
    "    * uses minimum value of two critics\n",
    "    * log is computed according to the prev slide\n",
    "* Target:\n",
    "    * Uses a small tau ( 0.005 for ex )\n",
    "    * Slowly moving avg of online and target network\n",
    "* Critic:\n",
    "    * target value fort new states\n",
    "    * sample states and actions\n",
    "    * reward is scaled here\n",
    "\n",
    "#### Limitations:\n",
    "* Only works in continous environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4ca577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:42:29.216833Z",
     "start_time": "2022-07-26T12:42:29.184836Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36625620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:42:33.475767Z",
     "start_time": "2022-07-26T12:42:29.218833Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.agents.agent import Agent\n",
    "from src.utils.buffer import Buffer\n",
    "from src.utils.logger import LearningLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00af9100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:42:33.491035Z",
     "start_time": "2022-07-26T12:42:33.476755Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size, input_shape, n_actions):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer_counter = 0\n",
    "        self.state_memory = np.zeros((self.buffer_size, *input_shape))\n",
    "        self.new_state_memory = np.zeros((self.buffer_size, *input_shape))\n",
    "        self.action_memory = np.zeros((self.buffer_size, n_actions))\n",
    "        self.reward_memory = np.zeros(self.buffer_size)\n",
    "        self.done_memory = np.zeros(self.buffer_size, dtype=np.bool)\n",
    "\n",
    "    def remember(self, state, action, reward, state_, done):\n",
    "        index = self.buffer_counter % self.buffer_size\n",
    "\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.done_memory[index] = done\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        max_mem = min(self.buffer_counter, self.buffer_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, batch_size)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        dones = self.done_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3842083c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:47:54.445735Z",
     "start_time": "2022-07-26T12:47:54.428221Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def MultiLayerPerceptron(policy=\"mlp\"):\n",
    "    layers = []\n",
    "    if type(policy) == str:\n",
    "        if policy == \"mlp\":\n",
    "            layers.append(Dense(256, activation='relu', name=\"mlp_dense_layer_0\"))\n",
    "            layers.append(Dense(256, activation='relu', name=\"mlp_dense_layer_1\"))\n",
    "    else:\n",
    "        for i,layer in enumerate(policy):\n",
    "            layer._name = 'mlp_custom_layer_{}'.format(i)\n",
    "            layers.append(layer)\n",
    "            \n",
    "    return layers\n",
    "\n",
    "    \n",
    "def get_critic_network(input_dims,output_dims):\n",
    "    state_input = Input(shape=input_dims)\n",
    "    action_input = Input(shape=(1, output_dims,))\n",
    "\n",
    "    # Classification block\n",
    "    x = Dense(512, activation='relu', name='fc1')(state_input)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    out_actions = Dense(1, activation='tanh')(x)\n",
    "\n",
    "    model = Model(inputs=[state_input,action_input], outputs=[out_actions])\n",
    "    model.compile(optimizer=Adam(lr=0.0003), loss='mse')\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def value_loss(state_input):\n",
    "    def loss(y_true, y_pred):\n",
    "        return 0.5 *keras.losses.MSE(y_pred,y_true)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def get_value_network(input_dims):\n",
    "    state_input = Input(shape=input_dims)\n",
    "\n",
    "    # Classification block\n",
    "    x = Dense(512, activation='relu', name='fc1')(state_input)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    out_actions = Dense(1, activation=None)(x)\n",
    "\n",
    "    model = Model(inputs=[state_input], outputs=[out_actions])\n",
    "    model.compile(optimizer=Adam(lr=0.0003), loss=[value_loss(state_input)])\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "# def get_model_actor_simple(input_dims, output_dims):\n",
    "#     state_input = Input(shape=input_dims)\n",
    "#     oldpolicy_probs = Input(shape=(1, output_dims,))\n",
    "#     advantages = Input(shape=(1, 1,))\n",
    "#     rewards = Input(shape=(1, 1,))\n",
    "#     values = Input(shape=(1, 1,))\n",
    "\n",
    "#     # Classification block\n",
    "#     x = Dense(512, activation='relu', name='fc1')(state_input)\n",
    "#     x = Dense(256, activation='relu', name='fc2')(x)\n",
    "#     out_actions = Dense(n_actions, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#     model = Model(inputs=[state_input, oldpolicy_probs, advantages, rewards, values],\n",
    "#                   outputs=[out_actions])\n",
    "#     model.compile(optimizer=Adam(lr=1e-4), loss=[ppo_loss(\n",
    "#         oldpolicy_probs=oldpolicy_probs,\n",
    "#         advantages=advantages,\n",
    "#         rewards=rewards,\n",
    "#         values=values)])\n",
    "#     # model.summary()\n",
    "#     return model\n",
    "\n",
    "\n",
    "# class CriticNetwork(keras.Model):\n",
    "#     def __init__(self,\n",
    "#                 fc,\n",
    "#                 n_actions=2,\n",
    "#                 name='critic'\n",
    "#         ):\n",
    "#         super(CriticNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "#         self.model_name = name\n",
    "#         self.fc = fc\n",
    "#         self.q = Dense(1, activation=None)\n",
    "#         self._name = name\n",
    "        \n",
    "#     def call(self, state, action):\n",
    "#         X = tf.concat([state, action], axis=1)\n",
    "#         print(X)\n",
    "#         for layer in self.fc:\n",
    "#             X = layer(X)\n",
    "            \n",
    "#         q = self.q(X)\n",
    "#         return q\n",
    "\n",
    "# class ValueNetwork(keras.Model):\n",
    "#     def __init__(self,\n",
    "#                  fc,\n",
    "#                  name='value',  \n",
    "#         ):\n",
    "#         super(ValueNetwork, self).__init__()\n",
    "        \n",
    "\n",
    "#         self.model_name = name\n",
    "\n",
    "#         self.fc = fc\n",
    "#         self.v = Dense(1, activation=None)\n",
    "#         self._name = name\n",
    "        \n",
    "#     def call(self, state):\n",
    "#         X = state\n",
    "#         print(X)\n",
    "#         for layer in self.fc:\n",
    "#             X = layer(X)\n",
    "\n",
    "#         v = self.v(X)\n",
    "\n",
    "#         return v\n",
    "\n",
    "class ActorNetwork(keras.Model):\n",
    "    def __init__(self, \n",
    "            fc,\n",
    "            n_actions=2,\n",
    "            max_action=1, \n",
    "            name='actor', \n",
    "    ):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name\n",
    "        self.max_action = max_action\n",
    "        self.noise = 1e-6\n",
    "\n",
    "        self.fc = fc\n",
    "        \n",
    "        self.mu = Dense(n_actions, activation=None)\n",
    "        self.sigma = Dense(n_actions, activation=None)\n",
    "        \n",
    "        self._name = name\n",
    "\n",
    "    def call(self, state):\n",
    "        X = state\n",
    "        print(X)\n",
    "        for layer in self.fc:\n",
    "            X = layer(X)\n",
    "\n",
    "        mu = self.mu(X)\n",
    "        sigma = self.sigma(X)\n",
    "        sigma = tf.clip_by_value(sigma, self.noise, 1)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def sample_normal(self, state, reparameterize=True):\n",
    "        mu, sigma = self.call(state)\n",
    "        probabilities = tfp.distributions.Normal(mu, sigma)\n",
    "\n",
    "        if reparameterize:\n",
    "            actions = probabilities.sample() # + something else if you want to implement\n",
    "        else:\n",
    "            actions = probabilities.sample()\n",
    "\n",
    "        action = tf.math.tanh(actions)*self.max_action\n",
    "        log_probs = probabilities.log_prob(actions)\n",
    "        log_probs -= tf.math.log(1-tf.math.pow(action,2)+self.noise)\n",
    "        log_probs = tf.math.reduce_sum(log_probs, axis=1, keepdims=True)\n",
    "\n",
    "        return action, log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44c377dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:47:55.200204Z",
     "start_time": "2022-07-26T12:47:55.164736Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.agents.agent import Agent\n",
    "\n",
    "\n",
    "class SoftActorCriticAgent(Agent):\n",
    "    def __init__(self, \n",
    "            environment,\n",
    "            alpha=0.0003, \n",
    "            beta=0.0003, \n",
    "            gamma=0.99, \n",
    "            tau=0.005,\n",
    "            buffer_size=1000000, \n",
    "            policy=\"mlp\", \n",
    "            batch_size=256, \n",
    "            reward_scale=2, \n",
    "            loss_function = keras.losses.MSE, #keras.losses.Huber()\n",
    "    ):\n",
    "        super(SoftActorCriticAgent, self).__init__(environment,loss_keys=[\"actor\",\"value\",\"critic_1\",\"critic_2\"],args=locals())\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.policy = policy\n",
    "        self.reward_scale = reward_scale\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        self.__init_networks()\n",
    "        self.__init_buffers()\n",
    "        self._add_models_to_config([self.actor,self.critic_1,self.critic_2,self.value,self.target_value])\n",
    "        self._init_tensorboard()\n",
    "        \n",
    "    def __init_buffers(self):\n",
    "        self.buffer = ReplayBuffer(self.buffer_size, self.observation_shape, self.n_actions)\n",
    "            \n",
    "    def __init_networks(self):\n",
    "        self.actor = ActorNetwork(n_actions=self.n_actions,policy=self.policy, max_action=self.env.action_space.high)\n",
    "        self.critic_1 = CriticNetwork(n_actions=self.n_actions,policy=self.policy, name='critic_1')\n",
    "        self.critic_2 = CriticNetwork(n_actions=self.n_actions,policy=self.policy, name='critic_2')\n",
    "        self.value = ValueNetwork(name='value',policy=self.policy)\n",
    "        self.target_value = ValueNetwork(name='target_value',policy=self.policy)\n",
    "\n",
    "        self.actor.compile(optimizer=Adam(learning_rate=self.alpha))\n",
    "        self.critic_1.compile(optimizer=Adam(learning_rate=self.beta))\n",
    "        self.critic_2.compile(optimizer=Adam(learning_rate=self.beta))\n",
    "        self.value.compile(optimizer=Adam(learning_rate=self.beta))\n",
    "        self.target_value.compile(optimizer=Adam(learning_rate=self.beta))\n",
    "\n",
    "        self.update_network_parameters(tau=1)\n",
    "        \n",
    "        self.models = [self.actor,self.critic_1,self.critic_2,self.value,self.target_value]\n",
    "    \n",
    "    def choose_action(self, observation):\n",
    "        state = tf.convert_to_tensor([observation])\n",
    "        actions, _ = self.actor.sample_normal(state, reparameterize=False)\n",
    "\n",
    "        return actions[0]\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.buffer.remember(state, action, reward, new_state, done)      \n",
    "\n",
    "    def update_network_parameters(self, tau=None):\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        weights = []\n",
    "        targets = self.target_value.weights\n",
    "        for i, weight in enumerate(self.value.weights):\n",
    "            weights.append(weight * tau + targets[i]*(1-tau))\n",
    "\n",
    "        self.target_value.set_weights(weights)\n",
    "        \n",
    "    def replay(self):\n",
    "        if self.buffer.buffer_counter < self.batch_size:\n",
    "            return\n",
    "    \n",
    "        state,action, reward, state_, done = self.buffer.sample(self.batch_size)\n",
    "        \n",
    "        states = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        states_ = tf.convert_to_tensor(state_, dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(action, dtype=tf.float32)\n",
    "        \n",
    "        # Value network update\n",
    "        with tf.GradientTape() as tape:\n",
    "            value = tf.squeeze(self.value(states),1)\n",
    "            value_= tf.squeeze(self.target_value(states_),1)\n",
    "            \n",
    "            current_policy_actions, log_probs = self.actor.sample_normal(states)\n",
    "            log_probs = tf.squeeze(log_probs,1)\n",
    "            \n",
    "            q1_new_policy = self.critic_1(states,current_policy_actions)\n",
    "            q2_new_policy = self.critic_2(states,current_policy_actions)\n",
    "            critic_value = tf.squeeze(tf.math.minimum(q1_new_policy,q2_new_policy))\n",
    "            \n",
    "            value_target = critic_value - log_probs\n",
    "            value_loss = 0.5 *self.loss_function(value,value_target)\n",
    "            \n",
    "            \n",
    "        value_network_gradient = tape.gradient(value_loss,self.value.trainable_variables)\n",
    "        self.value.optimizer.apply_gradients(zip(value_network_gradient, self.value.trainable_variables))\n",
    "        \n",
    "        # Actor network update\n",
    "        with tf.GradientTape() as tape:\n",
    "            # in the original paper, they reparameterize here. \n",
    "            new_policy_actions, log_probs = self.actor.sample_normal(states,reparameterize=True)\n",
    "            \n",
    "            log_probs = tf.squeeze(log_probs, 1)\n",
    "            q1_new_policy = self.critic_1(states, new_policy_actions)\n",
    "            q2_new_policy = self.critic_2(states, new_policy_actions)\n",
    "            critic_value = tf.squeeze(tf.math.minimum(q1_new_policy, q2_new_policy), 1)\n",
    "        \n",
    "            actor_loss = log_probs - critic_value\n",
    "            actor_loss = tf.math.reduce_mean(actor_loss)\n",
    "\n",
    "        actor_network_gradient = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(actor_network_gradient, self.actor.trainable_variables))\n",
    "\n",
    "        # Critic network update\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            \n",
    "            q_hat = self.reward_scale*reward + self.gamma*value_*(1-done)\n",
    "            q1_old_policy = tf.squeeze(self.critic_1(state, action), 1)\n",
    "            q2_old_policy = tf.squeeze(self.critic_2(state, action), 1)\n",
    "            critic_1_loss = 0.5 * self.loss_function(q1_old_policy, q_hat)\n",
    "            critic_2_loss = 0.5 * self.loss_function(q2_old_policy, q_hat)\n",
    "    \n",
    "        critic_1_network_gradient = tape.gradient(critic_1_loss,self.critic_1.trainable_variables)\n",
    "        critic_2_network_gradient = tape.gradient(critic_2_loss,self.critic_2.trainable_variables)\n",
    "\n",
    "        self.critic_1.optimizer.apply_gradients(zip(critic_1_network_gradient, self.critic_1.trainable_variables))\n",
    "        self.critic_2.optimizer.apply_gradients(zip(critic_2_network_gradient, self.critic_2.trainable_variables))\n",
    "\n",
    "        # log losses\n",
    "        self.learning_log.step_loss({\n",
    "            \"actor\":actor_loss.numpy(),\n",
    "            \"value\":value_loss.numpy(),\n",
    "            \"critic_1\":critic_1_loss.numpy(),\n",
    "            \"critic_2\":critic_2_loss.numpy()\n",
    "        })\n",
    "        \n",
    "        self.update_network_parameters()\n",
    "\n",
    "        # log evolution on tensorboard\n",
    "        self.write_tensorboard_scaler('actor_loss',tf.get_static_value(actor_loss),self.learning_log.learning_steps)\n",
    "        self.write_tensorboard_scaler('value_loss',tf.get_static_value(value_loss),self.learning_log.learning_steps)\n",
    "        self.write_tensorboard_scaler('critic_1_loss',tf.get_static_value(critic_1_loss),self.learning_log.learning_steps)\n",
    "        self.write_tensorboard_scaler('critic_2_loss',tf.get_static_value(critic_2_loss),self.learning_log.learning_steps)\n",
    "        \n",
    "\n",
    "    def test(self, episodes=10, render=True, init_environment=False):\n",
    "        for episode in range(episodes):\n",
    "            try:\n",
    "                state = self.env.reset()\n",
    "            except:\n",
    "                self._Agent__init_environment()\n",
    "                state = self.env.reset()\n",
    "                \n",
    "            done = False\n",
    "            score = 0\n",
    "            \n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                \n",
    "                # Sample action, probs and critic\n",
    "                action = self.choose_action(state)\n",
    "\n",
    "                # Step\n",
    "                state,reward,done, info = self.env.step(action)\n",
    "\n",
    "                # Get next state\n",
    "                score += reward\n",
    "            \n",
    "            if render:\n",
    "                self.env.close()\n",
    "\n",
    "            self.learning_log.episode_test_log(score,episode)\n",
    "\n",
    "            \n",
    "    def learn(self, timesteps=-1, plot_results=True, reset=False, success_threshold=False, log_level=1, log_each_n_episodes=50,):\n",
    "        self.validate_learn(timesteps,success_threshold,reset)\n",
    "        success_threshold = success_threshold if success_threshold else self.env.success_threshold\n",
    " \n",
    "        score = 0\n",
    "        timestep = 0\n",
    "        episode = 0\n",
    "        \n",
    "        while self.learning_condition(timesteps,timestep):  # Run until solved\n",
    "            state = self.env.reset()\n",
    "            score = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                action = self.choose_action(state)\n",
    "                state_, reward, done, info = self.env.step(action)\n",
    "                score += reward\n",
    "                self.remember(state, action, reward, state_, done)\n",
    "                self.replay()\n",
    "                state = state_\n",
    "            \n",
    "            self.running_reward.step(score)\n",
    "             # Log details\n",
    "            episode += 1\n",
    "            \n",
    "            self.learning_log.episode(\n",
    "                log_each_n_episodes,\n",
    "                score,\n",
    "                self.running_reward.reward, \n",
    "                log_level=log_level\n",
    "            )\n",
    "            \n",
    "            # log scores\n",
    "            self.write_tensorboard_scaler('score',score,self.learning_log.episodes)\n",
    "           \n",
    "            if self.did_finnish_learning(success_threshold,episode):\n",
    "                break\n",
    "\n",
    "        if plot_results:\n",
    "            self.plot_learning_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f340af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:47:57.587698Z",
     "start_time": "2022-07-26T12:47:55.884205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument 'graph_data' is not tf.Graph or tf.compat.v1.GraphDef. Received graph_data=<__main__.ActorNetwork object at 0x0000020CF4BA8B50> of type ActorNetwork.\n",
      "Argument 'graph_data' is not tf.Graph or tf.compat.v1.GraphDef. Received graph_data=<__main__.CriticNetwork object at 0x0000020CF4B51AB0> of type CriticNetwork.\n",
      "Argument 'graph_data' is not tf.Graph or tf.compat.v1.GraphDef. Received graph_data=<__main__.CriticNetwork object at 0x0000020CF4B52860> of type CriticNetwork.\n",
      "Argument 'graph_data' is not tf.Graph or tf.compat.v1.GraphDef. Received graph_data=<__main__.ValueNetwork object at 0x0000020CF4BA8DF0> of type ValueNetwork.\n",
      "Argument 'graph_data' is not tf.Graph or tf.compat.v1.GraphDef. Received graph_data=<__main__.ValueNetwork object at 0x0000020CF4B53490> of type ValueNetwork.\n",
      "The following models are incompatible with tensorboard graphs ['actor', 'critic_1', 'critic_2', 'value', 'target_value']\n",
      "\n",
      "tf.Tensor([[ 0.          0.          0.99947546 -0.03238533  0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-9.70400879e-05 -5.88121745e-03  9.99476478e-01 -3.23538330e-02\n",
      "   1.90992189e-03]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-3.11545948e-04 -1.30003552e-02  9.99479905e-01 -3.22477728e-02\n",
      "   6.43125202e-03]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-3.70121578e-04 -3.55003817e-03  9.99467206e-01 -3.26389871e-02\n",
      "  -2.37224480e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-5.06440643e-06  2.21246771e-02  9.99418763e-01 -3.40901153e-02\n",
      "  -8.79961641e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-8.90852381e-06 -2.32976811e-04  9.99389080e-01 -3.49494887e-02\n",
      "  -5.21142943e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-4.96822101e-04 -2.95705198e-02  9.99387987e-01 -3.49807375e-02\n",
      "  -1.89502626e-03]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00103319 -0.03250715  0.99938394 -0.03509603 -0.00699181]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00165723 -0.03782078  0.9993798  -0.03521376 -0.00713977]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00271279 -0.06397315  0.99940074 -0.03461453  0.0363396 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0038608  -0.06957622  0.99942167 -0.03400474  0.03697827]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00541407 -0.09413772  0.99946437 -0.03272583  0.07755348]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0068878  -0.08931705  0.99949471 -0.03178567  0.05700896]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00872848 -0.11155651  0.99954255 -0.03024381  0.09349062]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01082449 -0.12703057  0.99959876 -0.02832522  0.11632846]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0131306  -0.13976456  0.99965898 -0.02611366  0.13408371]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01562055 -0.15090562  0.99972026 -0.02365165  0.14925872]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01824646 -0.15914658  0.99977894 -0.02102554  0.15919789]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02094537 -0.16356971  0.99983158 -0.01835253  0.16203213]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02389038 -0.17848566  0.99988364 -0.01525475  0.18777095]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0269594  -0.18600152  0.99992835 -0.01197067  0.19905386]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02992754 -0.17988715  0.99995992 -0.00895327  0.18288263]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03332029 -0.20562128  0.99998708 -0.00508414  0.23449886]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03675375 -0.20808807  0.99999934 -0.00114638  0.23865306]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04043312 -0.22299255  0.99999451  0.00331217  0.27021563]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04439872 -0.24033931  0.99996471  0.00840079  0.30840672]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04851197 -0.24928782  0.99990398  0.0138572   0.33071279]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05261818 -0.24886137  0.99981205  0.01938743  0.33521195]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05666236 -0.24510141  0.99968978  0.02490687  0.33459423]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06068605 -0.24386031  0.99953375  0.03053319  0.34112056]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06498587 -0.26059512  0.99931828  0.0369185   0.38720902]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06945019 -0.27056507  0.99903752  0.04386375  0.42126891]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.07407693 -0.2804084   0.99867803  0.0514022   0.45739594]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0788855  -0.29142854  0.99822144  0.05961499  0.49851529]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.08372921 -0.29355809  0.99766895  0.06823971  0.52378299]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0886293  -0.29697473  0.99700268  0.07736696  0.5546405 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.09387701 -0.31804314  0.99615119  0.08765161  0.62544774]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.09944147 -0.33724017  0.99507933  0.09908138  0.6957565 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.10527488 -0.35353977  0.99375164  0.111614    0.76380835]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.11127442 -0.36360893  0.99214432  0.12509854  0.82303603]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.11759868 -0.38328814  0.99016175  0.13992751  0.90673067]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.12427779 -0.40479463  0.9877206   0.15623062  0.99909367]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.13109956 -0.41344045  0.98480807  0.17364636  1.07017125]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.13827811 -0.43506363  0.98126044  0.19268614  1.17380446]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99954506 0.03016093 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-1.60680514e-04 -9.73821295e-03  9.99529400e-01  3.06753591e-02\n",
      "   3.11919985e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-8.01076892e-04 -3.88119017e-02  9.99475791e-01  3.23750381e-02\n",
      "   1.03062087e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00128174 -0.02913136  0.99942421  0.03393018  0.0943026 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00202295 -0.04492158  0.9993435   0.03622926  0.13942413]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00290302 -0.05333743  0.99923804  0.03903003  0.16986394]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0036233  -0.04365329  0.99912923  0.04172276  0.16332909]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00432912 -0.04277726  0.99900374  0.04462648  0.17614754]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00519981 -0.05276886  0.99884097  0.0481322   0.21269677]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00622604 -0.06219591  0.99863459  0.05223939  0.2492349 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00722057 -0.0602746   0.99839813  0.0565789   0.2633908 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00854377 -0.0801938   0.99808067  0.0619272   0.32471063]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00960432 -0.06427605  0.99774772  0.06707823  0.31283543]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01088088 -0.07736708  0.99732761  0.07305911  0.36337114]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01249986 -0.09812003  0.99678163  0.08016475  0.4319149 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0144889  -0.1205478   0.99607714  0.08848911  0.50631173]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01684555 -0.14282753  0.99517961  0.09806912  0.58315159]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01948245 -0.15981187  0.99406681  0.10877118  0.65210944]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02242054 -0.1780661   0.99269005  0.12069159  0.72725617]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02558063 -0.19152035  0.99101854  0.13372455  0.79635193]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0291053  -0.21361636  0.98895361  0.14822537  0.88771112]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03302849 -0.23776927  0.98640572  0.16432821  0.98808146]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03727863 -0.25758427  0.98330674  0.18195567  1.08472937]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99701418 0.07721865 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-5.83444633e-04 -3.53602808e-02  9.96884592e-01  7.88740187e-02\n",
      "   1.00632123e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00189601 -0.0795495   0.99659138  0.08249618  0.22024321]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00344383 -0.0938072   0.99620176  0.08707496  0.27850467]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00506706 -0.09837768  0.99573109  0.09230168  0.318053  ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00684473 -0.10773769  0.99515011  0.09836799  0.36933816]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00878465 -0.11757072  0.99443823  0.10532144  0.42362453]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01109453 -0.13999258  0.9935234   0.11362774  0.50645776]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01342324 -0.14113426  0.99245597  0.12260162  0.54770752]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01575841 -0.14152515  0.99121456  0.13226371  0.59039713]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01822304 -0.14937162  0.98973479  0.14291619  0.65180749]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02063414 -0.146127    0.98803405  0.15423591  0.69374731]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0232894  -0.16092493  0.98597595  0.16688747  0.77684601]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02619629 -0.17617542  0.9834936   0.18094291  0.86503545]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02942579 -0.19572724  0.98048249  0.19660644  0.96669666]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99983349 0.01824824 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-1.93606854e-04 -1.17337488e-02  9.99823916e-01  1.87653122e-02\n",
      "   3.13428081e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-4.75703016e-04 -1.70967371e-02  9.99808255e-01  1.95819749e-02\n",
      "   4.95038086e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00109095 -0.03728768  0.99977493  0.02121535  0.09901306]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00181974 -0.04416932  0.99973051  0.02321425  0.12117522]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00309502 -0.07728934  0.9996489   0.02649663  0.19899394]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00457729 -0.08983479  0.99953875  0.03036918  0.23479487]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00612579 -0.09384828  0.99940268  0.03455828  0.25401912]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00816745 -0.12373724  0.99920045  0.03998068  0.32885924]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0101634  -0.12096664  0.99896262  0.04553776  0.33710139]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01272161 -0.15504265  0.99861927  0.05253147  0.42437235]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01534403 -0.15893473  0.99820093  0.05995756  0.45078102]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01807894 -0.16575202  0.99768826  0.06795692  0.48580549]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02088316 -0.16995271  0.99707094  0.07648223  0.51803981]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02383545 -0.17892665  0.9963173   0.08574289  0.56310971]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02720799 -0.20439659  0.99534723  0.096353    0.64572208]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03065085 -0.20865814  0.99419005  0.10763899  0.68758886]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03416259 -0.21283304  0.99281542  0.11965593  0.73305347]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0379321  -0.22845471  0.99113559  0.13285423  0.80635604]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04198313 -0.24551688  0.98908509  0.14734546  0.88701251]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04614396 -0.25217189  0.9866517   0.16284476  0.95086816]], shape=(1, 5), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.05053951 -0.26639681  0.98372541  0.17967835  1.03553039]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05530871 -0.28904252  0.98016174  0.19819929  1.14308812]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[ 0.          0.          0.99998264 -0.00589274  0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-2.21076083e-04 -1.33985505e-02  9.99985133e-01 -5.45294516e-03\n",
      "   2.66543844e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0010531  -0.05042544  0.99999296 -0.00375363  0.10299002]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00235626 -0.07897983  0.99999942 -0.00107832  0.16214028]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00384135 -0.09000539  0.99999804  0.00198159  0.18544949]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00568545 -0.11176359  0.9999831   0.00581439  0.2322925 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00803517 -0.14240699  0.99994223  0.01074861  0.29905432]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01026441 -0.13510554  0.99987988  0.0154992   0.28793951]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01262198 -0.14288304  0.99978751  0.02061401  0.3100394 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01516872 -0.15434798  0.99965544  0.02624873  0.34159242]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01786313 -0.16329776  0.99947669  0.03234733  0.36977178]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02069585 -0.17168002  0.99924219  0.03892358  0.39881465]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02380988 -0.18872893  0.998927    0.04631251  0.44822182]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02729201 -0.21103795  0.99850091  0.05473514  0.51111667]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03095437 -0.22196153  0.99795993  0.06384342  0.55299158]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03481046 -0.2337026   0.99727944  0.07371379  0.59962698]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03898958 -0.25327961  0.99640928  0.08466727  0.66594196]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04340232 -0.26743918  0.99532585  0.09657359  0.72458117]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04800491 -0.27894462  0.99399758  0.10940208  0.78164602]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05291548 -0.29760999  0.99234942  0.12346101  0.85789841]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0581459  -0.31699529  0.9903146   0.13884164  0.94029099]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06362105 -0.33182759  0.98784212  0.15546043  1.01829718]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06925155 -0.34124239  0.98488492  0.17320996  1.09057151]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.07534916 -0.36955216  0.98123797  0.19280054  1.20772618]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[ 0.          0.          0.99905417 -0.04348299  0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-4.52608684e-04 -2.74308293e-02  9.99084963e-01 -4.27695733e-02\n",
      "   4.32775239e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00108183 -0.03813484  0.99912113 -0.04191608  0.05177327]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00221781 -0.06884692  0.99919058 -0.04022664  0.10247711]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00347203 -0.07601345  0.99925842 -0.03850463  0.10444494]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00487023 -0.08473945  0.99932683 -0.0366864   0.1102736 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0066535  -0.10807715  0.99941306 -0.03425682  0.14734014]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00853542 -0.1140553   0.99949419 -0.0318018   0.14887055]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01039392 -0.1126366   0.99956292 -0.02956308  0.13574348]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01254097 -0.13012448  0.99963881 -0.02687463  0.16300132]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01456832 -0.12286955  0.99969795 -0.02457649  0.13932786]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01694535 -0.14406264  0.99976513 -0.02167228  0.17605938]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01964294 -0.16348981  0.99983425 -0.01820663  0.21008166]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02273696 -0.18751667  0.99990198 -0.0140009   0.2549259 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02577241 -0.18396632  0.99995015 -0.00998517  0.24339527]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02863221 -0.17332143  0.99997963 -0.00638238  0.218358  ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03148797 -0.1730765   0.99999604 -0.00281271  0.21634616]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-3.43448353e-02 -1.73143229e-01  9.99999715e-01  7.54566718e-04\n",
      "   2.16198957e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0376163  -0.19827087  0.99998645  0.00520617  0.26979579]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04134557 -0.2260158   0.99994321  0.01065731  0.33038277]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0452137  -0.23443233  0.99986437  0.01646959  0.35229243]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04913993 -0.23795332  0.99974671  0.02250585  0.36590407]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0532076  -0.24652556  0.99958017  0.02897401  0.3921398 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05738249 -0.2530239   0.99935762  0.03583784  0.41620917]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06181948 -0.26890825  0.99905521  0.04345897  0.46225172]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06615503 -0.26276066  0.99869261  0.05111811  0.46471111]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.07067598 -0.27399683  0.99823088  0.05945676  0.50614859]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.07547374 -0.2907733   0.99763666  0.0687102   0.56197121]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.08063649 -0.31289414  0.99686585  0.07911054  0.63205572]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.08596305 -0.32282181  0.99591533  0.09029207  0.68011568]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.09151709 -0.3366082   0.99473871  0.10244458  0.73996446]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0973054  -0.35080664  0.99329083  0.11564307  0.80471327]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.10330538 -0.36363512  0.99152637  0.12990554  0.8709895 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.10960648 -0.3818852   0.98936055  0.14548436  0.95326151]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.11632477 -0.40716909  0.98667761  0.16268773  1.05524495]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.12337671 -0.42739019  0.98340611  0.18141783  1.15236044]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99744749 0.07140376 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[1.99169916e-05 1.20709040e-03 9.97421220e-01 7.17698337e-02\n",
      "  2.22434862e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-4.74204175e-04 -2.99467374e-02  9.97286584e-01  7.36170426e-02\n",
      "   1.12249045e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00121998 -0.04519852  0.99707665  0.07640775  0.16961175]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0019656  -0.045189    0.99682434  0.07963186  0.19599828]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.003089   -0.06808498  0.99645787  0.08409353  0.27131497]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00467514 -0.09612995  0.99594248  0.08999212  0.35885307]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00639338 -0.10413552  0.99531649  0.09667001  0.40649534]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00837832 -0.12029912  0.99453107  0.10444115  0.47337908]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01046948 -0.12673741  0.99359359  0.11301227  0.52256087]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01274504 -0.13791231  0.99245756  0.1225887   0.58446199]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01520351 -0.14899816  0.99108717  0.13321498  0.64935306]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01803836 -0.17180906  0.98938169  0.14534051  0.74211891]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02106323 -0.18332588  0.9873367   0.15863869  0.81543015]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02440751 -0.20268334  0.98484537  0.17343469  0.90935866]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02803662 -0.21994616  0.98183788  0.18972182  1.00379788]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99999303 0.00373492 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 3.09503009e-04  1.87577581e-02  9.99995144e-01  3.11633994e-03\n",
      "  -3.74900253e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 5.73972047e-04  1.60284265e-02  9.99996571e-01  2.61889509e-03\n",
      "  -3.01482971e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 3.72513451e-04 -1.22096119e-02  9.99995126e-01  3.12208716e-03\n",
      "   3.04966148e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-2.99494989e-04 -4.07277843e-02  9.99989243e-01  4.63839033e-03\n",
      "   9.18978628e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-7.36706307e-04 -2.64976556e-02  9.99983768e-01  5.69766227e-03\n",
      "   6.41991593e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00152611 -0.04784281  0.9999716   0.00753627  0.11143304]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00256674 -0.06306853  0.99995047  0.00995274  0.14645847]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00399786 -0.08673462  0.99991218  0.01325236  0.19999037]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00573084 -0.10502862  0.99985091  0.01726752  0.24337171]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00772277 -0.12072321  0.9997595   0.02193044  0.28265569]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00973126 -0.12172691  0.99964192  0.02675889  0.29272032]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01206389 -0.14137131  0.99947421  0.03242373  0.34347483]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01426357 -0.13331386  0.99927779  0.03799877  0.33809116]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01668692 -0.14686959  0.99901999  0.04426123  0.37986494]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01946792 -0.16854536  0.9986717   0.0515251   0.44074154]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02242659 -0.17931346  0.99823112  0.05945279  0.48120839]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02542699 -0.18184272  0.99769874  0.06780283  0.50709214]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02869708 -0.19818713  0.99702372  0.07709542  0.56467315]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03228948 -0.21772112  0.99616555  0.08748824  0.6320147 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03606141 -0.22860173  0.99511354  0.09873727  0.68473759]], shape=(1, 5), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.04008266 -0.24371225  0.99381544  0.11104447  0.75003336]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04425439 -0.25283204  0.9922489   0.12426631  0.80693424]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.04851846 -0.25842859  0.99038365  0.13834822  0.86091108]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05312752 -0.27933666  0.98808999  0.15387716  0.95136803]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.05803584 -0.29747409  0.98530079  0.17082841  1.04117587]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.06323221 -0.31493163  0.98192859  0.18925181  1.13513675]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99850423 0.05467443 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 1.77995212e-04  1.07875886e-02  9.98507373e-01  5.46170818e-02\n",
      "  -3.48090919e-03]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[2.72381026e-04 5.72035236e-03 9.98483679e-01 5.50485576e-02\n",
      "  2.61894519e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[ 9.64134352e-05 -1.06647024e-02  9.98410442e-01  5.63612374e-02\n",
      "   7.96800816e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-3.64473171e-04 -2.79325216e-02  9.98281989e-01  5.85924079e-02\n",
      "   1.35446394e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00132423 -0.05816689  0.99806367  0.06220063  0.21908043]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00254625 -0.07406173  0.99777236  0.06671065  0.27390426]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00410822 -0.09466491  0.99738233  0.07230827  0.34007275]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00575537 -0.09982744  0.99691478  0.07849159  0.37581664]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00785568 -0.12729147  0.99628999  0.08605958  0.4602279 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00999496 -0.12965336  0.99555432  0.09418912  0.4947139 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01257161 -0.15616081  0.99460341  0.10374996  0.58230623]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01545251 -0.17460014  0.99342176  0.1145129   0.65622158]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01858044 -0.18957111  0.99197779  0.12641229  0.72647032]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02203473 -0.20935094  0.99019824  0.13966906  0.81065299]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02587078 -0.23248818  0.98799936  0.15445798  0.90615967]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03008834 -0.25560936  0.98529821  0.17084329  1.00646382]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.03471056 -0.28013489  0.98198855  0.18894045  1.11500416]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[0.         0.         0.99782665 0.06589371 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-3.49268621e-04 -2.11677952e-02  9.97753002e-01  6.69996005e-02\n",
      "   6.71719159e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-8.06220369e-04 -2.76940453e-02  9.97636473e-01  6.87129406e-02\n",
      "   1.04078702e-01]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00145184 -0.03912837  0.99746123  0.07121168  0.15181083]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00244013 -0.05989676  0.9971963   0.07483004  0.2198816 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00346876 -0.06234084  0.99687805  0.07895671  0.25084405]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00461289 -0.0693414   0.99648509  0.0837703   0.2927032 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00604447 -0.08676243  0.99597298  0.08965386  0.35792846]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00735599 -0.07948617  0.99540149  0.09579076  0.37354287]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00896056 -0.09724641  0.99467395  0.1030715   0.44345573]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01080434 -0.11174414  0.99377329  0.11142106  0.50897093]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01275796 -0.11840117  0.99269952  0.12061367  0.56091782]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01496604 -0.13382315  0.99138314  0.13099414  0.63416074]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.0171359  -0.13150648  0.98986515  0.14201053  0.67397188]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01971215 -0.15613639  0.98797244  0.15463007  0.77338043]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02252054 -0.17020542  0.98569267  0.16855255  0.85503124]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02576585 -0.19668595  0.98287828  0.18425603  0.96690009]], shape=(1, 5), dtype=float64)\n",
      "Episode * 10 * Moving Avg Reward is ==> 24.300 * Last Reward was ==> 17.000\n",
      "tf.Tensor([[0.         0.         0.99974878 0.02241396 0.        ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-4.00063801e-04 -2.42462910e-02  9.99726492e-01  2.33867909e-02\n",
      "   5.89747721e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-9.88409251e-04 -3.56573000e-02  9.99690096e-01  2.48940218e-02\n",
      "   9.13739607e-02]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00179822 -0.04907951  0.99963507  0.02701341  0.1284909 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00301954 -0.07401948  0.99954525  0.03015457  0.19045124]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00460249 -0.09593615  0.99941398  0.03423003  0.24712581]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00631877 -0.10401676  0.99924762  0.0387839   0.2761769 ]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.00814701 -0.11080243  0.99904048  0.04379635  0.30404444]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01036703 -0.13454708  0.99875522  0.04987996  0.36910885]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01274427 -0.14407503  0.99839826  0.05657665  0.40643726]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01526874 -0.15299787  0.99795621  0.06390157  0.44474305]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.01813476 -0.17369831  0.99738298  0.07229928  0.51013788]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor([[-0.02101502 -0.17456115  0.99670343  0.08113121  0.53685224]], shape=(1, 5), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[-0.01274504 -0.13791232  0.99245757  0.1225887   0.584462  ]\n",
      " [-0.02542699 -0.18184273  0.9976987   0.06780282  0.5070921 ]\n",
      " [-0.06362105 -0.33182758  0.98784214  0.15546043  1.0182972 ]\n",
      " ...\n",
      " [-0.00639338 -0.10413552  0.9953165   0.09667001  0.40649533]\n",
      " [-0.01824646 -0.15914658  0.9997789  -0.02102554  0.1591979 ]\n",
      " [-0.04198313 -0.24551688  0.9890851   0.14734545  0.88701254]], shape=(256, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.01520351 -0.14899816  0.99108714  0.13321498  0.6493531 ]\n",
      " [-0.02869708 -0.19818713  0.9970237   0.07709542  0.5646731 ]\n",
      " [-0.06925155 -0.34124237  0.9848849   0.17320995  1.0905715 ]\n",
      " ...\n",
      " [-0.00837832 -0.12029912  0.9945311   0.10444115  0.47337908]\n",
      " [-0.02094536 -0.1635697   0.99983156 -0.01835253  0.16203213]\n",
      " [-0.04614396 -0.2521719   0.9866517   0.16284476  0.9508682 ]], shape=(256, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.01274504 -0.13791232  0.99245757  0.1225887   0.584462  ]\n",
      " [-0.02542699 -0.18184273  0.9976987   0.06780282  0.5070921 ]\n",
      " [-0.06362105 -0.33182758  0.98784214  0.15546043  1.0182972 ]\n",
      " ...\n",
      " [-0.00639338 -0.10413552  0.9953165   0.09667001  0.40649533]\n",
      " [-0.01824646 -0.15914658  0.9997789  -0.02102554  0.1591979 ]\n",
      " [-0.04198313 -0.24551688  0.9890851   0.14734545  0.88701254]], shape=(256, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.01274504 -0.13791232  0.99245757  0.1225887   0.584462   -0.02544975]\n",
      " [-0.02542699 -0.18184273  0.9976987   0.06780282  0.5070921  -0.14430146]\n",
      " [-0.06362105 -0.33182758  0.98784214  0.15546043  1.0182972  -0.10809613]\n",
      " ...\n",
      " [-0.00639338 -0.10413552  0.9953165   0.09667001  0.40649533  0.05689055]\n",
      " [-0.01824646 -0.15914658  0.9997789  -0.02102554  0.1591979  -0.04459391]\n",
      " [-0.04198313 -0.24551688  0.9890851   0.14734545  0.88701254 -0.0687033 ]], shape=(256, 6), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"critic_1\" (type CriticNetwork).\n\nInput 0 of layer \"mlp_dense_layer_0\" is incompatible with the layer: expected axis -1 of input shape to have value 5, but received input with shape (256, 6)\n\nCall arguments received:\n   state=tf.Tensor(shape=(256, 5), dtype=float32)\n   action=tf.Tensor(shape=(256, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontinuous\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minverted_pendulum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m environment\n\u001b[0;32m      3\u001b[0m agent\u001b[38;5;241m=\u001b[39m SoftActorCriticAgent(environment)\n\u001b[1;32m----> 4\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_each_n_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuccess_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mSoftActorCriticAgent.learn\u001b[1;34m(self, timesteps, plot_results, reset, success_threshold, log_level, log_each_n_episodes)\u001b[0m\n\u001b[0;32m    199\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember(state, action, reward, state_, done)\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     state \u001b[38;5;241m=\u001b[39m state_\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_reward\u001b[38;5;241m.\u001b[39mstep(score)\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mSoftActorCriticAgent.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m current_policy_actions, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39msample_normal(states)\n\u001b[0;32m     92\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(log_probs,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m q1_new_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcurrent_policy_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m q2_new_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_2(states,current_policy_actions)\n\u001b[0;32m     96\u001b[0m critic_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mminimum(q1_new_policy,q2_new_policy))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mCriticNetwork.call\u001b[1;34m(self, state, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(X)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc:\n\u001b[1;32m---> 41\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq(X)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"critic_1\" (type CriticNetwork).\n\nInput 0 of layer \"mlp_dense_layer_0\" is incompatible with the layer: expected axis -1 of input shape to have value 5, but received input with shape (256, 6)\n\nCall arguments received:\n   state=tf.Tensor(shape=(256, 5), dtype=float32)\n   action=tf.Tensor(shape=(256, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from src.environments.continuous.inverted_pendulum import environment\n",
    "\n",
    "agent= SoftActorCriticAgent(environment)\n",
    "agent.learn(log_each_n_episodes=10, success_threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e620ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:43:50.143590Z",
     "start_time": "2022-07-26T12:43:50.143590Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181f98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:42:33.512035Z",
     "start_time": "2022-07-26T12:42:33.512035Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.hash, agent.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e80009f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:58:04.103192Z",
     "start_time": "2022-07-26T12:58:04.086288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'storage/environments/InvertedPendulumBulletEnv/SoftActorCriticAgent/88e695ba9c9146f81631e0b2fc3c9926'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tensorboard_writer_log_directory\n",
    "#'storage/environments/Pendulum/DdpgAgent/e996ee6c856f7c9cad03964bbe0fa65e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d0aa7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:59:21.471616Z",
     "start_time": "2022-07-26T12:59:16.888636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-52159a4648ea7aee\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-52159a4648ea7aee\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir storage/environments/InvertedPendulumBulletEnv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23f2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cefd392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T12:57:49.262823Z",
     "start_time": "2022-07-26T12:57:49.182868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n",
      "WARNING:tensorflow:From C:\\Users\\filip\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1358: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\filip\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1358: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\filip\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\profiler.py:150: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile()\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "@tf.function\n",
    "def traceme(x):\n",
    "    return model(x)\n",
    "\n",
    "traceme(tf.expand_dims(agent.env.reset(),axis=0))\n",
    "\n",
    "with agent.tensorboard_writer.as_default():\n",
    "    tf.summary.trace_export(name=\"model_trace\", step=0,profiler_outdir=agent.tensorboard_writer_log_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLayerPerceptron(policy=\"mlp\"):\n",
    "    layers = []\n",
    "    if type(policy) == str:\n",
    "        if policy == \"mlp\":\n",
    "            layers.append(Dense(256, activation='relu', name=\"mlp_dense_layer_0\"))\n",
    "            layers.append(Dense(256, activation='relu', name=\"mlp_dense_layer_1\"))\n",
    "    else:\n",
    "        for i,layer in enumerate(policy):\n",
    "            layer._name = 'mlp_custom_layer_{}'.format(i)\n",
    "            layers.append(layer)\n",
    "            \n",
    "    return layers\n",
    "        \n",
    "\n",
    "class CriticNetwork(keras.Model):\n",
    "    def __init__(self,\n",
    "                fc,\n",
    "                n_actions=2,\n",
    "                name='critic'\n",
    "        ):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.model_name = name\n",
    "        self.fc = fc\n",
    "        self.q = Dense(1, activation=None)\n",
    "        self._name = name\n",
    "        \n",
    "    def call(self, state, action):\n",
    "        X = tf.concat([state, action], axis=1)\n",
    "        print(X)\n",
    "        for layer in self.fc:\n",
    "            X = layer(X)\n",
    "            \n",
    "        q = self.q(X)\n",
    "        return q\n",
    "\n",
    "class ValueNetwork(keras.Model):\n",
    "    def __init__(self,\n",
    "                 fc,\n",
    "                 name='value',  \n",
    "        ):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "\n",
    "        self.model_name = name\n",
    "\n",
    "        self.fc = fc\n",
    "        self.v = Dense(1, activation=None)\n",
    "        self._name = name\n",
    "        \n",
    "    def call(self, state):\n",
    "        X = state\n",
    "        print(X)\n",
    "        for layer in self.fc:\n",
    "            X = layer(X)\n",
    "\n",
    "        v = self.v(X)\n",
    "\n",
    "        return v\n",
    "\n",
    "class ActorNetwork(keras.Model):\n",
    "    def __init__(self, \n",
    "            fc,\n",
    "            n_actions=2,\n",
    "            max_action=1, \n",
    "            name='actor', \n",
    "    ):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.model_name = name\n",
    "        self.max_action = max_action\n",
    "        self.noise = 1e-6\n",
    "\n",
    "        self.fc = fc\n",
    "        \n",
    "        self.mu = Dense(n_actions, activation=None)\n",
    "        self.sigma = Dense(n_actions, activation=None)\n",
    "        \n",
    "        self._name = name\n",
    "\n",
    "    def call(self, state):\n",
    "        X = state\n",
    "        print(X)\n",
    "        for layer in self.fc:\n",
    "            X = layer(X)\n",
    "\n",
    "        mu = self.mu(X)\n",
    "        sigma = self.sigma(X)\n",
    "        sigma = tf.clip_by_value(sigma, self.noise, 1)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def sample_normal(self, state, reparameterize=True):\n",
    "        mu, sigma = self.call(state)\n",
    "        probabilities = tfp.distributions.Normal(mu, sigma)\n",
    "\n",
    "        if reparameterize:\n",
    "            actions = probabilities.sample() # + something else if you want to implement\n",
    "        else:\n",
    "            actions = probabilities.sample()\n",
    "\n",
    "        action = tf.math.tanh(actions)*self.max_action\n",
    "        log_probs = probabilities.log_prob(actions)\n",
    "        log_probs -= tf.math.log(1-tf.math.pow(action,2)+self.noise)\n",
    "        log_probs = tf.math.reduce_sum(log_probs, axis=1, keepdims=True)\n",
    "\n",
    "        return action, log_probs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
