{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f64d680c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:19:33.022530Z",
     "start_time": "2022-07-21T16:19:33.006532Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c3dac7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:08:08.745618Z",
     "start_time": "2022-07-21T17:08:08.728653Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from src.utils.gym_environment import GymEnvironment\n",
    "from src.environments.discrete.mountain_car import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a72b829a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:08:09.335479Z",
     "start_time": "2022-07-21T17:08:09.312513Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Handles storage of state/action/reward and transitions\n",
    "class ReplayBuffer():\n",
    "    def __init__(\n",
    "            self,\n",
    "            environment,\n",
    "            buffer_size,\n",
    "            buffers=['state','new_state',\"action\",\"reward\", \"done\"]\n",
    "    ):\n",
    "        \n",
    "        self.buffer_position = 0\n",
    "        self.buffer_size = buffer_size\n",
    "        self.discrete = environment.action_space_mode == 'Discrete'\n",
    "        \n",
    "        self.__init_memory(environment)\n",
    "        # if discrete, the action space must be a one-hot encoded \n",
    "        \n",
    "    def __init_memory(self,environment):\n",
    "        dtype = np.int8 if self.discrete else np.float32\n",
    "        \n",
    "        if len(environment.observation_shape) ==1:\n",
    "            input_shape = environment.observation_shape[0]\n",
    "        else:\n",
    "            input_shape = environment.observation_shape[0]*environment.observation_shape[1]\n",
    "            \n",
    "        self.states = np.zeros((self.buffer_size,input_shape ))\n",
    "        self.new_states = np.zeros((self.buffer_size,input_shape ))    \n",
    "        self.actions = np.zeros((self.buffer_size, environment.n_actions), dtype=dtype)\n",
    "        self.rewards = np.zeros(self.buffer_size)\n",
    "        self.dones = np.zeros(self.buffer_size, dtype=np.float32)\n",
    "        \n",
    "    def remember(self,state,action,reward,state_, done):\n",
    "        # once we hit buffer_size entries, we want to add it to the beginning \n",
    "        index = self.buffer_position % self.buffer_size\n",
    "        \n",
    "        self.states[index] = state\n",
    "        self.new_states[index] = state_\n",
    "        self.rewards[index] = reward\n",
    "        self.dones[index] = 1- int(done)\n",
    "        \n",
    "        # When discrete store one hot\n",
    "        if self.discrete:\n",
    "            actions = np.zeros(self.actions.shape[1])\n",
    "            actions[action] = 1.0 \n",
    "            self.actions[index] = actions\n",
    "        else:\n",
    "            self.actions[index] = action\n",
    "        \n",
    "        self.buffer_position +=1\n",
    "        \n",
    "    def sample(self, batch_size=32):\n",
    "        max_position = min(self.buffer_position, self.buffer_size)\n",
    "        batch = np.random.choice(max_position, batch_size)\n",
    "        \n",
    "        states = self.states[batch]\n",
    "        states_ = self.new_states[batch]\n",
    "        rewards = self.rewards[batch]\n",
    "        dones = self.dones[batch]\n",
    "        actions = self.actions[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9d36dda0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:08:09.696633Z",
     "start_time": "2022-07-21T17:08:09.673415Z"
    }
   },
   "outputs": [],
   "source": [
    "class DqnAgent():\n",
    "    def __init__(\n",
    "        self,\n",
    "        environment,\n",
    "        alpha = 0.0005,\n",
    "        gamma = 0.99,\n",
    "        epsilon = 1.0,\n",
    "        epsilon_decay=0.9996,\n",
    "        \n",
    "        buffer_size=1000000,\n",
    "        batch_size=64,\n",
    "        optimizer = Adam(learning_rate=0.0005),\n",
    "        fully_connected_layer_configuration = 'MlpPolicy',\n",
    "    ):\n",
    "        # Args\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # Environment\n",
    "        env = GymEnvironment(environment)\n",
    "        self.env = env.env\n",
    "        self.n_actions = env.n_actions\n",
    "        self.actions = env.actions\n",
    "        self.observation_shape = env.observation_shape\n",
    "        self.action_space_mode = env.action_space_mode\n",
    "    \n",
    "        # Boot\n",
    "        self.__init_model() \n",
    "        self.__init_memory(env)\n",
    "        \n",
    "    def __init_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(256, input_shape=self.observation_shape, activation=\"relu\"),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(self.n_actions)\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer=self.optimizer, loss=\"mse\")\n",
    "        \n",
    "        #self.model = model\n",
    "        self.q_eval = model\n",
    "        \n",
    "    def __init_memory(self,environment):\n",
    "        self.memory = ReplayBuffer(environment,self.buffer_size)\n",
    "        \n",
    "    def decrement_eps(self):\n",
    "        self.epsilon = self.epsilon * self.epsilon_decay if self.epsilon > 0.01 else 0.01\n",
    "        \n",
    "    def remember(self,state,action,reward,new_state,done):\n",
    "        self.memory.remember(state,action,reward,new_state,done)\n",
    "        \n",
    "    def get_state(self,obs):\n",
    "        return obs\n",
    "        \n",
    "    def choose_action(self,state):\n",
    "        state = state[np.newaxis,:]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            if self.action_space_mode == \"Discrete\":\n",
    "                action = np.random.choice(self.actions)\n",
    "            else:\n",
    "                action = self.env.action_space.sample()\n",
    "        else:\n",
    "            if self.action_space_mode == \"Discrete\":\n",
    "                actions = self.q_eval.predict(state)\n",
    "                action = np.argmax(actions)\n",
    "            else:\n",
    "                actions = self.q_eval.predict(state)\n",
    "                action = actions\n",
    "            \n",
    "        return action\n",
    "    def replay(self):\n",
    "        if self.memory.buffer_position < self.batch_size:\n",
    "            return\n",
    "        \n",
    "\n",
    "        state, action, reward, new_state, done = self.memory.sample(self.batch_size)\n",
    "\n",
    "        # TODO - this is in discrete only\n",
    "        action_values = np.array(self.actions, dtype=np.int8)\n",
    "        action_indices = np.dot(action,action_values)\n",
    "        \n",
    "        q_eval = self.q_eval.predict(state)\n",
    "        q_next = self.q_eval.predict(new_state)\n",
    "        \n",
    "        q_target = q_eval.copy()\n",
    "        \n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        \n",
    "        q_target[batch_index,action_indices] = reward + self.gamma * np.max(q_next,axis=1)#* done\n",
    "        \n",
    "        q_target = reward + self.gamma * np.max(q_next,axis=1)* done\n",
    "        _ = self.q_eval.fit(state,q_target,verbose=0)\n",
    "        \n",
    "        self.decrement_eps()\n",
    "        \n",
    "    def learn(self, timesteps=-1, success_threshold=150, plot_results=True):\n",
    "        obs = self.env.reset()\n",
    "        \n",
    "        self.total_rewards = []\n",
    "        self.avg_rewards = []\n",
    "        \n",
    "        score = 0\n",
    "        timestep = 0\n",
    "        episode = 0\n",
    "\n",
    "        # Loop condition\n",
    "        def learning_condition():\n",
    "            if timesteps == -1:\n",
    "                return True\n",
    "            else: \n",
    "                return timesteps > timestep\n",
    "        \n",
    "        while learning_condition():\n",
    "\n",
    "            # Choose action\n",
    "            action = self.choose_action(obs)\n",
    "               \n",
    "            # Step\n",
    "            obs_,reward,done, info = self.env.step(action)\n",
    "            \n",
    "            # Get next state\n",
    "            score += reward\n",
    "            \n",
    "            self.remember(obs,action,reward,obs_,done)\n",
    "            obs = obs_\n",
    "            \n",
    "            self.replay()\n",
    "\n",
    "            \n",
    "            if done:\n",
    "                # Loop episode state\n",
    "                if episode % 2 == 0 and episode > 0:\n",
    "                    print('episode',episode,'score',score,'epsilon %:.3f',self.epsilon)\n",
    "                \n",
    "                # Update pointers\n",
    "                self.total_rewards.append(score)\n",
    "                \n",
    "                # Track reward evolution\n",
    "                if len(self.total_rewards) > 100:\n",
    "                    avg_reward = np.mean(self.total_rewards[-100:])\n",
    "                    self.avg_rewards.append(avg_reward)\n",
    "                    \n",
    "                    # Break loop if average reward is greater than success threshold\n",
    "                    if avg_reward > success_threshold:\n",
    "                        print('Agent solved environment at the episode {}'.format(episode))\n",
    "                        break\n",
    "                \n",
    "                # Reset environment\n",
    "                score = 0\n",
    "                episode +=1\n",
    "                obs = self.env.reset()\n",
    "                #state = self.get_state(obs)\n",
    "                \n",
    "            # Update timestep counter\n",
    "            timestep+=1\n",
    "        \n",
    "        if plot_results:\n",
    "            plt.plot(self.avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c387d8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T17:50:27.397762Z",
     "start_time": "2022-07-21T17:08:19.851329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| ---------------------------------\n",
      "| MountainCar-v0\n",
      "| Action space:\n",
      "|   * Discrete with low state-space\n",
      "| Dev notes:\n",
      "|   * Switched _max_episode_steps from 200 to 1000 so \n",
      "|     the agent can explore better.\n",
      "| ----------------------------------------------------------   \n",
      "\n",
      "\n",
      "episode 2 score -1000.0 epsilon %:.3f 0.45341012848884044\n",
      "episode 4 score -1000.0 epsilon %:.3f 0.20369770041952698\n",
      "episode 6 score -600.0 epsilon %:.3f 0.14439725488149371\n",
      "episode 8 score -1000.0 epsilon %:.3f 0.08556390706986079\n",
      "episode 10 score -699.0 epsilon %:.3f 0.043359576568349\n",
      "episode 12 score -1000.0 epsilon %:.3f 0.021077019276257936\n",
      "episode 14 score -1000.0 epsilon %:.3f 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m DqnAgent(environment,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36mDqnAgent.learn\u001b[1;34m(self, timesteps, success_threshold, plot_results)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember(obs,action,reward,obs_,done)\n\u001b[0;32m    131\u001b[0m obs \u001b[38;5;241m=\u001b[39m obs_\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Loop episode state\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m episode \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36mDqnAgent.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m action_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint8)\n\u001b[0;32m     86\u001b[0m action_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(action,action_values)\n\u001b[1;32m---> 88\u001b[0m q_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m q_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_eval\u001b[38;5;241m.\u001b[39mpredict(new_state)\n\u001b[0;32m     91\u001b[0m q_target \u001b[38;5;241m=\u001b[39m q_eval\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\keras\\engine\\training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1981\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1983\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1984\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DqnAgent(environment,batch_size=1024)\n",
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba998ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:18:38.588205Z",
     "start_time": "2022-07-21T16:18:38.575177Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283615c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:57:39.460955Z",
     "start_time": "2022-07-21T16:57:39.460955Z"
    }
   },
   "outputs": [],
   "source": [
    "def environment():\n",
    "    return gym.make('LunarLanderContinuous-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bdd0fa99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:56:36.667762Z",
     "start_time": "2022-07-21T16:56:26.095834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0633368  -0.24367835]\n",
      "[-0.05356975  0.6722458 ]\n",
      "[-0.76528037  0.36938968]\n",
      "[-0.9259187  0.7559831]\n",
      "[0.44720107 0.75970054]\n",
      "[-0.27903184  0.18431884]\n",
      "[0.01356326 0.718217  ]\n",
      "[0.5353247 0.8629306]\n",
      "[-0.5461493  0.5685996]\n",
      "[0.9518825 0.6007192]\n",
      "[-0.1062305   0.79450095]\n",
      "[0.9007106 0.8401727]\n",
      "[-0.11708402  0.8448496 ]\n",
      "[-0.5269093   0.53305244]\n",
      "[0.5354025  0.69721764]\n",
      "[0.35754716 0.13913973]\n",
      "[ 0.0054669 -0.8371688]\n",
      "[-0.8493767  0.8713312]\n",
      "[-0.9293254   0.77524847]\n",
      "[-0.57839215 -0.80573606]\n",
      "[0.96759635 0.10845508]\n",
      "[ 0.4084481  -0.91168207]\n",
      "[-0.4664504 -0.0221516]\n",
      "[-0.28357014 -0.39967752]\n",
      "[-0.31281063 -0.7315502 ]\n",
      "[ 0.62336594 -0.8415845 ]\n",
      "[-0.5840137  -0.21036048]\n",
      "[-0.6302923  -0.31064716]\n",
      "[-0.3825194   0.26230457]\n",
      "[0.02264549 0.5801822 ]\n",
      "[-0.36797705 -0.23173308]\n",
      "[-0.6495363   0.98836005]\n",
      "[ 0.467967  -0.7819958]\n",
      "[-0.68230194  0.21298589]\n",
      "[-0.39990023  0.15090734]\n",
      "[-0.05084972 -0.7535494 ]\n",
      "[0.5978603  0.44560415]\n",
      "[ 0.84613    -0.11139116]\n",
      "[-0.5405891  0.5175358]\n",
      "[ 0.599845   -0.92617303]\n",
      "[-0.01046951  0.18249169]\n",
      "[-0.48697153 -0.402182  ]\n",
      "[0.32038766 0.91143644]\n",
      "[ 0.5745935  -0.36701584]\n",
      "[0.59460354 0.5486389 ]\n",
      "[ 0.44004455 -0.75729436]\n",
      "[-0.62500787  0.13400738]\n",
      "[-0.04603229 -0.7458897 ]\n",
      "[-0.489695  -0.4036722]\n",
      "[-0.35123852  0.5030373 ]\n",
      "[-0.5466644 -0.0475111]\n",
      "[0.54761463 0.5987951 ]\n",
      "[-0.73748845  0.427331  ]\n",
      "[ 0.94454414 -0.29349154]\n",
      "[ 0.7690278 -0.4363534]\n",
      "[ 0.3857704  -0.28871468]\n",
      "[ 0.08442514 -0.8737589 ]\n",
      "[-0.33488777 -0.02869083]\n",
      "[-0.36408705  0.45306987]\n",
      "[ 0.559052   -0.63298255]\n",
      "[0.17194787 0.632194  ]\n",
      "[ 0.04027855 -0.1979794 ]\n",
      "[-0.9543697  0.9600486]\n",
      "[-0.8536643   0.05295158]\n",
      "[-0.77912813  0.21407525]\n",
      "[ 0.11922022 -0.17892615]\n",
      "[-0.49787125  0.4123543 ]\n",
      "[-0.03643165  0.23130104]\n",
      "[ 0.8925715  -0.17790008]\n",
      "[0.7602481  0.20315742]\n",
      "[-0.84287214 -0.9160668 ]\n",
      "[ 0.2741201 -0.5311915]\n",
      "[-0.06968252 -0.7433526 ]\n",
      "[0.2213329 0.7586762]\n",
      "[-0.23343438 -0.73682934]\n",
      "[ 0.08819103 -0.27292237]\n",
      "[-0.83980846  0.10665113]\n",
      "[-0.975131   0.6398419]\n",
      "[-0.43727425  0.77855474]\n",
      "[ 0.91033924 -0.8969167 ]\n",
      "[-0.75593334  0.623875  ]\n",
      "[-0.05251995  0.8683811 ]\n",
      "[-0.15797286 -0.038899  ]\n",
      "[-0.8458094  0.5915258]\n",
      "[-0.71906716  0.45491886]\n",
      "[-0.41942766 -0.1912433 ]\n",
      "[0.22653456 0.28394243]\n",
      "[-0.4154895  -0.03875399]\n",
      "[0.6485289 0.5055083]\n",
      "[0.6977477 0.7878472]\n",
      "[-0.02502714  0.20947854]\n",
      "[ 0.93613696 -0.06586991]\n",
      "[ 0.9375977 -0.7531927]\n",
      "[0.3073812 0.6452776]\n",
      "[ 0.87244725 -0.7917302 ]\n",
      "[-0.21673924  0.843179  ]\n",
      "[-0.1972321  -0.28621083]\n",
      "[0.67299354 0.3126724 ]\n",
      "[0.37996757 0.86293244]\n",
      "[-0.5175692   0.32447782]\n",
      "[-0.36689216  0.24558097]\n",
      "[0.6711687 0.6699888]\n",
      "[0.27113983 0.9754213 ]\n",
      "[-0.2786138  0.6283438]\n",
      "[-0.56539565  0.24409495]\n",
      "[-0.256809   0.9008155]\n",
      "[-0.0646068  -0.01747334]\n",
      "[-0.63276803 -0.16823028]\n",
      "[-0.8533      0.26748174]\n",
      "[-0.6737766  0.4848655]\n",
      "[-0.2545536   0.31074065]\n",
      "[-0.26338753  0.7439692 ]\n",
      "[-0.42745087 -0.8452324 ]\n",
      "[ 0.6196434 -0.4620078]\n",
      "[-0.22805564 -0.22864115]\n",
      "[ 0.9279239 -0.6253022]\n",
      "[0.70955986 0.9688581 ]\n",
      "[ 0.26244143 -0.7230279 ]\n",
      "[-0.86663073 -0.11055603]\n",
      "[0.36376578 0.5943824 ]\n",
      "[ 0.0859075  -0.24645989]\n",
      "[-0.8960458   0.90852505]\n",
      "[-0.8379473  0.8734033]\n",
      "[0.73677033 0.27479798]\n",
      "[-0.640023   -0.49018827]\n",
      "[-0.56504434 -0.8486576 ]\n",
      "[0.98776376 0.10736058]\n",
      "[-0.09399062 -0.7934528 ]\n",
      "[0.29419747 0.7149566 ]\n",
      "[ 0.3632111  -0.61457664]\n",
      "[-0.24829824  0.30857897]\n",
      "[-0.22643425  0.24542105]\n",
      "[ 0.2439279  -0.59096277]\n",
      "[0.5591061 0.9927126]\n",
      "[-0.00240837  0.17187488]\n",
      "[ 0.2484371  -0.00316826]\n",
      "[-0.8673331 -0.9450775]\n",
      "[-0.82150096  0.7368927 ]\n",
      "[-0.7959947   0.70796186]\n",
      "[-0.56775266 -0.04584775]\n",
      "[ 0.43322986 -0.18212414]\n",
      "[0.65617096 0.98107255]\n",
      "[-0.6523179  -0.18858434]\n",
      "[-0.33115485  0.0959276 ]\n",
      "[0.44977748 0.63113767]\n",
      "[-0.46920773  0.5241019 ]\n",
      "[-0.4054498 -0.7443847]\n",
      "[-0.64203995  0.45312244]\n",
      "[0.25198498 0.86710584]\n",
      "[-0.72517174  0.7689595 ]\n",
      "[ 0.6669725 -0.6147144]\n",
      "[ 0.03712709 -0.7006435 ]\n",
      "[-0.6538669   0.16942346]\n",
      "[0.08798211 0.14279535]\n",
      "[0.32263404 0.68103653]\n",
      "[0.91890097 0.92452943]\n",
      "[-0.77455825  0.903295  ]\n",
      "[ 0.50786304 -0.605986  ]\n",
      "[ 0.35594156 -0.9056374 ]\n",
      "[-0.3756675  -0.92939794]\n",
      "[-0.10142477 -0.08239298]\n",
      "[0.98947906 0.9665707 ]\n",
      "[0.11311743 0.71615875]\n",
      "[ 0.39217016 -0.42655116]\n",
      "[-0.8186886   0.94797206]\n",
      "[ 0.17409931 -0.35063073]\n",
      "[ 0.50855714 -0.17812057]\n",
      "[0.26755086 0.7271399 ]\n",
      "[0.20136581 0.61394036]\n",
      "[ 0.94248235 -0.14686649]\n",
      "[0.13325629 0.6254977 ]\n",
      "[ 0.19336468 -0.9931037 ]\n",
      "[-0.18860245 -0.94321537]\n",
      "[-0.31704032  0.16121428]\n",
      "[-0.45394632 -0.19806407]\n",
      "[-0.8373143   0.02310366]\n",
      "[-0.8212188  0.5031504]\n",
      "[-0.41074094  0.61073554]\n",
      "[0.43789646 0.49125206]\n",
      "[ 0.17523974 -0.44920203]\n",
      "[-0.7842593   0.31011793]\n",
      "[ 0.8498366 -0.223514 ]\n",
      "[0.3278225  0.52533066]\n",
      "[ 0.1379586  -0.10851001]\n",
      "[-0.24629334 -0.5542033 ]\n",
      "[ 0.4430529 -0.7459478]\n",
      "[-0.2119463  0.7703739]\n",
      "[ 0.27502906 -0.58975744]\n",
      "[-0.97233856  0.14324562]\n",
      "[0.9718493  0.10234914]\n",
      "[-0.1471999  0.7561777]\n",
      "[-0.32423267  0.4744434 ]\n",
      "[-0.50373805  0.83510107]\n",
      "[ 0.6756696 -0.4090999]\n",
      "[-0.69531274  0.6853053 ]\n",
      "[-0.5120246   0.88545835]\n",
      "[ 0.8005453  -0.68786806]\n",
      "[-0.3088704   0.26726568]\n",
      "[ 0.79715425 -0.3862814 ]\n",
      "[-0.54724985 -0.3517071 ]\n",
      "[-0.06354372 -0.6187712 ]\n",
      "[0.81253815 0.45931667]\n",
      "[ 0.993226   -0.03834887]\n",
      "[0.38511366 0.63899076]\n",
      "[0.1420787  0.35660237]\n",
      "[-0.18394789  0.47944856]\n",
      "[-0.8467634 -0.3553926]\n",
      "[0.90545577 0.3730079 ]\n",
      "[-0.40311253 -0.8023017 ]\n",
      "[0.06877118 0.32068938]\n",
      "[ 0.05098065 -0.94299334]\n",
      "[-0.8867619  -0.83752686]\n",
      "[ 0.16620776 -0.98782694]\n",
      "[0.9099808  0.67398053]\n",
      "[0.03236541 0.06504876]\n",
      "[-0.17949225  0.65884644]\n",
      "[-0.9203043   0.97621185]\n",
      "[-0.4172725   0.42793155]\n",
      "[-0.2648172  -0.14766143]\n",
      "[-0.5600657  -0.00949575]\n",
      "[-0.14051314 -0.02778288]\n",
      "[ 0.32965368 -0.09973892]\n",
      "[ 0.46765757 -0.52479476]\n",
      "[0.7815755 0.8808419]\n",
      "[-0.99357283  0.79800475]\n",
      "[0.33493719 0.8979704 ]\n",
      "[ 0.19287917 -0.33672532]\n",
      "[0.09369555 0.08307365]\n",
      "[0.6681767 0.5631807]\n",
      "[ 0.7933576  -0.81469744]\n",
      "[ 0.48883575 -0.04719844]\n",
      "[-0.75541246 -0.13167155]\n",
      "[ 0.45573032 -0.23893484]\n",
      "[-0.39045367  0.85961044]\n",
      "[0.06556541 0.19548854]\n",
      "[0.27716675 0.6241133 ]\n",
      "[-0.96305424  0.9008324 ]\n",
      "[0.06640924 0.05079929]\n",
      "[-0.22883993 -0.8800688 ]\n",
      "[-0.22366682  0.77510124]\n",
      "[-0.4711494   0.48977607]\n",
      "[-0.06821422 -0.6211244 ]\n",
      "[-0.37144834 -0.36036116]\n",
      "[0.37932602 0.5111124 ]\n",
      "[-0.16504323 -0.7563047 ]\n",
      "[-0.6610365   0.07793782]\n",
      "[0.38322145 0.6409511 ]\n",
      "[0.24041735 0.45682147]\n",
      "[-0.3744937  0.3767679]\n",
      "[ 0.11796217 -0.93241525]\n",
      "[-0.12919448  0.07448963]\n",
      "[0.9839589 0.687274 ]\n",
      "[0.39104748 0.27313244]\n",
      "[-0.07608446 -0.69093937]\n",
      "[ 0.13941953 -0.42958173]\n",
      "[-0.14005794 -0.6090843 ]\n",
      "[-0.5590884 -0.9336651]\n",
      "[-0.66743135 -0.6705309 ]\n",
      "[-0.7785802   0.35911912]\n",
      "[ 0.05204586 -0.5496034 ]\n",
      "[0.3915214 0.2519663]\n",
      "[-0.28270766  0.6685984 ]\n",
      "[-0.9904739  -0.96221554]\n",
      "[ 0.85334903 -0.26420715]\n",
      "[0.8106572  0.89345497]\n",
      "[-0.5189131  0.6417407]\n",
      "[0.39227834 0.4408988 ]\n",
      "[-0.81678116  0.06950931]\n",
      "[ 0.7418097 -0.9462856]\n",
      "[0.5042836  0.85484767]\n",
      "[-0.59729284  0.4902047 ]\n",
      "[-0.09014951  0.776554  ]\n",
      "[0.8479203  0.59126824]\n",
      "[-0.5111161  -0.14898703]\n",
      "[0.39307266 0.7241081 ]\n",
      "[ 0.00243914 -0.24391752]\n",
      "[ 0.33717135 -0.67399335]\n",
      "[-0.47848198  0.40651995]\n",
      "[-0.29093838 -0.5688571 ]\n",
      "[-0.18753216  0.3650759 ]\n",
      "[ 0.64775497 -0.8953187 ]\n",
      "[0.48544854 0.7664331 ]\n",
      "[-0.6728872  -0.57997566]\n",
      "[0.07190549 0.00331928]\n",
      "[-0.76393545 -0.7157754 ]\n",
      "[-0.23491697 -0.48853594]\n",
      "[-0.83830726  0.13372369]\n",
      "[-0.8863737  -0.59286964]\n",
      "[-0.48729226 -0.5580454 ]\n",
      "[-0.09717917 -0.7058113 ]\n",
      "[ 0.85285985 -0.45365995]\n",
      "[0.22231133 0.8285216 ]\n",
      "[ 0.45415962 -0.47871575]\n",
      "episode 2 score -379.1020677511453 epsilon %:.3f 1.0\n",
      "[-0.49694428  0.03292629]\n",
      "[ 0.7725768 -0.5866572]\n",
      "[-0.23670863 -0.9154845 ]\n",
      "[-0.1869881  -0.13940766]\n",
      "[ 0.6764997  -0.94793755]\n",
      "[-0.14718911  0.3532139 ]\n",
      "[0.20259719 0.02289178]\n",
      "[-0.24222508  0.1907139 ]\n",
      "[ 0.97074836 -0.42839384]\n",
      "[-0.0851036   0.47722104]\n",
      "[-0.40594542 -0.06202456]\n",
      "[-0.7206194  -0.34245762]\n",
      "[-0.3816464   0.39292926]\n",
      "[0.8453739  0.81068856]\n",
      "[0.7312409  0.37351435]\n",
      "[-0.06102626 -0.25437596]\n",
      "[-0.9005071   0.35841614]\n",
      "[-0.63086265 -0.2075721 ]\n",
      "[-0.5166193   0.45205134]\n",
      "[ 0.63523465 -0.16742885]\n",
      "[-0.4645355   0.38868976]\n",
      "[-0.12488819 -0.1677945 ]\n",
      "[ 0.32051757 -0.22126985]\n",
      "[-0.5765304  -0.28470013]\n",
      "[ 0.45805353 -0.6357246 ]\n",
      "[0.86017025 0.09724718]\n",
      "[-0.3521025  -0.71465224]\n",
      "[0.04710677 0.9177668 ]\n",
      "[-0.2624799   0.18106101]\n",
      "[-0.23992454  0.45149472]\n",
      "[-0.20192984 -0.54412985]\n",
      "[-0.28590545  0.1577702 ]\n",
      "[-0.26206964  0.6359654 ]\n",
      "[-0.29841387  0.3428851 ]\n",
      "[ 0.10111009 -0.11372914]\n",
      "[0.8826236  0.38548583]\n",
      "[0.25821605 0.27835375]\n",
      "[-0.42869097 -0.9986351 ]\n",
      "[-0.2667691   0.68534076]\n",
      "[ 0.32445672 -0.43511802]\n",
      "[-0.08807196 -0.17376617]\n",
      "[ 0.5100487  -0.25589597]\n",
      "[ 0.759189   -0.81124383]\n",
      "[-0.74932635 -0.06123646]\n",
      "[-0.97357714  0.8935014 ]\n",
      "[0.8571232 0.5063055]\n",
      "[0.2558115  0.06202657]\n",
      "[ 0.6697456  -0.39238745]\n",
      "[ 0.65891397 -0.41414052]\n",
      "[0.02625421 0.32255387]\n",
      "[0.2607263  0.51733476]\n",
      "[ 0.3923108  -0.29620108]\n",
      "[ 0.57028097 -0.7339906 ]\n",
      "[-0.36748508 -0.05283597]\n",
      "[0.54700786 0.45798665]\n",
      "[-0.12940454  0.6099483 ]\n",
      "[ 0.3977709  -0.30481777]\n",
      "[-0.80504656  0.3954222 ]\n",
      "[-0.22406998  0.5458782 ]\n",
      "[-0.97298634 -0.904392  ]\n",
      "[0.86181283 0.9432121 ]\n",
      "[0.96362245 0.3679718 ]\n",
      "[0.8449875  0.78529614]\n",
      "[0.04162678 0.7228046 ]\n",
      "[-0.36562136  0.42996648]\n",
      "[-0.28890076 -0.02933914]\n",
      "[0.44491556 0.8176274 ]\n",
      "[0.9714829  0.07799283]\n",
      "[ 0.14566468 -0.8889369 ]\n",
      "[-0.59601     0.25648326]\n",
      "[0.28612897 0.54480517]\n",
      "[-0.74877846  0.26511544]\n",
      "[-0.50560284 -0.20946999]\n",
      "[-0.14989409 -0.37991267]\n",
      "[ 0.7344906  -0.01724908]\n",
      "[-0.07419674 -0.48874605]\n",
      "[-0.31344837 -0.9504258 ]\n",
      "[-0.54180664  0.1780104 ]\n",
      "[ 0.92092484 -0.6816516 ]\n",
      "[-0.3814468   0.22039013]\n",
      "[-0.38636053  0.78529406]\n",
      "[ 0.99430084 -0.68234897]\n",
      "[ 0.3708411  -0.56637263]\n",
      "[ 0.13573794 -0.0542807 ]\n",
      "[-0.33086753 -0.9822775 ]\n",
      "[-0.49124196  0.15811852]\n",
      "[ 0.3058665  -0.51384586]\n",
      "[0.0830939 0.579941 ]\n",
      "[ 0.87077844 -0.1425638 ]\n",
      "[0.4888654  0.13295484]\n",
      "[-0.43978223  0.84355545]\n",
      "[-0.06352108  0.5105214 ]\n",
      "[-0.2998263 -0.6703259]\n",
      "[0.3893545  0.22380018]\n",
      "[0.68750787 0.3340252 ]\n",
      "[ 0.6777648  -0.44909868]\n",
      "[0.7202286  0.01164704]\n",
      "[-0.11911681  0.0535932 ]\n",
      "[-0.5099171   0.67337626]\n",
      "[-0.2332159  -0.95467824]\n",
      "[0.55349   0.4764347]\n",
      "[-0.94326323 -0.96946144]\n",
      "[0.6984572 0.299825 ]\n",
      "[0.32077235 0.27072164]\n",
      "[ 0.07970197 -0.40430334]\n",
      "[-0.06033608 -0.20096396]\n",
      "[ 0.60854477 -0.10368793]\n",
      "[-0.03500132  0.18323138]\n",
      "[-0.17192975 -0.83152264]\n",
      "[-0.3054574  -0.79990685]\n",
      "[-0.5727115  0.9083393]\n",
      "[-0.8965405  -0.17538981]\n",
      "[-0.43641156  0.09785145]\n",
      "[ 0.8802965 -0.1315957]\n",
      "[-0.53536457  0.07715865]\n",
      "[0.2141403 0.2384779]\n",
      "[ 0.14275198 -0.42826006]\n",
      "[-0.39594203 -0.4797868 ]\n",
      "[-0.35364354 -0.16411358]\n",
      "[-0.8373452   0.58572525]\n",
      "[-0.7653      0.99728054]\n",
      "[ 0.40597713 -0.84313506]\n",
      "[-0.58539397  0.41045216]\n",
      "[-0.8202085  -0.94523305]\n",
      "[-0.41571793 -0.366716  ]\n",
      "[ 0.00838379 -0.74216366]\n",
      "[ 0.48286062 -0.7312824 ]\n",
      "[-0.9373729  0.838488 ]\n",
      "[-0.47554958  0.29105163]\n",
      "[-0.3071119 -0.1432047]\n",
      "[0.73531747 0.815589  ]\n",
      "[-0.33754092 -0.4170738 ]\n",
      "[ 0.4088077  -0.97327155]\n",
      "[0.5346744  0.54003173]\n",
      "[0.2088853  0.94811296]\n",
      "[ 0.77347356 -0.49867192]\n",
      "[0.78089076 0.949603  ]\n",
      "[0.47051418 0.28516862]\n",
      "[-0.9572641 -0.6445693]\n",
      "[-0.92256755 -0.4580553 ]\n",
      "[-0.7253078   0.49964064]\n",
      "[-0.19656806  0.22702481]\n",
      "[-0.48274037  0.39464992]\n",
      "[0.5716053  0.83470446]\n",
      "[-0.05893707  0.46482593]\n",
      "[ 0.8450272  -0.42726862]\n",
      "[-0.39261657  0.6051651 ]\n",
      "[0.11198355 0.89360356]\n",
      "[-0.01507795 -0.35509256]\n",
      "[-0.9831379   0.28226787]\n",
      "[-0.98485667  0.8327094 ]\n",
      "[-0.6791514  0.2922624]\n",
      "[0.8494846  0.40531933]\n",
      "[ 0.525713   -0.37457514]\n",
      "[ 0.2802145 -0.7630413]\n",
      "[0.31563488 0.3728543 ]\n",
      "[0.20095949 0.15865861]\n",
      "[ 0.74393606 -0.4150018 ]\n",
      "[0.9951253  0.41436866]\n",
      "[-0.9841333   0.26943174]\n",
      "[ 0.37433812 -0.6778847 ]\n",
      "[-0.69990283  0.7623824 ]\n",
      "[ 0.5947283 -0.1405878]\n",
      "[ 0.50124854 -0.04948179]\n",
      "[0.66840124 0.5726784 ]\n",
      "[0.46618935 0.7917468 ]\n",
      "[0.23719114 0.8060404 ]\n",
      "[0.16692762 0.8894369 ]\n",
      "[-0.80111337  0.18998094]\n",
      "[ 0.62621623 -0.46367866]\n",
      "[ 0.51860976 -0.8864442 ]\n",
      "[ 0.27887335 -0.8735767 ]\n",
      "[0.78559095 0.17156975]\n",
      "[-0.23873201  0.55537915]\n",
      "[ 0.70174426 -0.6160677 ]\n",
      "[-0.3966805   0.61695653]\n",
      "[0.19565462 0.04753077]\n",
      "[ 0.01169546 -0.70575064]\n",
      "[ 0.36211187 -0.2796983 ]\n",
      "[ 0.490036   -0.10295286]\n",
      "[-0.30902547 -0.9077754 ]\n",
      "[ 0.47618484 -0.8441846 ]\n",
      "[0.8408566 0.6569629]\n",
      "[0.02195534 0.8558549 ]\n",
      "[0.5050156  0.03032772]\n",
      "[ 0.7189492  -0.37643796]\n",
      "[-0.74681324  0.08683124]\n",
      "[-0.23985538 -0.9859448 ]\n",
      "[0.9212405  0.01404697]\n",
      "[0.83791095 0.3092742 ]\n",
      "[-0.4841277 -0.2601857]\n",
      "[-0.6982178  -0.27445287]\n",
      "[-0.8221952  0.2576552]\n",
      "[-0.5406268  -0.81656283]\n",
      "[ 0.13702211 -0.99653476]\n",
      "[0.78175837 0.5952568 ]\n",
      "[-0.893881    0.21618302]\n",
      "[ 0.18404374 -0.47952566]\n",
      "[-0.6550532  -0.38338372]\n",
      "[-0.6647828   0.97116417]\n",
      "[-0.15538225 -0.14908391]\n",
      "[0.46028602 0.41019556]\n",
      "[-0.4925223  0.0845957]\n",
      "[-0.32144392 -0.21464819]\n",
      "[0.9906067 0.5028175]\n",
      "[0.34186348 0.09899425]\n",
      "[-0.12240704  0.714998  ]\n",
      "[-0.8874113  -0.26667783]\n",
      "[-0.9875999 -0.5784828]\n",
      "[0.8045635  0.24809772]\n",
      "[0.69649553 0.8271646 ]\n",
      "[-0.33194357  0.58612216]\n",
      "[-0.93905437 -0.89119637]\n",
      "[0.3050593 0.0308545]\n",
      "[-0.87290126  0.32920682]\n",
      "[-0.05741521 -0.7040835 ]\n",
      "[-0.69365746 -0.8921476 ]\n",
      "[0.02556157 0.5640366 ]\n",
      "[0.4916781 0.8478538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08823588  0.04737251]\n",
      "[-0.29108357  0.36126688]\n",
      "[-0.06398269 -0.29433268]\n",
      "[-0.27063945  0.968677  ]\n",
      "[ 0.54183125 -0.3955426 ]\n",
      "[0.8702851  0.08683275]\n",
      "[-0.15497018 -0.20516816]\n",
      "[-0.96203834  0.9395652 ]\n",
      "[-0.894422   0.2778901]\n",
      "[-0.14765032 -0.44220752]\n",
      "[-0.8250152 -0.6316387]\n",
      "[-0.86882013  0.42715898]\n",
      "[0.2798227  0.07811061]\n",
      "[-0.28510845  0.8460584 ]\n",
      "[0.86331856 0.20642674]\n",
      "[-0.6045139  -0.19660573]\n",
      "[-0.86337656  0.11353471]\n",
      "[-0.35388586  0.2896628 ]\n",
      "[ 0.18539    -0.38323602]\n",
      "[-0.65724456  0.7050641 ]\n",
      "[0.9031156  0.69637114]\n",
      "[-0.11701062 -0.2720563 ]\n",
      "[0.15340726 0.33954063]\n",
      "[-0.3763001 -0.8923053]\n",
      "[-0.9544976  -0.14179796]\n",
      "[-0.7639739 -0.8687708]\n",
      "[-0.3007412  0.4346523]\n",
      "episode 4 score -210.12410759287064 epsilon %:.3f 0.9888602708591564\n",
      "[-0.15633708  0.34083796]\n",
      "[0.0335612 0.6538079]\n",
      "[0.19526497 0.7073592 ]\n",
      "[0.9232765  0.45447588]\n",
      "[ 0.05069947 -0.6821521 ]\n",
      "[-0.77955055 -0.9266228 ]\n",
      "[-0.02339509 -0.26199716]\n",
      "[-0.08718321  0.9983971 ]\n",
      "[ 0.9572237  -0.37933457]\n",
      "[-0.4100904  -0.35647747]\n",
      "[-0.3126762 -0.7947548]\n",
      "[ 0.36837205 -0.50163025]\n",
      "[-0.9140061   0.23506753]\n",
      "[ 0.3532724 -0.7777492]\n",
      "[ 0.27352434 -0.79862165]\n",
      "[-0.22033575 -0.6981674 ]\n",
      "[ 0.14582722 -0.10632627]\n",
      "[ 0.3789996 -0.2507074]\n",
      "[-0.2981909  -0.39903137]\n",
      "[-0.94998884 -0.88769245]\n",
      "[0.3514239  0.87686694]\n",
      "[ 0.9949545  -0.38164374]\n",
      "[ 0.6883085  -0.30688757]\n",
      "[-0.8936476   0.18387462]\n",
      "[ 0.2308792  -0.57195675]\n",
      "[-0.20430034 -0.19136488]\n",
      "[ 0.16732469 -0.43890947]\n",
      "[-0.96754706  0.9712868 ]\n",
      "[-0.20222643 -0.18664174]\n",
      "[-0.7100059  0.2164224]\n",
      "[-0.49895698  0.19709018]\n",
      "[ 0.6408506 -0.6402474]\n",
      "[ 0.19562426 -0.06359117]\n",
      "[ 0.24143763 -0.66043514]\n",
      "[-0.68980473 -0.72211367]\n",
      "[-0.172108   -0.11913767]\n",
      "[-0.55014765  0.5791534 ]\n",
      "[ 0.11651455 -0.80294293]\n",
      "[0.05006757 0.46872228]\n",
      "[-0.6010496   0.52729666]\n",
      "[-0.90561926 -0.8266801 ]\n",
      "[-0.05365135 -0.11149894]\n",
      "[0.31476098 0.07274663]\n",
      "[[-131.08247 -131.02219]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m agent2 \u001b[38;5;241m=\u001b[39m DqnAgent(environment,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43magent2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [123]\u001b[0m, in \u001b[0;36mDqnAgent.learn\u001b[1;34m(self, timesteps, success_threshold, plot_results)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Step\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m obs_,reward,done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Get next state\u001b[39;00m\n\u001b[0;32m    131\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\gym\\wrappers\\time_limit.py:17\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m---> 17\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:13\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observation, reward, done, info\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai_4\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:339\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    336\u001b[0m dispersion \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnp_random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m SCALE \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m    338\u001b[0m m_power \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mand\u001b[39;00m \u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mand\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    341\u001b[0m ):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# Main engine\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous:\n\u001b[0;32m    344\u001b[0m         m_power \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mclip(action[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# 0.5..1.0\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "agent2 = DqnAgent(environment,batch_size=512)\n",
    "agent2.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8e27f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:55:17.479651Z",
     "start_time": "2022-07-21T16:55:17.479651Z"
    }
   },
   "outputs": [],
   "source": [
    "gym.make('LunarLanderContinuous-v2').action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5938e485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:04:22.477571Z",
     "start_time": "2022-07-21T16:04:22.455794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.2882689e-04,  1.4102881e+00,  2.2365194e-02,  4.8845876e-02,\n",
       "        -2.1515167e-03, -4.0259656e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       dtype=float32),\n",
       " 1.8001698641777761,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.step([0.9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3503316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:05:08.453518Z",
     "start_time": "2022-07-21T16:05:07.695100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04110719, -0.17545287]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q_eval.predict(np.expand_dims(agent.env.reset(),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27fb36de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:06:39.456794Z",
     "start_time": "2022-07-21T16:06:39.446559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00695028,  1.4209193 , -0.7040039 ,  0.4443818 ,  0.00806044,\n",
       "         0.1594675 ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.reset()[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5482f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:07:37.522757Z",
     "start_time": "2022-07-21T16:07:37.511750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2968304 , -0.19083126], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33323dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
