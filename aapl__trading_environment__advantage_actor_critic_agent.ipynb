{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c22e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T12:50:09.432185Z",
     "start_time": "2022-08-10T12:50:08.888672Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutup\n",
    "shutup.please()\n",
    "\n",
    "import gym\n",
    "import src.environments.continuous.stock_trading  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682ec5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T15:21:01.332156Z",
     "start_time": "2022-08-08T15:20:59.717151Z"
    }
   },
   "source": [
    "### Train the agent\n",
    "* Run it until he has a running average above the success_threshold\n",
    "* Use a large number of episodes for the running average ( 1000+ ) so if even it falls into a privileged sample, it wont be prone to error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab573ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T12:50:09.447774Z",
     "start_time": "2022-08-10T12:50:09.434186Z"
    }
   },
   "outputs": [],
   "source": [
    "def environment():\n",
    "    env = gym.make('StockTradingEnvironment-v0',\n",
    "        use_technical_indicators= [\n",
    "        \"macd\",\n",
    "        \"boll_ub\",\n",
    "        \"boll_lb\",\n",
    "        \"rsi_30\",\n",
    "        \"cci_30\",\n",
    "        \"dx_30\",\n",
    "        \"close_30_sma\",\n",
    "        \"close_60_sma\",\n",
    "    ])\n",
    "    \n",
    "    poc_threshold = 0.1 # 10% \n",
    "    print('* Original success threshold', env.success_threshold)\n",
    "    \n",
    "    print('* POC success threshold', poc_threshold)\n",
    "    print()\n",
    "    \n",
    "    env.success_threshold = poc_threshold\n",
    "    return env\n",
    "\n",
    "# from src.environments.continuous.trading import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07d5538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T12:50:12.865387Z",
     "start_time": "2022-08-10T12:50:09.448776Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.agents.actor_critic.a2c import A2CAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f83292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T12:50:14.292509Z",
     "start_time": "2022-08-10T12:50:12.868387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Original success threshold 0.0855973435323849\n",
      "* POC success threshold 0.1\n",
      "\n",
      "@TODO Agent._load_agent_configuration()\n"
     ]
    }
   ],
   "source": [
    "agent=A2CAgent(environment, epochs=1, actor_learning_rate=0.000025,critic_learning_rate=0.000025,policy=\"CNN\")\n",
    "agent.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85947b8a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 100 * Moving Avg Reward is ==> 0.04352 * Last Reward was ==> -0.12891 \n",
      "Episode * 200 * Moving Avg Reward is ==> 0.05082 * Last Reward was ==> 0.07479 \n",
      "Episode * 300 * Moving Avg Reward is ==> 0.05965 * Last Reward was ==> 0.29955 \n",
      "Episode * 400 * Moving Avg Reward is ==> 0.06660 * Last Reward was ==> 0.15068 \n",
      "Episode * 500 * Moving Avg Reward is ==> 0.06391 * Last Reward was ==> 0.28067 \n",
      "Episode * 600 * Moving Avg Reward is ==> 0.05900 * Last Reward was ==> 0.22462 \n",
      "Episode * 700 * Moving Avg Reward is ==> 0.05861 * Last Reward was ==> 0.25963 \n",
      "Episode * 800 * Moving Avg Reward is ==> 0.05862 * Last Reward was ==> 0.01233 \n",
      "Episode * 900 * Moving Avg Reward is ==> 0.05671 * Last Reward was ==> -0.22894 \n",
      "Episode * 1000 * Moving Avg Reward is ==> 0.05806 * Last Reward was ==> -0.04058 \n",
      "Episode * 1100 * Moving Avg Reward is ==> 0.05752 * Last Reward was ==> -0.12966 * Total episodes ending on loss: 398/1000 \n",
      "Episode * 1200 * Moving Avg Reward is ==> 0.05718 * Last Reward was ==> 0.30996 * Total episodes ending on loss: 411/1000 \n",
      "Episode * 1300 * Moving Avg Reward is ==> 0.05438 * Last Reward was ==> -0.09097 * Total episodes ending on loss: 426/1000 \n",
      "Episode * 1400 * Moving Avg Reward is ==> 0.05146 * Last Reward was ==> 0.25450 * Total episodes ending on loss: 430/1000 \n",
      "Episode * 1500 * Moving Avg Reward is ==> 0.05006 * Last Reward was ==> -0.19110 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 1600 * Moving Avg Reward is ==> 0.05316 * Last Reward was ==> 0.20276 * Total episodes ending on loss: 423/1000 \n",
      "Episode * 1700 * Moving Avg Reward is ==> 0.05404 * Last Reward was ==> 0.25531 * Total episodes ending on loss: 428/1000 \n",
      "Episode * 1800 * Moving Avg Reward is ==> 0.05183 * Last Reward was ==> -0.01771 * Total episodes ending on loss: 438/1000 \n",
      "Episode * 1900 * Moving Avg Reward is ==> 0.05214 * Last Reward was ==> 0.25450 * Total episodes ending on loss: 435/1000 \n",
      "Episode * 2000 * Moving Avg Reward is ==> 0.04918 * Last Reward was ==> 0.00897 * Total episodes ending on loss: 441/1000 \n",
      "Episode * 2100 * Moving Avg Reward is ==> 0.05183 * Last Reward was ==> 0.08191 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 2200 * Moving Avg Reward is ==> 0.05144 * Last Reward was ==> 0.23386 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 2300 * Moving Avg Reward is ==> 0.05258 * Last Reward was ==> -0.00437 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 2400 * Moving Avg Reward is ==> 0.05358 * Last Reward was ==> 0.26487 * Total episodes ending on loss: 420/1000 \n",
      "Episode * 2500 * Moving Avg Reward is ==> 0.05826 * Last Reward was ==> -0.21293 * Total episodes ending on loss: 413/1000 \n",
      "Episode * 2600 * Moving Avg Reward is ==> 0.05807 * Last Reward was ==> 0.00850 * Total episodes ending on loss: 412/1000 \n",
      "Episode * 2700 * Moving Avg Reward is ==> 0.05407 * Last Reward was ==> 0.13820 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 2800 * Moving Avg Reward is ==> 0.05694 * Last Reward was ==> -0.16008 * Total episodes ending on loss: 410/1000 \n",
      "Episode * 2900 * Moving Avg Reward is ==> 0.05790 * Last Reward was ==> -0.09347 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 3000 * Moving Avg Reward is ==> 0.06124 * Last Reward was ==> 0.17137 * Total episodes ending on loss: 399/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06281\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06319\n",
      "\n",
      "Episode * 3100 * Moving Avg Reward is ==> 0.06149 * Last Reward was ==> 0.24257 * Total episodes ending on loss: 400/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06336\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06358\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06388\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06414\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06453\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06468\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06475\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06477\n",
      "\n",
      "Episode * 3200 * Moving Avg Reward is ==> 0.06044 * Last Reward was ==> 0.14567 * Total episodes ending on loss: 400/1000 \n",
      "Episode * 3300 * Moving Avg Reward is ==> 0.05935 * Last Reward was ==> 0.15541 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 3400 * Moving Avg Reward is ==> 0.05808 * Last Reward was ==> 0.19756 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 3500 * Moving Avg Reward is ==> 0.05725 * Last Reward was ==> -0.06312 * Total episodes ending on loss: 402/1000 \n",
      "Episode * 3600 * Moving Avg Reward is ==> 0.05695 * Last Reward was ==> 0.13281 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 3700 * Moving Avg Reward is ==> 0.06240 * Last Reward was ==> -0.20292 * Total episodes ending on loss: 389/1000 \n",
      "Episode * 3800 * Moving Avg Reward is ==> 0.05980 * Last Reward was ==> -0.17787 * Total episodes ending on loss: 396/1000 \n",
      "Episode * 3900 * Moving Avg Reward is ==> 0.06166 * Last Reward was ==> 0.27698 * Total episodes ending on loss: 392/1000 \n",
      "Episode * 4000 * Moving Avg Reward is ==> 0.05925 * Last Reward was ==> 0.13927 * Total episodes ending on loss: 398/1000 \n",
      "Episode * 4100 * Moving Avg Reward is ==> 0.05536 * Last Reward was ==> -0.15273 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 4200 * Moving Avg Reward is ==> 0.05699 * Last Reward was ==> 0.17072 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 4300 * Moving Avg Reward is ==> 0.05813 * Last Reward was ==> 0.02279 * Total episodes ending on loss: 404/1000 \n",
      "Episode * 4400 * Moving Avg Reward is ==> 0.05762 * Last Reward was ==> 0.29499 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 4500 * Moving Avg Reward is ==> 0.05760 * Last Reward was ==> -0.19477 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 4600 * Moving Avg Reward is ==> 0.05685 * Last Reward was ==> -0.18828 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 4700 * Moving Avg Reward is ==> 0.05190 * Last Reward was ==> 0.27743 * Total episodes ending on loss: 420/1000 \n",
      "Episode * 4800 * Moving Avg Reward is ==> 0.05269 * Last Reward was ==> -0.21222 * Total episodes ending on loss: 416/1000 \n",
      "Episode * 4900 * Moving Avg Reward is ==> 0.05141 * Last Reward was ==> 0.31801 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 5000 * Moving Avg Reward is ==> 0.05073 * Last Reward was ==> 0.26077 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 5100 * Moving Avg Reward is ==> 0.05091 * Last Reward was ==> -0.07717 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 5200 * Moving Avg Reward is ==> 0.04809 * Last Reward was ==> 0.22090 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 5300 * Moving Avg Reward is ==> 0.04833 * Last Reward was ==> 0.07960 * Total episodes ending on loss: 425/1000 \n",
      "Episode * 5400 * Moving Avg Reward is ==> 0.05204 * Last Reward was ==> -0.15357 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 5500 * Moving Avg Reward is ==> 0.05311 * Last Reward was ==> 0.02438 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 5600 * Moving Avg Reward is ==> 0.05027 * Last Reward was ==> -0.16588 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 5700 * Moving Avg Reward is ==> 0.05260 * Last Reward was ==> 0.22090 * Total episodes ending on loss: 429/1000 \n",
      "Episode * 5800 * Moving Avg Reward is ==> 0.05601 * Last Reward was ==> -0.19607 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 5900 * Moving Avg Reward is ==> 0.05616 * Last Reward was ==> 0.15056 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 6000 * Moving Avg Reward is ==> 0.05614 * Last Reward was ==> -0.21355 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 6100 * Moving Avg Reward is ==> 0.05759 * Last Reward was ==> -0.06532 * Total episodes ending on loss: 412/1000 \n",
      "Episode * 6200 * Moving Avg Reward is ==> 0.05782 * Last Reward was ==> -0.16876 * Total episodes ending on loss: 413/1000 \n",
      "Episode * 6300 * Moving Avg Reward is ==> 0.05326 * Last Reward was ==> -0.19245 * Total episodes ending on loss: 424/1000 \n",
      "Episode * 6400 * Moving Avg Reward is ==> 0.04944 * Last Reward was ==> 0.27743 * Total episodes ending on loss: 430/1000 \n",
      "Episode * 6500 * Moving Avg Reward is ==> 0.04563 * Last Reward was ==> 0.27015 * Total episodes ending on loss: 437/1000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 6600 * Moving Avg Reward is ==> 0.04639 * Last Reward was ==> 0.18563 * Total episodes ending on loss: 432/1000 \n",
      "Episode * 6700 * Moving Avg Reward is ==> 0.05010 * Last Reward was ==> 0.32117 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 6800 * Moving Avg Reward is ==> 0.04722 * Last Reward was ==> -0.18897 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 6900 * Moving Avg Reward is ==> 0.04635 * Last Reward was ==> 0.27015 * Total episodes ending on loss: 430/1000 \n",
      "Episode * 7000 * Moving Avg Reward is ==> 0.05132 * Last Reward was ==> 0.11440 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 7100 * Moving Avg Reward is ==> 0.05252 * Last Reward was ==> -0.10265 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 7200 * Moving Avg Reward is ==> 0.05456 * Last Reward was ==> 0.26785 * Total episodes ending on loss: 413/1000 \n",
      "Episode * 7300 * Moving Avg Reward is ==> 0.05851 * Last Reward was ==> -0.16198 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 7400 * Moving Avg Reward is ==> 0.05598 * Last Reward was ==> 0.33276 * Total episodes ending on loss: 414/1000 \n",
      "Episode * 7500 * Moving Avg Reward is ==> 0.05867 * Last Reward was ==> 0.19099 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 7600 * Moving Avg Reward is ==> 0.06313 * Last Reward was ==> -0.22918 * Total episodes ending on loss: 394/1000 \n",
      "Episode * 7700 * Moving Avg Reward is ==> 0.05876 * Last Reward was ==> 0.00404 * Total episodes ending on loss: 402/1000 \n",
      "Episode * 7800 * Moving Avg Reward is ==> 0.06232 * Last Reward was ==> 0.22226 * Total episodes ending on loss: 391/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06488\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06509\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06541\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06555\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06560\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06563\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06585\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06609\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06618\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06651\n",
      "\n",
      "Episode * 7900 * Moving Avg Reward is ==> 0.06393 * Last Reward was ==> 0.18307 * Total episodes ending on loss: 389/1000 \n",
      "Episode * 8000 * Moving Avg Reward is ==> 0.06108 * Last Reward was ==> 0.14049 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 8100 * Moving Avg Reward is ==> 0.06246 * Last Reward was ==> 0.02227 * Total episodes ending on loss: 399/1000 \n",
      "Episode * 8200 * Moving Avg Reward is ==> 0.06046 * Last Reward was ==> -0.20097 * Total episodes ending on loss: 400/1000 \n",
      "Episode * 8300 * Moving Avg Reward is ==> 0.05814 * Last Reward was ==> -0.08502 * Total episodes ending on loss: 408/1000 \n",
      "Episode * 8400 * Moving Avg Reward is ==> 0.06569 * Last Reward was ==> -0.02726 * Total episodes ending on loss: 388/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06681\n",
      "\n",
      "Episode * 8500 * Moving Avg Reward is ==> 0.06409 * Last Reward was ==> 0.15813 * Total episodes ending on loss: 391/1000 \n",
      "Episode * 8600 * Moving Avg Reward is ==> 0.06140 * Last Reward was ==> 0.22371 * Total episodes ending on loss: 397/1000 \n",
      "Episode * 8700 * Moving Avg Reward is ==> 0.06091 * Last Reward was ==> 0.29955 * Total episodes ending on loss: 401/1000 \n",
      "Episode * 8800 * Moving Avg Reward is ==> 0.05803 * Last Reward was ==> -0.21423 * Total episodes ending on loss: 410/1000 \n",
      "Episode * 8900 * Moving Avg Reward is ==> 0.05729 * Last Reward was ==> -0.09105 * Total episodes ending on loss: 410/1000 \n",
      "Episode * 9000 * Moving Avg Reward is ==> 0.05589 * Last Reward was ==> 0.30996 * Total episodes ending on loss: 411/1000 \n",
      "Episode * 9100 * Moving Avg Reward is ==> 0.05312 * Last Reward was ==> 0.30153 * Total episodes ending on loss: 416/1000 \n",
      "Episode * 9200 * Moving Avg Reward is ==> 0.05517 * Last Reward was ==> -0.06532 * Total episodes ending on loss: 411/1000 \n",
      "Episode * 9300 * Moving Avg Reward is ==> 0.05660 * Last Reward was ==> -0.20097 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 9400 * Moving Avg Reward is ==> 0.05177 * Last Reward was ==> 0.26033 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 9500 * Moving Avg Reward is ==> 0.05146 * Last Reward was ==> 0.25317 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 9600 * Moving Avg Reward is ==> 0.04688 * Last Reward was ==> -0.15695 * Total episodes ending on loss: 440/1000 \n",
      "Episode * 9700 * Moving Avg Reward is ==> 0.04743 * Last Reward was ==> -0.15270 * Total episodes ending on loss: 438/1000 \n",
      "Episode * 9800 * Moving Avg Reward is ==> 0.04592 * Last Reward was ==> 0.30996 * Total episodes ending on loss: 439/1000 \n",
      "Episode * 9900 * Moving Avg Reward is ==> 0.04419 * Last Reward was ==> -0.11148 * Total episodes ending on loss: 447/1000 \n",
      "Episode * 10000 * Moving Avg Reward is ==> 0.04374 * Last Reward was ==> -0.19070 * Total episodes ending on loss: 447/1000 \n",
      "Episode * 10100 * Moving Avg Reward is ==> 0.04492 * Last Reward was ==> -0.15270 * Total episodes ending on loss: 443/1000 \n",
      "Episode * 10200 * Moving Avg Reward is ==> 0.04860 * Last Reward was ==> 0.30120 * Total episodes ending on loss: 438/1000 \n",
      "Episode * 10300 * Moving Avg Reward is ==> 0.04881 * Last Reward was ==> -0.19110 * Total episodes ending on loss: 440/1000 \n",
      "Episode * 10400 * Moving Avg Reward is ==> 0.04670 * Last Reward was ==> 0.27951 * Total episodes ending on loss: 446/1000 \n",
      "Episode * 10500 * Moving Avg Reward is ==> 0.04676 * Last Reward was ==> 0.15247 * Total episodes ending on loss: 442/1000 \n",
      "Episode * 10600 * Moving Avg Reward is ==> 0.05117 * Last Reward was ==> -0.07103 * Total episodes ending on loss: 422/1000 \n",
      "Episode * 10700 * Moving Avg Reward is ==> 0.05260 * Last Reward was ==> 0.15586 * Total episodes ending on loss: 416/1000 \n",
      "Episode * 10800 * Moving Avg Reward is ==> 0.05605 * Last Reward was ==> -0.15357 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 10900 * Moving Avg Reward is ==> 0.05935 * Last Reward was ==> 0.30436 * Total episodes ending on loss: 402/1000 \n",
      "Episode * 11000 * Moving Avg Reward is ==> 0.06031 * Last Reward was ==> -0.04970 * Total episodes ending on loss: 399/1000 \n",
      "Episode * 11100 * Moving Avg Reward is ==> 0.05879 * Last Reward was ==> -0.12402 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 11200 * Moving Avg Reward is ==> 0.05677 * Last Reward was ==> -0.17431 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 11300 * Moving Avg Reward is ==> 0.05779 * Last Reward was ==> 0.14761 * Total episodes ending on loss: 401/1000 \n",
      "Episode * 11400 * Moving Avg Reward is ==> 0.06008 * Last Reward was ==> -0.07913 * Total episodes ending on loss: 395/1000 \n",
      "Episode * 11500 * Moving Avg Reward is ==> 0.05817 * Last Reward was ==> -0.23341 * Total episodes ending on loss: 402/1000 \n",
      "Episode * 11600 * Moving Avg Reward is ==> 0.05992 * Last Reward was ==> -0.22377 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 11700 * Moving Avg Reward is ==> 0.06123 * Last Reward was ==> 0.17480 * Total episodes ending on loss: 402/1000 \n",
      "Episode * 11800 * Moving Avg Reward is ==> 0.05993 * Last Reward was ==> -0.04525 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 11900 * Moving Avg Reward is ==> 0.05707 * Last Reward was ==> 0.24882 * Total episodes ending on loss: 405/1000 \n",
      "Episode * 12000 * Moving Avg Reward is ==> 0.05775 * Last Reward was ==> -0.21131 * Total episodes ending on loss: 400/1000 \n",
      "Episode * 12100 * Moving Avg Reward is ==> 0.05972 * Last Reward was ==> -0.03775 * Total episodes ending on loss: 398/1000 \n",
      "Episode * 12200 * Moving Avg Reward is ==> 0.05872 * Last Reward was ==> 0.00953 * Total episodes ending on loss: 393/1000 \n",
      "Episode * 12300 * Moving Avg Reward is ==> 0.05544 * Last Reward was ==> 0.21041 * Total episodes ending on loss: 399/1000 \n",
      "Episode * 12400 * Moving Avg Reward is ==> 0.05178 * Last Reward was ==> -0.07913 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 12500 * Moving Avg Reward is ==> 0.05206 * Last Reward was ==> 0.15056 * Total episodes ending on loss: 408/1000 \n",
      "Episode * 12600 * Moving Avg Reward is ==> 0.04886 * Last Reward was ==> -0.20097 * Total episodes ending on loss: 414/1000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 12700 * Moving Avg Reward is ==> 0.04557 * Last Reward was ==> -0.16009 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 12800 * Moving Avg Reward is ==> 0.04633 * Last Reward was ==> 0.18823 * Total episodes ending on loss: 420/1000 \n",
      "Episode * 12900 * Moving Avg Reward is ==> 0.04878 * Last Reward was ==> -0.19008 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 13000 * Moving Avg Reward is ==> 0.05068 * Last Reward was ==> 0.27513 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 13100 * Moving Avg Reward is ==> 0.05038 * Last Reward was ==> 0.01378 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 13200 * Moving Avg Reward is ==> 0.04767 * Last Reward was ==> 0.13724 * Total episodes ending on loss: 431/1000 \n",
      "Episode * 13300 * Moving Avg Reward is ==> 0.05386 * Last Reward was ==> 0.18823 * Total episodes ending on loss: 424/1000 \n",
      "Episode * 13400 * Moving Avg Reward is ==> 0.05845 * Last Reward was ==> 0.24752 * Total episodes ending on loss: 414/1000 \n",
      "Episode * 13500 * Moving Avg Reward is ==> 0.05725 * Last Reward was ==> 0.18435 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 13600 * Moving Avg Reward is ==> 0.05884 * Last Reward was ==> 0.25439 * Total episodes ending on loss: 411/1000 \n",
      "Episode * 13700 * Moving Avg Reward is ==> 0.05890 * Last Reward was ==> 0.25519 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 13800 * Moving Avg Reward is ==> 0.05655 * Last Reward was ==> -0.00063 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 13900 * Moving Avg Reward is ==> 0.05573 * Last Reward was ==> -0.21292 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 14000 * Moving Avg Reward is ==> 0.05699 * Last Reward was ==> 0.14485 * Total episodes ending on loss: 418/1000 \n",
      "Episode * 14100 * Moving Avg Reward is ==> 0.05638 * Last Reward was ==> 0.28808 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 14200 * Moving Avg Reward is ==> 0.05725 * Last Reward was ==> -0.21763 * Total episodes ending on loss: 412/1000 \n",
      "Episode * 14300 * Moving Avg Reward is ==> 0.05270 * Last Reward was ==> 0.13724 * Total episodes ending on loss: 414/1000 \n",
      "Episode * 14400 * Moving Avg Reward is ==> 0.05396 * Last Reward was ==> 0.16363 * Total episodes ending on loss: 409/1000 \n",
      "Episode * 14500 * Moving Avg Reward is ==> 0.05774 * Last Reward was ==> 0.03668 * Total episodes ending on loss: 399/1000 \n",
      "Episode * 14600 * Moving Avg Reward is ==> 0.06148 * Last Reward was ==> 0.00966 * Total episodes ending on loss: 389/1000 \n",
      "Episode * 14700 * Moving Avg Reward is ==> 0.06284 * Last Reward was ==> -0.16537 * Total episodes ending on loss: 384/1000 \n",
      "Episode * 14800 * Moving Avg Reward is ==> 0.06309 * Last Reward was ==> 0.03746 * Total episodes ending on loss: 385/1000 \n",
      "Episode * 14900 * Moving Avg Reward is ==> 0.05978 * Last Reward was ==> -0.09538 * Total episodes ending on loss: 397/1000 \n",
      "Episode * 15000 * Moving Avg Reward is ==> 0.05529 * Last Reward was ==> -0.20515 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 15100 * Moving Avg Reward is ==> 0.05443 * Last Reward was ==> 0.19055 * Total episodes ending on loss: 408/1000 \n",
      "Episode * 15200 * Moving Avg Reward is ==> 0.05413 * Last Reward was ==> -0.18439 * Total episodes ending on loss: 406/1000 \n",
      "Episode * 15300 * Moving Avg Reward is ==> 0.05444 * Last Reward was ==> 0.17076 * Total episodes ending on loss: 412/1000 \n",
      "Episode * 15400 * Moving Avg Reward is ==> 0.05311 * Last Reward was ==> 0.02227 * Total episodes ending on loss: 416/1000 \n",
      "Episode * 15500 * Moving Avg Reward is ==> 0.04847 * Last Reward was ==> -0.19890 * Total episodes ending on loss: 428/1000 \n",
      "Episode * 15600 * Moving Avg Reward is ==> 0.04769 * Last Reward was ==> 0.27848 * Total episodes ending on loss: 432/1000 \n",
      "Episode * 15700 * Moving Avg Reward is ==> 0.04951 * Last Reward was ==> 0.25439 * Total episodes ending on loss: 428/1000 \n",
      "Episode * 15800 * Moving Avg Reward is ==> 0.04749 * Last Reward was ==> 0.15586 * Total episodes ending on loss: 433/1000 \n",
      "Episode * 15900 * Moving Avg Reward is ==> 0.05054 * Last Reward was ==> 0.18728 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 16000 * Moving Avg Reward is ==> 0.05048 * Last Reward was ==> 0.17655 * Total episodes ending on loss: 420/1000 \n",
      "Episode * 16100 * Moving Avg Reward is ==> 0.05191 * Last Reward was ==> -0.11550 * Total episodes ending on loss: 424/1000 \n",
      "Episode * 16200 * Moving Avg Reward is ==> 0.05609 * Last Reward was ==> -0.02726 * Total episodes ending on loss: 418/1000 \n",
      "Episode * 16300 * Moving Avg Reward is ==> 0.05566 * Last Reward was ==> 0.13724 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 16400 * Moving Avg Reward is ==> 0.05523 * Last Reward was ==> 0.22694 * Total episodes ending on loss: 415/1000 \n",
      "Episode * 16500 * Moving Avg Reward is ==> 0.06061 * Last Reward was ==> 0.23756 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 16600 * Moving Avg Reward is ==> 0.05922 * Last Reward was ==> 0.01142 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 16700 * Moving Avg Reward is ==> 0.05610 * Last Reward was ==> -0.10302 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 16800 * Moving Avg Reward is ==> 0.05634 * Last Reward was ==> 0.20882 * Total episodes ending on loss: 404/1000 \n",
      "Episode * 16900 * Moving Avg Reward is ==> 0.05880 * Last Reward was ==> 0.09433 * Total episodes ending on loss: 401/1000 \n",
      "Episode * 17000 * Moving Avg Reward is ==> 0.05913 * Last Reward was ==> -0.15282 * Total episodes ending on loss: 401/1000 \n",
      "Episode * 17100 * Moving Avg Reward is ==> 0.06090 * Last Reward was ==> 0.14502 * Total episodes ending on loss: 390/1000 \n",
      "Episode * 17200 * Moving Avg Reward is ==> 0.05651 * Last Reward was ==> 0.12745 * Total episodes ending on loss: 400/1000 \n",
      "Episode * 17300 * Moving Avg Reward is ==> 0.05432 * Last Reward was ==> 0.10255 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 17400 * Moving Avg Reward is ==> 0.05637 * Last Reward was ==> -0.18307 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 17500 * Moving Avg Reward is ==> 0.05754 * Last Reward was ==> 0.29582 * Total episodes ending on loss: 401/1000 \n",
      "Episode * 17600 * Moving Avg Reward is ==> 0.05652 * Last Reward was ==> 0.14939 * Total episodes ending on loss: 404/1000 \n",
      "Episode * 17700 * Moving Avg Reward is ==> 0.05607 * Last Reward was ==> -0.09250 * Total episodes ending on loss: 411/1000 \n",
      "Episode * 17800 * Moving Avg Reward is ==> 0.05889 * Last Reward was ==> -0.17444 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 17900 * Moving Avg Reward is ==> 0.05657 * Last Reward was ==> 0.28614 * Total episodes ending on loss: 404/1000 \n",
      "Episode * 18000 * Moving Avg Reward is ==> 0.05914 * Last Reward was ==> 0.29356 * Total episodes ending on loss: 398/1000 \n",
      "Episode * 18100 * Moving Avg Reward is ==> 0.05686 * Last Reward was ==> 0.24883 * Total episodes ending on loss: 400/1000 \n",
      "Episode * 18200 * Moving Avg Reward is ==> 0.05934 * Last Reward was ==> 0.16681 * Total episodes ending on loss: 388/1000 \n",
      "Episode * 18300 * Moving Avg Reward is ==> 0.06221 * Last Reward was ==> 0.07868 * Total episodes ending on loss: 376/1000 \n",
      "Episode * 18400 * Moving Avg Reward is ==> 0.06465 * Last Reward was ==> 0.23357 * Total episodes ending on loss: 363/1000 \n",
      "Episode * 18500 * Moving Avg Reward is ==> 0.06253 * Last Reward was ==> -0.20925 * Total episodes ending on loss: 369/1000 \n",
      "Episode * 18600 * Moving Avg Reward is ==> 0.06092 * Last Reward was ==> -0.25777 * Total episodes ending on loss: 367/1000 \n",
      "Episode * 18700 * Moving Avg Reward is ==> 0.06583 * Last Reward was ==> 0.11962 * Total episodes ending on loss: 346/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06682\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06682\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06720\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06751\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06768\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06807\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06814\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06814\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06836\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06847\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 18800 * Moving Avg Reward is ==> 0.06865 * Last Reward was ==> 0.18898 * Total episodes ending on loss: 334/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06865\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06882\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06919\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06939\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06958\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06978\n",
      "\n",
      "Episode * 18900 * Moving Avg Reward is ==> 0.06783 * Last Reward was ==> 0.20751 * Total episodes ending on loss: 328/1000 \n",
      "Episode * 19000 * Moving Avg Reward is ==> 0.06156 * Last Reward was ==> 0.08095 * Total episodes ending on loss: 333/1000 \n",
      "Episode * 19100 * Moving Avg Reward is ==> 0.06047 * Last Reward was ==> 0.15272 * Total episodes ending on loss: 334/1000 \n",
      "Episode * 19200 * Moving Avg Reward is ==> 0.05892 * Last Reward was ==> 0.10205 * Total episodes ending on loss: 330/1000 \n",
      "Episode * 19300 * Moving Avg Reward is ==> 0.05811 * Last Reward was ==> -0.21248 * Total episodes ending on loss: 330/1000 \n",
      "Episode * 19400 * Moving Avg Reward is ==> 0.05603 * Last Reward was ==> -0.06860 * Total episodes ending on loss: 334/1000 \n",
      "Episode * 19500 * Moving Avg Reward is ==> 0.05446 * Last Reward was ==> -0.01184 * Total episodes ending on loss: 339/1000 \n",
      "Episode * 19600 * Moving Avg Reward is ==> 0.05993 * Last Reward was ==> 0.28332 * Total episodes ending on loss: 330/1000 \n",
      "Episode * 19700 * Moving Avg Reward is ==> 0.05513 * Last Reward was ==> 0.21539 * Total episodes ending on loss: 346/1000 \n",
      "Episode * 19800 * Moving Avg Reward is ==> 0.04964 * Last Reward was ==> -0.19656 * Total episodes ending on loss: 364/1000 \n",
      "Episode * 19900 * Moving Avg Reward is ==> 0.05037 * Last Reward was ==> -0.12712 * Total episodes ending on loss: 372/1000 \n",
      "Episode * 20000 * Moving Avg Reward is ==> 0.05497 * Last Reward was ==> 0.28100 * Total episodes ending on loss: 368/1000 \n",
      "Episode * 20100 * Moving Avg Reward is ==> 0.05870 * Last Reward was ==> 0.26951 * Total episodes ending on loss: 363/1000 \n",
      "Episode * 20200 * Moving Avg Reward is ==> 0.06089 * Last Reward was ==> 0.09581 * Total episodes ending on loss: 366/1000 \n",
      "Episode * 20300 * Moving Avg Reward is ==> 0.05774 * Last Reward was ==> -0.20373 * Total episodes ending on loss: 375/1000 \n",
      "Episode * 20400 * Moving Avg Reward is ==> 0.05624 * Last Reward was ==> 0.21712 * Total episodes ending on loss: 385/1000 \n",
      "Episode * 20500 * Moving Avg Reward is ==> 0.06137 * Last Reward was ==> 0.32214 * Total episodes ending on loss: 371/1000 \n",
      "Episode * 20600 * Moving Avg Reward is ==> 0.06094 * Last Reward was ==> 0.03339 * Total episodes ending on loss: 375/1000 \n",
      "Episode * 20700 * Moving Avg Reward is ==> 0.06417 * Last Reward was ==> -0.18358 * Total episodes ending on loss: 360/1000 \n",
      "Episode * 20800 * Moving Avg Reward is ==> 0.06644 * Last Reward was ==> 0.08784 * Total episodes ending on loss: 355/1000 \n",
      "Episode * 20900 * Moving Avg Reward is ==> 0.06477 * Last Reward was ==> 0.16528 * Total episodes ending on loss: 353/1000 \n",
      "Episode * 21000 * Moving Avg Reward is ==> 0.06479 * Last Reward was ==> 0.25748 * Total episodes ending on loss: 350/1000 \n",
      "Episode * 21100 * Moving Avg Reward is ==> 0.06088 * Last Reward was ==> 0.16408 * Total episodes ending on loss: 361/1000 \n",
      "Episode * 21200 * Moving Avg Reward is ==> 0.06099 * Last Reward was ==> -0.05814 * Total episodes ending on loss: 361/1000 \n",
      "Episode * 21300 * Moving Avg Reward is ==> 0.06535 * Last Reward was ==> -0.15889 * Total episodes ending on loss: 346/1000 \n",
      "Episode * 21400 * Moving Avg Reward is ==> 0.06416 * Last Reward was ==> 0.25735 * Total episodes ending on loss: 334/1000 \n",
      "Episode * 21500 * Moving Avg Reward is ==> 0.06099 * Last Reward was ==> 0.05707 * Total episodes ending on loss: 336/1000 \n",
      "Episode * 21600 * Moving Avg Reward is ==> 0.05547 * Last Reward was ==> 0.02469 * Total episodes ending on loss: 343/1000 \n",
      "Episode * 21700 * Moving Avg Reward is ==> 0.05524 * Last Reward was ==> -0.15881 * Total episodes ending on loss: 349/1000 \n",
      "Episode * 21800 * Moving Avg Reward is ==> 0.05632 * Last Reward was ==> 0.30030 * Total episodes ending on loss: 344/1000 \n",
      "Episode * 21900 * Moving Avg Reward is ==> 0.05949 * Last Reward was ==> -0.21341 * Total episodes ending on loss: 340/1000 \n",
      "Episode * 22000 * Moving Avg Reward is ==> 0.05919 * Last Reward was ==> -0.07171 * Total episodes ending on loss: 346/1000 \n",
      "Episode * 22100 * Moving Avg Reward is ==> 0.06127 * Last Reward was ==> -0.20548 * Total episodes ending on loss: 339/1000 \n",
      "Episode * 22200 * Moving Avg Reward is ==> 0.06403 * Last Reward was ==> 0.31208 * Total episodes ending on loss: 333/1000 \n",
      "Episode * 22300 * Moving Avg Reward is ==> 0.06615 * Last Reward was ==> 0.20460 * Total episodes ending on loss: 335/1000 \n",
      "Episode * 22400 * Moving Avg Reward is ==> 0.06823 * Last Reward was ==> 0.26872 * Total episodes ending on loss: 337/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06982\n",
      "\n",
      "Episode * 22500 * Moving Avg Reward is ==> 0.06924 * Last Reward was ==> -0.17581 * Total episodes ending on loss: 339/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.06991\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07029\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07044\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07058\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07070\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07075\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07095\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07122\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07173\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07175\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07213\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07259\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07278\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07296\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07310\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07311\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07322\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07350\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07353\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07369\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07371\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07411\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07437\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07446\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07454\n",
      "\n",
      "Episode * 22600 * Moving Avg Reward is ==> 0.07349 * Last Reward was ==> -0.15486 * Total episodes ending on loss: 332/1000 \n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07456\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07461\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07471\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07509\n",
      "\n",
      "* Models saved *\n",
      "\n",
      "New historical moving average record: 0.07522\n",
      "\n",
      "Episode * 22700 * Moving Avg Reward is ==> 0.07389 * Last Reward was ==> 0.14827 * Total episodes ending on loss: 329/1000 \n",
      "Episode * 22800 * Moving Avg Reward is ==> 0.06929 * Last Reward was ==> 0.23854 * Total episodes ending on loss: 340/1000 \n",
      "Episode * 22900 * Moving Avg Reward is ==> 0.06536 * Last Reward was ==> 0.16124 * Total episodes ending on loss: 347/1000 \n",
      "Episode * 23000 * Moving Avg Reward is ==> 0.06365 * Last Reward was ==> 0.05127 * Total episodes ending on loss: 350/1000 \n",
      "Episode * 23100 * Moving Avg Reward is ==> 0.06340 * Last Reward was ==> 0.00325 * Total episodes ending on loss: 349/1000 \n",
      "Episode * 23200 * Moving Avg Reward is ==> 0.05833 * Last Reward was ==> -0.05101 * Total episodes ending on loss: 366/1000 \n",
      "Episode * 23300 * Moving Avg Reward is ==> 0.05490 * Last Reward was ==> -0.15080 * Total episodes ending on loss: 371/1000 \n",
      "Episode * 23400 * Moving Avg Reward is ==> 0.05310 * Last Reward was ==> -0.03573 * Total episodes ending on loss: 384/1000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 23500 * Moving Avg Reward is ==> 0.04929 * Last Reward was ==> -0.21431 * Total episodes ending on loss: 393/1000 \n",
      "Episode * 23600 * Moving Avg Reward is ==> 0.04932 * Last Reward was ==> -0.03709 * Total episodes ending on loss: 397/1000 \n",
      "Episode * 23700 * Moving Avg Reward is ==> 0.04802 * Last Reward was ==> -0.19891 * Total episodes ending on loss: 408/1000 \n",
      "Episode * 23800 * Moving Avg Reward is ==> 0.05246 * Last Reward was ==> 0.20910 * Total episodes ending on loss: 404/1000 \n",
      "Episode * 23900 * Moving Avg Reward is ==> 0.05052 * Last Reward was ==> -0.19929 * Total episodes ending on loss: 413/1000 \n",
      "Episode * 24000 * Moving Avg Reward is ==> 0.05358 * Last Reward was ==> -0.00318 * Total episodes ending on loss: 410/1000 \n",
      "Episode * 24100 * Moving Avg Reward is ==> 0.05230 * Last Reward was ==> 0.21978 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 24200 * Moving Avg Reward is ==> 0.05624 * Last Reward was ==> 0.25519 * Total episodes ending on loss: 407/1000 \n",
      "Episode * 24300 * Moving Avg Reward is ==> 0.05609 * Last Reward was ==> 0.23108 * Total episodes ending on loss: 410/1000 \n",
      "Episode * 24400 * Moving Avg Reward is ==> 0.05450 * Last Reward was ==> 0.31311 * Total episodes ending on loss: 412/1000 \n",
      "Episode * 24500 * Moving Avg Reward is ==> 0.05668 * Last Reward was ==> -0.16518 * Total episodes ending on loss: 409/1000 \n",
      "Episode * 24600 * Moving Avg Reward is ==> 0.05328 * Last Reward was ==> -0.10265 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 24700 * Moving Avg Reward is ==> 0.05223 * Last Reward was ==> -0.13645 * Total episodes ending on loss: 418/1000 \n",
      "Episode * 24800 * Moving Avg Reward is ==> 0.05230 * Last Reward was ==> -0.20028 * Total episodes ending on loss: 416/1000 \n",
      "Episode * 24900 * Moving Avg Reward is ==> 0.05301 * Last Reward was ==> 0.25588 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 25000 * Moving Avg Reward is ==> 0.04958 * Last Reward was ==> 0.26578 * Total episodes ending on loss: 420/1000 \n",
      "Episode * 25100 * Moving Avg Reward is ==> 0.04952 * Last Reward was ==> 0.27403 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 25200 * Moving Avg Reward is ==> 0.04484 * Last Reward was ==> 0.22194 * Total episodes ending on loss: 432/1000 \n",
      "Episode * 25300 * Moving Avg Reward is ==> 0.04931 * Last Reward was ==> 0.24863 * Total episodes ending on loss: 419/1000 \n",
      "Episode * 25400 * Moving Avg Reward is ==> 0.04926 * Last Reward was ==> -0.21631 * Total episodes ending on loss: 417/1000 \n",
      "Episode * 25500 * Moving Avg Reward is ==> 0.04689 * Last Reward was ==> -0.06791 * Total episodes ending on loss: 421/1000 \n",
      "Episode * 25600 * Moving Avg Reward is ==> 0.05072 * Last Reward was ==> -0.17849 * Total episodes ending on loss: 403/1000 \n",
      "Episode * 25700 * Moving Avg Reward is ==> 0.05201 * Last Reward was ==> 0.13881 * Total episodes ending on loss: 397/1000 \n",
      "Episode * 25800 * Moving Avg Reward is ==> 0.05066 * Last Reward was ==> -0.13754 * Total episodes ending on loss: 397/1000 \n",
      "Episode * 25900 * Moving Avg Reward is ==> 0.05403 * Last Reward was ==> -0.15173 * Total episodes ending on loss: 386/1000 \n",
      "Episode * 26000 * Moving Avg Reward is ==> 0.05620 * Last Reward was ==> 0.27808 * Total episodes ending on loss: 381/1000 \n",
      "Episode * 26100 * Moving Avg Reward is ==> 0.05908 * Last Reward was ==> -0.21763 * Total episodes ending on loss: 376/1000 \n",
      "Episode * 26200 * Moving Avg Reward is ==> 0.06442 * Last Reward was ==> -0.13001 * Total episodes ending on loss: 365/1000 \n",
      "Episode * 26300 * Moving Avg Reward is ==> 0.06258 * Last Reward was ==> 0.02049 * Total episodes ending on loss: 372/1000 \n",
      "Episode * 26400 * Moving Avg Reward is ==> 0.06246 * Last Reward was ==> 0.18527 * Total episodes ending on loss: 375/1000 \n",
      "Episode * 26500 * Moving Avg Reward is ==> 0.06113 * Last Reward was ==> 0.22096 * Total episodes ending on loss: 380/1000 \n",
      "Episode * 26600 * Moving Avg Reward is ==> 0.05877 * Last Reward was ==> -0.14344 * Total episodes ending on loss: 392/1000 \n",
      "Episode * 26700 * Moving Avg Reward is ==> 0.05953 * Last Reward was ==> 0.16300 * Total episodes ending on loss: 390/1000 \n",
      "Episode * 26800 * Moving Avg Reward is ==> 0.05973 * Last Reward was ==> 0.28465 * Total episodes ending on loss: 388/1000 \n",
      "Episode * 26900 * Moving Avg Reward is ==> 0.05898 * Last Reward was ==> 0.08489 * Total episodes ending on loss: 389/1000 \n",
      "Episode * 27000 * Moving Avg Reward is ==> 0.05786 * Last Reward was ==> 0.09753 * Total episodes ending on loss: 394/1000 \n",
      "Episode * 27100 * Moving Avg Reward is ==> 0.05700 * Last Reward was ==> 0.26874 * Total episodes ending on loss: 389/1000 \n",
      "Episode * 27200 * Moving Avg Reward is ==> 0.05219 * Last Reward was ==> -0.16136 * Total episodes ending on loss: 399/1000 \n",
      "Episode * 27300 * Moving Avg Reward is ==> 0.05407 * Last Reward was ==> 0.11121 * Total episodes ending on loss: 390/1000 \n",
      "Episode * 27400 * Moving Avg Reward is ==> 0.05504 * Last Reward was ==> -0.28896 * Total episodes ending on loss: 378/1000 \n",
      "Episode * 27500 * Moving Avg Reward is ==> 0.06073 * Last Reward was ==> 0.28468 * Total episodes ending on loss: 360/1000 \n",
      "Episode * 27600 * Moving Avg Reward is ==> 0.06021 * Last Reward was ==> 0.15393 * Total episodes ending on loss: 354/1000 \n",
      "Episode * 27700 * Moving Avg Reward is ==> 0.05716 * Last Reward was ==> 0.12524 * Total episodes ending on loss: 365/1000 \n",
      "Episode * 27800 * Moving Avg Reward is ==> 0.05615 * Last Reward was ==> 0.04081 * Total episodes ending on loss: 370/1000 \n",
      "Episode * 27900 * Moving Avg Reward is ==> 0.05466 * Last Reward was ==> 0.13910 * Total episodes ending on loss: 373/1000 \n",
      "Episode * 28000 * Moving Avg Reward is ==> 0.05672 * Last Reward was ==> -0.07435 * Total episodes ending on loss: 365/1000 \n",
      "Episode * 28100 * Moving Avg Reward is ==> 0.05587 * Last Reward was ==> 0.19056 * Total episodes ending on loss: 369/1000 \n",
      "Episode * 28200 * Moving Avg Reward is ==> 0.05962 * Last Reward was ==> -0.11291 * Total episodes ending on loss: 351/1000 \n",
      "Episode * 28300 * Moving Avg Reward is ==> 0.05464 * Last Reward was ==> 0.13811 * Total episodes ending on loss: 362/1000 \n",
      "Episode * 28400 * Moving Avg Reward is ==> 0.05321 * Last Reward was ==> 0.10029 * Total episodes ending on loss: 364/1000 \n",
      "Episode * 28500 * Moving Avg Reward is ==> 0.05160 * Last Reward was ==> 0.15688 * Total episodes ending on loss: 368/1000 \n",
      "Episode * 28600 * Moving Avg Reward is ==> 0.04991 * Last Reward was ==> 0.22998 * Total episodes ending on loss: 372/1000 \n",
      "Episode * 28700 * Moving Avg Reward is ==> 0.05050 * Last Reward was ==> -0.24288 * Total episodes ending on loss: 369/1000 \n",
      "Episode * 28800 * Moving Avg Reward is ==> 0.04894 * Last Reward was ==> -0.21386 * Total episodes ending on loss: 371/1000 \n",
      "Episode * 28900 * Moving Avg Reward is ==> 0.05036 * Last Reward was ==> 0.28348 * Total episodes ending on loss: 369/1000 \n",
      "Episode * 29000 * Moving Avg Reward is ==> 0.04995 * Last Reward was ==> -0.10179 * Total episodes ending on loss: 365/1000 \n"
     ]
    }
   ],
   "source": [
    "agent.env.mode = \"train\"\n",
    "agent.learning_log.episodes = 0\n",
    "agent.learn(\n",
    "    timesteps=-1, \n",
    "    log_every=100,\n",
    "    success_threshold_lookback=1000,\n",
    "    success_strict=True,\n",
    ")\n",
    "\n",
    "print('A2C + CNN + 0.19 threshold -> Executed in 1h 1m 4s, finished 18:43:51 2022-08-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0ca56",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.891Z"
    }
   },
   "outputs": [],
   "source": [
    "xxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51604aa0",
   "metadata": {},
   "source": [
    "### Test the results\n",
    "* Runs a set of episodes with **unseen data**\n",
    "* Stores the results in a csv file for later consulting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cbe8c2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.892Z"
    }
   },
   "outputs": [],
   "source": [
    "success = 0\n",
    "n_tests = 10000\n",
    "\n",
    "scores = []\n",
    "targets = []\n",
    "portfolio_target_ratios = []\n",
    "initial_investments = []\n",
    "\n",
    "for i in trange(n_tests):\n",
    "    state = agent.env.reset(visualize=False,mode=\"test\")\n",
    "    step = 0\n",
    "    score = 0\n",
    "    reward = 0\n",
    "    done = False\n",
    "    \n",
    "    targets.append((agent.env.episode_target-agent.env.initial_investment)/agent.env.initial_investment)\n",
    "    initial_investments.append(agent.env.initial_investment)\n",
    "\n",
    "    while not done:\n",
    "        agent.env.render()\n",
    "        \n",
    "        # Select action\n",
    "        action, action_onehot, prediction = agent.choose_action(state)\n",
    "        \n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        next_state, reward, done, info = agent.env.step(action)\n",
    "        \n",
    "        # End of episode, track scores here\n",
    "        if done :\n",
    "            if agent.env.portfolio_value > agent.env.initial_investment:\n",
    "                success +=1\n",
    "\n",
    "        step+=1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    \n",
    "    # Track scores and ratios\n",
    "    scores.append(score)\n",
    "    portfolio_target_ratios.append(info[\"portfolio_value\"]/info[\"episode_target\"] -1)\n",
    "    \n",
    "    \n",
    "test_results_dataframe = pd.DataFrame([[\n",
    "    n_tests,\n",
    "    str(round(np.mean(scores)*100,3))+'%',\n",
    "    str(round(np.mean(targets)*100,3))+'%',\n",
    "    str(round(np.mean(portfolio_target_ratios)*100,3))+'%',\n",
    "    str(round(min(scores)*100,3))+'%',\n",
    "    str(round(max(scores)*100,3))+'%',\n",
    "    str(round((success/n_tests)*100,3)) +'%'\n",
    "]],\n",
    "    columns=[\n",
    "        '# Blind tests',\n",
    "        '% Average portfolio return', \n",
    "        '% Desired portfolio return', \n",
    "        'Portfolio/Target rate',\n",
    "        '% Historical minimum return',\n",
    "        '% Historical maximum return', \n",
    "        '% Episodes concluded with positive outcome'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "agent.results_writer.store_test_results(agent,test_results_dataframe)\n",
    "\n",
    "test_results_dataframe.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda01087",
   "metadata": {},
   "source": [
    "### Visual test\n",
    "* Runs a set of episodes with **unseen data**\n",
    "* See the evolution in real time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc53ab8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.893Z"
    }
   },
   "outputs": [],
   "source": [
    "success = 0\n",
    "n_tests = 10\n",
    "\n",
    "scores = []\n",
    "targets = []\n",
    "\n",
    "\n",
    "for i in trange(n_tests):\n",
    "    state = agent.env.reset(visualize=True,mode=\"test\")\n",
    "    step = 0\n",
    "    score = 0\n",
    "    reward = 0\n",
    "    done = False\n",
    "    targets.append((agent.env.episode_target-agent.env.initial_investment)/agent.env.initial_investment)\n",
    "    initial_portfolio = agent.env.portfolio_value\n",
    "\n",
    "    while not done:\n",
    "        agent.env.render()\n",
    "        \n",
    "        # Select desired action\n",
    "        action, action_onehot, prediction = agent.choose_action(state)\n",
    "\n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        next_state, reward, done, _ = agent.env.step(action)\n",
    "\n",
    "        # Update current state\n",
    "        if done :\n",
    "            if agent.env.portfolio_value > agent.env.initial_investment:\n",
    "                success +=1\n",
    "\n",
    "        step+=1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835bf3e",
   "metadata": {},
   "source": [
    "### Transactions profit\n",
    "* Track how much the agent gained by doing purchases and sales\n",
    "* Doesn't track the portfolio value \n",
    "* Already has the fees discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b574ea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.894Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "success = 0\n",
    "n_tests = 10000\n",
    "\n",
    "test_results_data = []\n",
    "test_results_columns = [\n",
    "    'dataset id',\n",
    "    'episode start date', \n",
    "    'episode end date',\n",
    "    'episode working days',\n",
    "    'total transactions',\n",
    "    'total transaction profit',\n",
    "    \"dataframe hash\",\n",
    "    \"agent hash\"\n",
    "]\n",
    "\n",
    "print('NOTE: This test only tracks the transactions profit. ')\n",
    "\n",
    "for i in trange(n_tests):\n",
    "    trading_history = []\n",
    "    state = agent.env.reset(visualize=False,mode=\"test\")\n",
    "    step = 0\n",
    "    score = 0\n",
    "    reward = 0\n",
    "    done = False\n",
    "    #targets.append((agent.env.episode_target-agent.env.initial_investment)/agent.env.initial_investment)\n",
    "    #initial_portfolio = agent.env.portfolio_value\n",
    "    \n",
    "    j = 0\n",
    "    num_stocks = 0\n",
    "    while not done:\n",
    "        agent.env.render()\n",
    "        \n",
    "        # Select desired action\n",
    "        action, action_onehot, prediction = agent.choose_action(state)\n",
    "        current_price = agent.env.df.iloc[agent.env.current_step -1]['close']\n",
    "        \n",
    "        if action == agent.env.ACTIONS.BUY:\n",
    "            discounted_price = current_price * (1+agent.env.fees.BUY) \n",
    "            if agent.env.stock_held < agent.env.maximum_stocks_held and agent.env.cash_in_hand >= discounted_price:\n",
    "                num_stocks +=1\n",
    "                trading_history.append(['buy', discounted_price])\n",
    "        elif action == agent.env.ACTIONS.SELL:\n",
    "            if agent.env.stock_held > 0:\n",
    "                discounted_price = current_price * (1-agent.env.fees.SELL) \n",
    "                trading_history.append(['sell', discounted_price])\n",
    "                num_stocks =0\n",
    "                \n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        next_state, reward, done, _ = agent.env.step(action)\n",
    "\n",
    "        # Update current state\n",
    "        if done :\n",
    "            if agent.env.portfolio_value > agent.env.initial_investment:\n",
    "                success +=1\n",
    "                \n",
    "            profits = []\n",
    "            purchases = []\n",
    "            for e in trading_history:\n",
    "                if e[0] == 'buy':\n",
    "                    purchases.append(e[1])\n",
    "                else:\n",
    "                    profits.append((e[1]* len(purchases) - sum(purchases)) / sum(purchases))\n",
    "                    purchases.clear() \n",
    "                    \n",
    "            test_results_data.append([\n",
    "                agent.env.dataset_idx,\n",
    "                agent.env.df.iloc[agent.env.lookback].name,\n",
    "                agent.env.df.iloc[-1].name,\n",
    "                agent.env.window_size,\n",
    "                len(profits),\n",
    "                sum(profits)*100,\n",
    "                agent.env.df_name,\n",
    "                agent.hash\n",
    "            ])\n",
    "\n",
    "\n",
    "        step+=1\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    \n",
    "\n",
    "agent.env.close()\n",
    "\n",
    "\n",
    "pd.DataFrame(test_results_data,columns=test_results_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753593b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.894Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_results_df = pd.DataFrame(test_results_data,columns=test_results_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa7c41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.896Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_results_df.sort_values(by=\"dataset id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74cc2b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.896Z"
    }
   },
   "outputs": [],
   "source": [
    "transaction_results_df[transaction_results_df['total transaction profit'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abe6da",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.897Z"
    }
   },
   "outputs": [],
   "source": [
    "failed_episodes_df = transaction_results_df[transaction_results_df['total transaction profit'] <= 0]\n",
    "failed_episodes_idx = failed_episodes_df['dataset id'].unique()\n",
    "failed_episodes_idx.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d02ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.898Z"
    }
   },
   "outputs": [],
   "source": [
    "len(transaction_results_df[transaction_results_df['total transaction profit'] <= 0]['dataset id'].unique()),len(transaction_results_df[transaction_results_df['total transaction profit'] > 0]['dataset id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc4d6a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "for idx in failed_episodes_idx:\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(agent.env.df['close'])\n",
    "    plt.title('#'+str(idx)+' - ' + str(len(failed_episodes_df[failed_episodes_df['dataset id'] == idx])) +'/' + str(len(transaction_results_df[transaction_results_df['dataset id'] == idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06983296",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.899Z"
    }
   },
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144ef9d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.900Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(agent.env.df['close'])\n",
    "plt.title('#'+str(idx)+' - ' + str(len(failed_episodes_df[failed_episodes_df['dataset id'] == idx])) +'/' + str(len(transaction_results_df[transaction_results_df['dataset id'] == idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4929f74",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T12:50:08.901Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.ten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
